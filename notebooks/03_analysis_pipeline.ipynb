{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd420a8e",
   "metadata": {},
   "source": [
    "# Lab 3 - Data Analysis Pipeline\n",
    "\n",
    "**Notebook:** `03_analysis_pipeline.ipynb`  \n",
    "**Objective:** We implement the **third pipeline**: perform **descriptive analysis** on aggregated datasets from the Exploitation Zone and generate **visual dashboards** using `matplotlib` and `seaborn`. This analysis reveals patterns across space and time for tourist housing, household structure, and commercial activity.\n",
    "\n",
    "### Group: *L3-T04*\n",
    "\n",
    "#### Group Members: **Marvin Ernst, Oriol Gelabert, Alex Malo**  \n",
    "Class: **23D020 - Big Data Management for Data Science**  \n",
    "Date: *June 23, 2025*\n",
    "\n",
    "In this notebook we address the **B.1 Analysis Task**:\n",
    "- **Descriptive Analysis**: Use statistical summaries and charts to explore household demographics, commercial indicators, and tourism licenses.\n",
    "- **Dashboarding**: Create static visualizations that highlight trends and support decision-making by local authorities or urban planners.\n",
    "\n",
    "---\n",
    "\n",
    "### Steps in this pipeline:\n",
    "\n",
    "1. **Setup and Load Data**  \n",
    "   Load libraries, create a Spark session, and read aggregated datasets from the Exploitation Zone.\n",
    "\n",
    "2. **Descriptive Analysis**  \n",
    "   - Analyze household sizes by district  \n",
    "   - Evaluate prevalence of commercial indicators like coworking and nightlife  \n",
    "   - Explore spatial patterns in tourist housing licenses\n",
    "\n",
    "3. **Data Visualization (Dashboarding)**  \n",
    "   - Bar plots for size distributions and indicator prevalence  \n",
    "   - Scatter plots to identify relationships between datasets  \n",
    "   - Annotated figures to support storytelling and interpretation\n",
    "\n",
    "---\n",
    "\n",
    "All visualizations are generated from data in the **Exploitation Zone**, ensuring consistency and reproducibility of results.\n",
    "\n",
    "### Setup\n",
    "\n",
    "First, we load all the relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1579b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import pandas.io.formats.style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c749ab0",
   "metadata": {},
   "source": [
    "#### Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74acead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865759cb",
   "metadata": {},
   "source": [
    "#### Define Folder Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fdfad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path().resolve().parent\n",
    "exploitation = project_root / \"exploitation_zone\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14c2d6a",
   "metadata": {},
   "source": [
    "## **Descriptive Analysis**\n",
    "\n",
    "We now compute summary statistics on the main datasets to explore data distributions, count totals, and check for outliers or irregularities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef424cb6",
   "metadata": {},
   "source": [
    "#### **Household Size Distribution**\n",
    "\n",
    "We load household data and convert to Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbc6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_household_dis = spark.read.parquet(f\"{exploitation}/households_districte_2022.parquet\")\n",
    "pdf_household_dis = df_household_dis.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3b9d7f",
   "metadata": {},
   "source": [
    "And we how summary stats for household size distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df774a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics for household counts by district:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DES_DISTRICTE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ciutat vella</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4549.000000</td>\n",
       "      <td>5586.731021</td>\n",
       "      <td>286.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>1895.0</td>\n",
       "      <td>5836.0</td>\n",
       "      <td>15979.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eixample</th>\n",
       "      <td>9.0</td>\n",
       "      <td>12512.333333</td>\n",
       "      <td>14834.308149</td>\n",
       "      <td>356.0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>4543.0</td>\n",
       "      <td>19621.0</td>\n",
       "      <td>38275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gracia</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5874.888889</td>\n",
       "      <td>7168.646219</td>\n",
       "      <td>99.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>9153.0</td>\n",
       "      <td>18697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horta-guinardo</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7794.444444</td>\n",
       "      <td>8934.563967</td>\n",
       "      <td>196.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>13497.0</td>\n",
       "      <td>21348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>les corts</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3645.555556</td>\n",
       "      <td>4106.853483</td>\n",
       "      <td>86.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1517.0</td>\n",
       "      <td>6103.0</td>\n",
       "      <td>9869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nou barris</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7440.333333</td>\n",
       "      <td>8210.112225</td>\n",
       "      <td>293.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>3151.0</td>\n",
       "      <td>12661.0</td>\n",
       "      <td>19946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sant andreu</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6666.666667</td>\n",
       "      <td>7451.179017</td>\n",
       "      <td>201.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>11950.0</td>\n",
       "      <td>17929.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sant marti</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10615.888889</td>\n",
       "      <td>11875.709605</td>\n",
       "      <td>300.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>3996.0</td>\n",
       "      <td>18560.0</td>\n",
       "      <td>28392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sants-montjuic</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8277.777778</td>\n",
       "      <td>9524.982202</td>\n",
       "      <td>300.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3085.0</td>\n",
       "      <td>13516.0</td>\n",
       "      <td>23841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarria-sant gervasi</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6269.888889</td>\n",
       "      <td>6542.707342</td>\n",
       "      <td>232.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>4006.0</td>\n",
       "      <td>9432.0</td>\n",
       "      <td>17190.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count          mean           std    min    25%     50%  \\\n",
       "DES_DISTRICTE                                                                  \n",
       "ciutat vella           9.0   4549.000000   5586.731021  286.0  505.0  1895.0   \n",
       "eixample               9.0  12512.333333  14834.308149  356.0  763.0  4543.0   \n",
       "gracia                 9.0   5874.888889   7168.646219   99.0  228.0  1918.0   \n",
       "horta-guinardo         9.0   7794.444444   8934.563967  196.0  433.0  2720.0   \n",
       "les corts              9.0   3645.555556   4106.853483   86.0  158.0  1517.0   \n",
       "nou barris             9.0   7440.333333   8210.112225  293.0  590.0  3151.0   \n",
       "sant andreu            9.0   6666.666667   7451.179017  201.0  399.0  2392.0   \n",
       "sant marti             9.0  10615.888889  11875.709605  300.0  677.0  3996.0   \n",
       "sants-montjuic         9.0   8277.777778   9524.982202  300.0  600.0  3085.0   \n",
       "sarria-sant gervasi    9.0   6269.888889   6542.707342  232.0  468.0  4006.0   \n",
       "\n",
       "                         75%      max  \n",
       "DES_DISTRICTE                          \n",
       "ciutat vella          5836.0  15979.0  \n",
       "eixample             19621.0  38275.0  \n",
       "gracia                9153.0  18697.0  \n",
       "horta-guinardo       13497.0  21348.0  \n",
       "les corts             6103.0   9869.0  \n",
       "nou barris           12661.0  19946.0  \n",
       "sant andreu          11950.0  17929.0  \n",
       "sant marti           18560.0  28392.0  \n",
       "sants-montjuic       13516.0  23841.0  \n",
       "sarria-sant gervasi   9432.0  17190.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Descriptive statistics for household counts by district:\")\n",
    "pdf_household_dis.groupby(\"DES_DISTRICTE\")[\"NUM_VALOR\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804cb9c5",
   "metadata": {},
   "source": [
    "**Null and Uniqueness Checks:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6612d2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in household dataset:\n",
      "COD_DISTRICTE             0\n",
      "DES_DISTRICTE             0\n",
      "NUM_PERSONES_AGG          0\n",
      "TOTAL_PERSONES_AGG        0\n",
      "NUM_VALOR                 0\n",
      "PCT_PERSONES_DISTRICTE    0\n",
      "PCT_VIVENDES_DISTRICTE    0\n",
      "dtype: int64\n",
      "\n",
      "Unique values in household dataset:\n",
      "COD_DISTRICTE             10\n",
      "DES_DISTRICTE             10\n",
      "NUM_PERSONES_AGG           9\n",
      "TOTAL_PERSONES_AGG        89\n",
      "NUM_VALOR                 89\n",
      "PCT_PERSONES_DISTRICTE    90\n",
      "PCT_VIVENDES_DISTRICTE    90\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Null values in household dataset:\")\n",
    "print(pdf_household_dis.isnull().sum())\n",
    "print(\"\\nUnique values in household dataset:\")\n",
    "print(pdf_household_dis.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6894936f",
   "metadata": {},
   "source": [
    "#### **Commercial Indicators Stats**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34cd218",
   "metadata": {},
   "source": [
    "We load commercial indicator data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44fee855",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_com_dis = spark.read.parquet(f\"{exploitation}/comercial_indicators_district_2022.parquet\")\n",
    "pdf_com_dis = df_com_dis.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "262469e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in commercial indicators DataFrame:\n",
      "['DES_ACTIVITAT_PRINCIPAL', 'DES_GRUP', 'COD_DISTRICTE', 'TOTAL', 'TOTAL_IND_OCI_NOCTURN', 'TOTAL_IND_COWORKING', 'TOTAL_IND_SERVEI_DEGUSTACIO', 'TOTAL_IND_OBERT24H', 'TOTAL_IND_MIXT', 'TOTAL_IND_PEU_CARRER', 'TOTAL_IND_MERCAT', 'TOTAL_IND_GALERIA', 'TOTAL_IND_CENTRE_COMERCIAL', 'TOTAL_IND_EIX_COMERCIAL']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available columns in commercial indicators DataFrame:\")\n",
    "print(pdf_com_dis.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e6142",
   "metadata": {},
   "source": [
    "And also here we show summary stats for commercial indicators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41fd0f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TOTAL_IND_COWORKING  TOTAL_IND_OCI_NOCTURN\n",
      "count           159.000000             159.000000\n",
      "mean              2.037736               1.377358\n",
      "std               8.622084               5.871708\n",
      "min               0.000000               0.000000\n",
      "25%               0.000000               0.000000\n",
      "50%               0.000000               0.000000\n",
      "75%               1.000000               0.000000\n",
      "max              92.000000              42.000000\n"
     ]
    }
   ],
   "source": [
    "print(pdf_com_dis[[\"TOTAL_IND_COWORKING\", \"TOTAL_IND_OCI_NOCTURN\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4120d23a",
   "metadata": {},
   "source": [
    "**Null and Uniqueness Checks:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e559d049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null values in commercial indicators dataset:\n",
      "DES_ACTIVITAT_PRINCIPAL        0\n",
      "DES_GRUP                       0\n",
      "COD_DISTRICTE                  0\n",
      "TOTAL                          0\n",
      "TOTAL_IND_OCI_NOCTURN          0\n",
      "TOTAL_IND_COWORKING            0\n",
      "TOTAL_IND_SERVEI_DEGUSTACIO    0\n",
      "TOTAL_IND_OBERT24H             0\n",
      "TOTAL_IND_MIXT                 0\n",
      "TOTAL_IND_PEU_CARRER           0\n",
      "TOTAL_IND_MERCAT               0\n",
      "TOTAL_IND_GALERIA              0\n",
      "TOTAL_IND_CENTRE_COMERCIAL     0\n",
      "TOTAL_IND_EIX_COMERCIAL        0\n",
      "dtype: int64\n",
      "\n",
      "Unique values in commercial indicators dataset:\n",
      "DES_ACTIVITAT_PRINCIPAL          2\n",
      "DES_GRUP                        16\n",
      "COD_DISTRICTE                   10\n",
      "TOTAL                          131\n",
      "TOTAL_IND_OCI_NOCTURN           13\n",
      "TOTAL_IND_COWORKING             16\n",
      "TOTAL_IND_SERVEI_DEGUSTACIO     22\n",
      "TOTAL_IND_OBERT24H              13\n",
      "TOTAL_IND_MIXT                   5\n",
      "TOTAL_IND_PEU_CARRER           133\n",
      "TOTAL_IND_MERCAT                29\n",
      "TOTAL_IND_GALERIA               16\n",
      "TOTAL_IND_CENTRE_COMERCIAL      27\n",
      "TOTAL_IND_EIX_COMERCIAL        111\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNull values in commercial indicators dataset:\")\n",
    "print(pdf_com_dis.isnull().sum())\n",
    "print(\"\\nUnique values in commercial indicators dataset:\")\n",
    "print(pdf_com_dis.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfacdce",
   "metadata": {},
   "source": [
    "####  **Tourist Licenses Distributions**\n",
    "\n",
    "We load tourist housing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hut_dis = spark.read.parquet(f\"{exploitation}/hut_district_2022_1T.parquet\")\n",
    "pdf_hut_dis = df_hut_dis.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3ded70",
   "metadata": {},
   "source": [
    "We show distribution of tourist licenses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701867cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tourist license counts by district:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>936.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1281.534848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>227.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>548.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1103.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4378.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TOTAL\n",
       "count    10.000000\n",
       "mean    936.300000\n",
       "std    1281.534848\n",
       "min      29.000000\n",
       "25%     227.750000\n",
       "50%     548.000000\n",
       "75%    1103.750000\n",
       "max    4378.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tourist license counts by district:\")\n",
    "pdf_hut_dis.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b733eedb",
   "metadata": {},
   "source": [
    "**Null and Uniqueness Checks:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa578b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null values in tourist licenses dataset:\n",
      "COD_DISTRICTE    0\n",
      "TOTAL            0\n",
      "dtype: int64\n",
      "\n",
      "Unique values in tourist licenses dataset:\n",
      "COD_DISTRICTE    10\n",
      "TOTAL            10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNull values in tourist licenses dataset:\")\n",
    "print(pdf_hut_dis.isnull().sum())\n",
    "print(\"\\nUnique values in tourist licenses dataset:\")\n",
    "print(pdf_hut_dis.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6eba32",
   "metadata": {},
   "source": [
    "## **Dashboarding**\n",
    "\n",
    "Here we visually tell a ”data story” and we want to ensure the dashboards provide meaningful insights and support decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2416bc13",
   "metadata": {},
   "source": [
    "### **Household Composition by District**\n",
    "Here, we plot distribution of household sizes by district:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdadb747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(\n",
    "    data=pdf_household_dis,\n",
    "    x=\"DES_DISTRICTE\",\n",
    "    y=\"NUM_VALOR\",\n",
    "    hue=\"NUM_PERSONES_AGG\"\n",
    ")\n",
    "plt.title(\"Household Size Distribution by District (2022)\")\n",
    "plt.xlabel(\"District\")\n",
    "plt.ylabel(\"Number of Households\")\n",
    "plt.xticks(rotation=35)\n",
    "\n",
    "plt.legend(\n",
    "    title=\"Household Size\",\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.5, -0.4),\n",
    "    ncol=6,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1bda730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique household sizes: [np.int32(1), np.int32(2), np.int32(3), np.int32(4), np.int32(5), np.int32(6), np.int32(7), np.int32(8), np.int32(9)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique household sizes:\", sorted(pdf_household_dis[\"NUM_PERSONES_AGG\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e977ad79",
   "metadata": {},
   "source": [
    "From this we can see that single-person households dominate across all districts, especially in Eixample, Sants-Montjuïc, and Sant Martí. Larger household sizes (6 or more people) are relatively rare, with only a small presence in districts like Nou Barris and Ciutat Vella, suggesting limited availability or affordability of large living spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b6b02a",
   "metadata": {},
   "source": [
    "### **Commercial Premises per District**\n",
    "\n",
    "First we need to compute percentages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3c7a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_com_dis[\"PCT_IND_COWORKING\"] = (pdf_com_dis[\"TOTAL_IND_COWORKING\"] / pdf_com_dis[\"TOTAL\"]) * 100\n",
    "pdf_com_dis[\"PCT_IND_OCI_NOCTURN\"] = (pdf_com_dis[\"TOTAL_IND_OCI_NOCTURN\"] / pdf_com_dis[\"TOTAL\"]) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54061eb",
   "metadata": {},
   "source": [
    "Now, we show average % coworking and nightlife by district:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "775b0a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(\n",
    "    data=pdf_com_dis,\n",
    "    x=\"COD_DISTRICTE\",\n",
    "    y=\"PCT_IND_COWORKING\",\n",
    "    color=\"skyblue\",\n",
    "    label=\"Coworking\"\n",
    ")\n",
    "sns.barplot(\n",
    "    data=pdf_com_dis,\n",
    "    x=\"COD_DISTRICTE\",\n",
    "    y=\"PCT_IND_OCI_NOCTURN\",\n",
    "    color=\"coral\",\n",
    "    label=\"Nightlife\",\n",
    "    alpha=0.6\n",
    ")\n",
    "plt.title(\"Coworking vs Nightlife Premises by District (2022)\")\n",
    "plt.xlabel(\"District Code\")\n",
    "plt.ylabel(\"Percentage of Total Premises\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb310a4",
   "metadata": {},
   "source": [
    "This shows us that District 5 (Eixample) has a significantly higher percentage of coworking spaces than any other district, suggesting it is a major hub for flexible workspaces. In contrast, nightlife-related premises are more evenly distributed, but still slightly concentrated in districts 4 (Ciutat Vella) and 5, reflecting the urban activity in central areas.\n",
    "\n",
    "Note that the black bars in the middle of each bar are error bar (95% confidence interval) around the estimated mean value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30973b35",
   "metadata": {},
   "source": [
    "### **Tourist Licenses by District**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd9407c",
   "metadata": {},
   "source": [
    "We plot number of licenses per district:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c018ea85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mf/w_wd3t0951z162wpkh1xbddc0000gn/T/ipykernel_96297/2768034204.py:2: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(\n",
    "    data=pdf_hut_dis.sort_values(\"TOTAL\", ascending=False),\n",
    "    x=\"COD_DISTRICTE\",\n",
    "    y=\"TOTAL\",\n",
    "    palette=\"Blues_d\"\n",
    ")\n",
    "plt.title(\"Number of Tourist Licenses by District (Q1 2022)\")\n",
    "plt.xlabel(\"District Code\")\n",
    "plt.ylabel(\"Number of Licenses\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6e6f2d",
   "metadata": {},
   "source": [
    "We can see that District 2 (Eixample) has by far the highest number of tourist licenses in Q1 2022, far surpassing all other districts. This suggests a strong concentration of tourist accommodations in central areas, potentially linked to accessibility, attractions, or real estate dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f27d1",
   "metadata": {},
   "source": [
    "### **Correlation Between Tourist Activity and Commercial Uses**\n",
    "\n",
    "We investigate whether districts with more **tourist housing licenses** also show higher prevalence of **coworking** and **nightlife** commercial spaces.\n",
    "\n",
    "These scatter plots visualize the relationship between:\n",
    "- the **number of tourist licenses** per district\n",
    "- and the **percentage of coworking or nightlife premises** in the same district.\n",
    "\n",
    "We merge tourist licenses and coworking/nightlife presence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4b62408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, ensure the district code types match before merging:\n",
    "pdf_com_dis['COD_DISTRICTE'] = pdf_com_dis['COD_DISTRICTE'].astype(int)\n",
    "pdf_hut_dis['COD_DISTRICTE'] = pdf_hut_dis['COD_DISTRICTE'].astype(int)\n",
    "\n",
    "# Merge tourist housing and commercial indicators:\n",
    "merged_df = pdf_hut_dis.merge(\n",
    "    pdf_com_dis[['COD_DISTRICTE', 'PCT_IND_COWORKING', 'PCT_IND_OCI_NOCTURN']],\n",
    "    on=\"COD_DISTRICTE\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Scatter plot: Tourist Licenses vs Commercial Indicators\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(data=merged_df, x=\"TOTAL\", y=\"PCT_IND_COWORKING\")\n",
    "plt.title(\"Tourist Licenses vs % Coworking\")\n",
    "plt.xlabel(\"Total Tourist Licenses\")\n",
    "plt.ylabel(\"% Coworking Premises\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(data=merged_df, x=\"TOTAL\", y=\"PCT_IND_OCI_NOCTURN\")\n",
    "plt.title(\"Tourist Licenses vs % Nightlife\")\n",
    "plt.xlabel(\"Total Tourist Licenses\")\n",
    "plt.ylabel(\"% Nightlife Premises\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c2c0de",
   "metadata": {},
   "source": [
    "We can see that there is no strong linear relationship between the number of tourist licenses and the percentage of coworking or nightlife premises in a district.  \n",
    "However, districts with higher tourism activity tend to also have non-zero presence of these commercial types, suggesting a possible co-location pattern rather than direct proportionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893e06f0",
   "metadata": {},
   "source": [
    "### **Tourist Housing Trends Over Time**\n",
    "\n",
    "We analyze the number of tourist housing licenses over multiple quarters and districts to uncover growth patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab414b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAA/15JREFUeJzs3Qd8W9XdxvFHy3tkkElIyCIhgbBL2TsQoGWEMgsBApQWyipQaNmjjJYy3rLLSCmj7NmyIZQdRkpYISFhJwSy7XhovZ//kSVLtmzLiYdk/b7vq17dc6+ujmU5WI//5xxPNBqNCgAAAAAAAOhC3q58MgAAAAAAAMAQSgEAAAAAAKDLEUoBAAAAAACgyxFKAQAAAAAAoMsRSgEAAAAAAKDLEUoBAAAAAACgyxFKAQAAAAAAoMsRSgEAAAAAAKDLEUoBAAAAAACgyxFKAQDQg11wwQXyeDzd3Q198cUXrh933nlnd3cFnezII4/Uuuuuq2xh7zl7773zzjvKNjvuuKO7dQV7DezfAwAAsgmhFAAAHfzBL5Pbyy+/rGz13XffuQ+vM2fOzPkP/dnuySef1B577KG+ffuqqKhI6623nk4//XQtXrxY2aQnvK+7IoxLfi3Kyso0YsQIHXDAAXrooYcUiUQ65Hlef/119/O5bNkydbaPP/7YPZeFygAAdAZ/p1wVAIA8ddddd6Xs/+Mf/9Bzzz3XrH399dfvkv6cc845Ouuss9odSl144YWu2mXjjTfukH4MGzZMNTU1CgQCHXK9nsDCp6uuukobbbSRfv/736tPnz5677339Le//U333XefXnjhBY0ZM0a59r6+9dZbOyyAyTWFhYX6+9//7u7b+/3LL7/UE0884YIpq4h67LHHVFFRkTj/2WefXa1Qyn4+LQTr1atXxo+z/vj9/naHUvZc1vdsqn4DAPQchFIAAHSgX/7ylyn7b775pvvw3rS9s1VXV6u0tNR9CG3vB9HOYJUjVgmEmHvvvdcFUgcddJDuvvtu+Xy+xDELG3baaSf94he/cCFVV37/4u+bbH1fZzv7XjV9TS655BJdfvnlOvvss3XsscfqX//6V+JYQUFBp/bHwsH6+nr3s8fPHwAgGzF8DwCALmYf/H/3u99pnXXWcZUVVg3zl7/8RdFoNKM5mJrODROfN8qqGg499FD17t1b2267bcqxZBYm2HGrsrAhRvb8f/jDH9wxG361xRZbuPtHHXVUYijSms4F1dLX8+mnn+rAAw9Uv379VFxc7Pryxz/+MeWcb7/9VkcffbQGDBjgXq/x48fr9ttvTznH+m3Xv//++3XppZdqyJAh7kP4Lrvsorlz56acO2fOHE2ePFkDBw5059i5Bx98sJYvX55y3j//+U9tttlmrl9WxWTnfP3116t1raas+sS+T7fccktKIGV+8pOfuMqpWbNm6cEHH3RtJ554ovterVq1qtm1DjnkEPf84XA40faf//xH2223nQuYysvLtddee+mjjz5KeZyFX3bNzz//XHvuuac777DDDlNHzykV/97be/z66693Q9pKSko0ceJE93ra+/7iiy92r5291vvss4+WLFnS7LqZfE2tsdfuV7/6lRsqadVKRxxxhJYuXZo4PmXKFK211loKBoPNHmt9XZOqNatWtGs88MAD+uyzz1qdU+r//u//3HvcXiN7j2y++ea65557Ej/PZ5xxhrs/fPjwxM9nfHid3bf3igWddg37eXn66adbnFPKframTp2qwYMHu3Ptmr/+9a9dkGU/qxaMGgtJGaIJAOgM3f+nUwAA8oh9AP/5z3+ul156yX0YtOFxzzzzjPugaR8Qr7766tW+tn2AHD16tP70pz+lBFzJ7EP83nvvrQkTJuiiiy5yH0QttHnttdcSw6+s/bzzztNxxx3nQgCz9dZbq6N98MEH7vo2pM+ey4IMC0hsuJMFS+b777/XT3/608SHbQuvLJyw127FihU65ZRTUq5pFSler9cNjbNg6Morr3RBy1tvveWO24ft3XffXXV1dfrtb3/rwhx73W1uJ5ujp7Ky0p1nz3/uuee6wOyYY47RDz/84MKC7bffXu+//74L9DK9VlMWZM2ePduFN8lDuZJZYHL++ee7a1nIZRVVFug89dRTiaAgHrTY62XXiodbNqTOAhbr2xVXXOHOufHGG10QaX1PDoxCoZA7z45ZaGRBSGexoMReM3utLHSy7429vjvvvLMLOiyIs/eivc72/UsOHtvzNbXE3j/2fbNgxl5/e7wNr4sHmocffrgblmg/j/YzErdw4UK9+OKL7vuxJuz6NlzPQmGbOywdG/p40kknueF+J598smpra93Pib1/LXDef//9XahllXb2b4WFaMZ+LuKsrxbO2tdrx1t6bWyYrgWg9l61n7+xY8e6968Fofb62nvd+nLddde50Do+5Lirhh4DAPJEFAAAdJoTTjjB0qHE/qOPPur2L7nkkpTzDjjggKjH44nOnTvX7c+fP9+dd8cddzS7prWff/75iX27b22HHHJIs3Pjx+Kuvvpqt//DDz+02OcZM2a0+Nzp2Hl2vj2uJem+nu233z5aXl4e/fLLL1POjUQiiftTp06NDho0KPrjjz+mnHPwwQdHKysro6tWrXL7L730krv++uuvH62rq0ucd+2117r2WbNmuf3333/f7T/wwAMt9vWLL76I+ny+6KWXXprSbtfw+/2J9kyulU78PWDfi9ZUVFREN91008Rrsvbaa0cnT56ccs7999/vrvXKK6+4/ZUrV0Z79eoVPfbYY1POW7hwoXu9ktunTJniHnvWWWdF1/R9ncyuO2zYsGbf+379+kWXLVuWaD/77LNd+0YbbRQNBoOJdnsfFxQURGtra9v9NbX2/txss82i9fX1ifYrr7zStT/22GNuPxwOR4cMGRI96KCDUh7/17/+1f1szps3r9Xnsa+7tLS0xePx98upp56aaNthhx3cLW6fffaJjh8/vtXn+fOf/+yuY69rU9bu9XqjH330UZv/bhxxxBHu3HQ/t/GfQXtv2+Ps5wsAgM7A8D0AALrQv//9b1fRYhUIyWw4n31utCqg1XX88ce3eU58YmSbcLk7J6O2yqNXXnnFDcsbOnRoyrH4cEN7PWzVsp/97Gfu/o8//pi4WcWMVULZnEvJbMhh8jw98UqvefPmuW28esmqYdINhTMPP/ywe22siif5Oa0SyirRrMot02uls3LlSre1IWitseNWDRZ/TaxCyt4/VVVViXNsfqK11147MVzTqnCs8sWG9CX33d5zW265ZaLvyWy4Vlew/idXj1l/jM3BlDxvlrVbRZVV7azu15SOVQMlT7RvX7c9r72mxirsrKru8ccfT3yP4hVeViloQ9vWhA2VNMnXTvfz+c0332jGjBmr/Tw77LCDxo0b1+o59v5+9NFH3c+WDQ9squmQXwAAOguhFAAAXciGC9n8LU0DifiQGDu+ujL50GzDwLbZZhs3JM3maLKhYTbUp6sDqnhItMEGG7QaXFkYYfMu2fCk5JuFT2bRokUpj2kacNmcPCY+d5C9RqeddppbIc2GNlm4ZcPikueAsuF1FoJZANX0eT/55JPEc2ZyrXTi3/vWwon48eT3iX3vbAU1C02MhVMWqFjYEw8RrO/GhsQ17bsNHWv6elkoY3M5dYWm35t4QGVzq6Vrj3/P2vs1tcS+n01DokGDBiXmY4oPm7TX+JFHHnH7Nszv3XffdUPv1lQ8TGwtjLQhjNYvG1Zn/T3hhBMSQ2s78t8B+9mywLO1nz8AALoCc0oBAJCFWqpUSJ7MuimbJLotdo5VKFl1ic1PZJMgW7WNfeC3D/hNJ93uTvGgzCppbD6hdGxurGQt9T95ji1b9c7mYLJqMfuarWrtsssucyvKWUBjz2uvv1WtpbtevOIlk2ulEw8gba6gllg4aaFBcsWLza1l8wNZiGjzC9lcUhagWFjV9DWzOZissquppiv52ZxiViHUFVr63rT1PWvv17Qm7PW2ye1tknsLqGxrlXdWNbemPvzwQ7cdNWpUi+fYe8OCMJtLzH42rVLwhhtucHO82eT4mcjk3wEAALIFoRQAAF1o2LBhev7555tVwdgqdPHjyRU+VimUbE0qqeIshLBV6ez217/+1U2MbiveWVC16667dsnQHVuBLfmDejpWCWOvkQVx1q+OtOGGG7rbOeeco9dff91Vj91000265JJLNHLkSBeIWMVJSxNSZ3qtdOyadrPhU9dee23ayhmbcNskT7htLByxx1hgZWGihVQWVsVZ303//v07/DXrLh31NVnFla0il1y5tGDBArfyYDILo6wCzo7Zqne2yl/853FNWKhmP1u77bZbq+fZ6oIWNNrNhjHa5OY28f7ZZ5/tVnjsiJ9P+9mySfZb+/kzDOMDAHQ2hu8BANCF7AOwhSx/+9vfUtptJS37ADhp0iS3bx8YbUiYVTUls6qJNWGrnjVlKwAaW0Uu/qE4XSDWkexDsa3uZSusffXVV2krZKyCZvLkya5aJN2HZxuC1F4W5tiKc8ksULKgLv71Wwhgz22VKU1XMbT9xYsXZ3ytlljliw1Ps3nAmla/2XAxW2HOhlbZ15/Mggq79rRp01wlTdMKHhtCaO8dCxqDwWCHvGbdraO+JhsGmvx4W33Pvn/xn7k4m7vKfhZt9TsbZmqVemvKVoW0Sjr7/jUdRpgs/t6Ksyotq96y91287x3x82nv0X333ddV273zzjvNjsff913xbwEAIL9RKQUAQBeyiYWtWsMqk2wum4022sh9WLXhX6ecckqiKsTYvE/2Yda2NhmxBVS2HPyauOiii9x1rPrDqrJsPh4LumyoWXyybOuDTbhs1T5WxWMfTG1C6bbmqrGAyYKSpuzDfTq21Lw956abbuomobbr22tiwwpnzpzpzrGv3yq47PmPPfZY9wHdgjWb4NwqztKFbK158cUXdeKJJ7p5mKxayUIJq2CJB2Dxr9+qnKwyxfpjH97tdZg/f76ba8j6evrpp2d0rZbYhNo2mbVVPX388cdu36px7Ouy17Fv37568MEHUybmNvZa2fAve/9YOJU8dM9YeGNhi82BZOfanGEWAFrwZ6+rVXE1DUSzXUd9TVZ1ZNWBFuTZEDl739v77+c//3nKeXbtPfbYQw888ID7ObCflUzZe8CG/Jna2lpX2WhzgNlQTfu5t2CsNRMnTnRDFO1rsjnfbA4z+9qsD/GKOhteaOw9YK+FvUfs35V4gJQpC/ns3x6bGN3e0zZ00KrD7Ot+9dVX3ddugbW9ny0ktbnSbLinDfW1qjUAADpEp6zpBwAAnBNOOMEtqZ7Mlri3ZeEHDx4cDQQC0dGjR7tl3uPLsMetWrUqOnXqVLfsfXl5efTAAw+MLlq0qNnS7nbf2n744Ydmzx8/FvfCCy+4ZeftuQsKCtz2kEMOiX722Wcpj3vsscei48aNi/r9fvf4O+64o8Wv0Y7ZOS3dvv76a7d8fbrrfPjhh9H99tsv2qtXr2hRUVF0zJgx0XPPPTflnO+//969juuss457vQYOHBjdZZddorfcckviHFuy3q5vS9gna/q88+bNix599NHRkSNHuufr06dPdKeddoo+//zzzb6uhx56KLrttttGS0tL3W3s2LGuH7Nnz273tVry6KOPRnfbbbdo7969o4WFhdFRo0ZFf/e736X9Xsb98Y9/dF+TndsSez123313996xvlkfjzzyyOg777yTOGfKlCnu6+qo93XydYcNG9bse2Dv8aZ9TPc9i7+fZsyY0e6vKZ349aZPnx497rjj3GtdVlYWPeyww6KLFy9O+5j777/fPcbOz5R93cnv+5KSkui6664bnTx5cvTBBx+MhsPhZo/ZYYcd3C3u5ptvjm6//fbRvn37uveDfY1nnHFGdPny5SmPu/jii6Nrr7121Ov1uuey19jYffvepNP03w3z5ZdfRo844ohov3793PONGDHCPb6uri5xzq233urafT6fu4Z9HwAA6Cge+5+OibcAAACA3GeVi1YhZ1WF2223XXd3BwCAHotQCgAAAEhiE8zb0Lm5c+cy2TcAAJ2IOaUAAAAASffdd5+b/8nmqrL5vgikAADoXFRKAQAAAPaLscejsrIyN4G8TfTv9/P3WwAAOhP/pQUAAABiM7d3dxcAAMgr3u588gsuuMD9RSr5Nnbs2MRxW0r3hBNOcMsi21+tbHnl77//PuUathywLZNbUlLilqc944wz3HK8yV5++WW3hLAtY2vLKN95551d9jUCAAAAAAAgy0IpM378eC1YsCBxe/XVVxPHTj31VD3xxBN64IEHNH36dH333Xfaf//9E8fD4bALpOrr6/X6669r2rRpLnA677zzEufMnz/fnbPTTjtp5syZOuWUU3TMMcfomWee6fKvFQAAAAAAAFkwp5RVSj366KMuLGpq+fLl6tevn+655x4dcMABru3TTz/V+uuvrzfeeEM//elP9Z///MetjmJh1YABA9w5Nv7/97//vX744QcVFBS4+zZZ5Ycffpi49sEHH6xly5bp6aefzqifkUjEPUd5eTkTXgIAAAAAALTCoqaVK1dq8ODB8nq92Tun1Jw5c1wni4qKtNVWW+myyy7T0KFD9e677yoYDGrXXXdNnGtD++xYPJSy7YYbbpgIpMzuu++uX//61/roo4+0ySabuHOSrxE/xyqmWlJXV+ducd9++63GjRvX4V87AAAAAABAT/X1119ryJAh2RlKbbnllm643ZgxY9zQvQsvvFDbbbedq2pauHChq3Tq1atXymMsgLJjxrbJgVT8ePxYa+esWLFCNTU1Ki4ubtYvC8asL+lezIqKig74ygEAAAAAAHomy1zWWWcdN+KsNd0aSk2aNClxf8KECS6kGjZsmO6///60YVFXOfvss3Xaaac1ezEtkCKUAgAAAAAAaFtbUyB1+0Tnyawqar311tPcuXM1cOBAN4G5zf2UzFbfs2PGtk1X44vvt3WOhUstBV+2Sl88gCKIAgAAAAAA6HhZFUpVVVXp888/16BBg7TZZpspEAjohRdeSByfPXu2vvrqKzf3lLHtrFmztGjRosQ5zz33nAuR4nNA2TnJ14ifE78GAAAAAAAA8iyUOv300zV9+nR98cUXev3117XffvvJ5/PpkEMOUWVlpaZOneqG0b300ktu4vOjjjrKhUk2ybmZOHGiC58OP/xw/e9//9Mzzzyjc845RyeccIKrdjLHH3+85s2bpzPPPNOt3nfDDTe44YGnnnpqd37pAAAAAAAAea1b55T65ptvXAC1ePFi9evXT9tuu63efPNNd99cffXVbunAyZMnu9XwbNU8C5XiLMB68skn3Wp7FlaVlpZqypQpuuiiixLnDB8+XE899ZQLoa699lo36/vf//53dy0AAAAAANB5wuGwgsFgd3cDHcxGtlkms6Y80Wg02iE96sFsonOr3Fq+fDnzSwEAAAAA0AaLGhYuXNhsnmj0HL169XLzeKebzDzTHKVbK6UAAAAAAEDPEw+k+vfvr5KSkjZXYUNuBY6rVq1KzO9t84KvLkIpAAAAAADQoUP24oFU3759u7s76ATFxcVua8GUfZ9XdyhfVq2+BwAAAAAAclt8DimrkELPVdLw/V2TOcMIpQAAAAAAQIdjyF7P5umA7y+hFAAAAAAAALocoRQAAAAAAAC6HKEUAAAAAADo8tX5fvvb32rEiBEqLCzUOuuso5/97Gd64YUXEue8/vrr2nPPPdW7d28VFRVpww031F//+lc3kXrTYWTxW2lpqUaPHq0jjzxS7777bsb9efnllxPX8Hq9qqys1CabbKIzzzxTCxYsSDn3ggsu0MYbb5zYt5Xozj77bI0cOdL1s1+/ftphhx302GOP6YsvvkjpX7rbnXfemfL8drNr2Nc+a9aslOe2r2vffffN+LVset10NzvH+pDumH09nYnV9wAAAAAAQJexoGabbbZRr1699Oc//9mFTTZZ9jPPPKMTTjhBn376qR555BEdeOCBOuqoo/TSSy+5c59//nkXEr3xxhu6//77U+Y0uuOOO7THHnuotrZWn332mW655RZtueWWuv3223XEEUdk3LfZs2eroqJCK1as0Hvvvacrr7xSt912mwturJ/pHH/88Xrrrbf0f//3fxo3bpwWL17sAjXbWkCUHGr95S9/0dNPP+2+ljgLwOzxyc//3Xff6YwzztBee+2luXPnqqCgQKvzWn7wwQcpz3/yySe7r81er7g+ffq469jz2vN35bxghFIAAAAAAKDL/OY3v3Fhx9tvv+0qm+LGjx+vo48+WtXV1Tr22GP185//3IVLccccc4wGDBjg2i2UOuiggxLHLJQZOHCgu7/uuutq4sSJmjJlik488URXNWTVVpno379/4lrrrbee9tlnH1cx9etf/1qvvvpq2sc8/vjjuvbaa11lU/z5N9tss8TxeL9MWVmZ/H5/SltLz3/KKae4r9VCugkTJmh1XksLs5Kfq7i4WHV1dWmf367TUr86C8P3AAAAAABAl1iyZImrFLIqnuQQJc4CmWeffdZVGZ1++unNjlvAZGHRvffe2+ZznXrqqVq5cqWee+651e6vhThWCfXaa69p0aJFac+xIOff//63e66Osnz5ct13333ufktVUpm8ltmOSikAAAAAANAlbChaNBrV2LFjWzzHht+Z9ddfP+1xe2z8nNbEn8OGpq2J5OtYJVNTVs112GGHqW/fvtpoo4207bbb6oADDnDD6tpryJAhbmvVYsYqpVp6rTJ5LdsbhFklV7LttttO//nPf9RZCKUAAAAAAECXsBClM85NeVwkKnmkSCh1QvTVFe9HS/Mrbb/99po3b57efPNNN5eUTTBuw/kuvPBCnXvuuZn3WdL0B/6tkqIivfn+u7r8xqt14w03ttmvjlJeXu7m0WpaKdaZCKUAAAAAAECXsJXxLNyxeZJaYsPzzCeffKKtt9662XFrtwnFWwp3oitqpZV1+viDma5t3QFDXLvHu3qTdtvzueusu27654xG3TxR226zjbbdehud+bszdMmll+jiiy/Wmaf+TgWBAjtJsv8PhiXrY3V9ok1FfkVX1btrDR8yVL0qKzVm5Gj98OMiHfyLAzX91f+m7Xsmr2V72KqDo0aN6pBrZfycXfpsAAAAAAAgb9lKb7vvvruuv/76xBC1ZMuWLXOTlNt5V111VdpJxefMmaNDDjmk5UDKbtGorr39JlWUl2vXTbd27RYIRVfWKrKiVpHlNYosa7gtXeXaTGRxtSI/VCmyyG4rVf3FIt1yw03a/qfbqG+wUJHvlseeIxhW5Otliny1VNGvl8Vu3yxX9Nvlin63XOsPXFehUEg1X/6g6PcrFV1UpegPVZKFT+GIoourFV2yStHlNZLPK60KNvt6fjPlGH348Ud65NFHVvu1zHaEUgAAAAAAoMtYiBIOh/WTn/xEDz30kAuZrBrpuuuu01ZbbeUm7b755pv12GOPuVX4/vfu+5o/e67+fuPNOvLIIzV5n/10wG57K/JjtQuOzJIvFmjhwoX68pM5eu6/L+kXx0/RvY89qOsvucpVHlnllIU/0eW10rIaybbxAMuO1cRCoUVff6eFX36jOZ98qvvu/5e223s3/bhksa6/+M+SDQcMRWIVTqZhu/NBP9PNd9+pd2fN1Bdff6V/v/iczvnzJdpp6+1UUdkrFjr5vVLAF7tvwwAL/VJRQCopkCJJ10xSUlyiYw45QhdccEGLQ/Xaei3bw57DXsOmt4j1r5MwfA8AAAAAADQTrQvFQhQLbIoDrsLHY2HK6l6vYbja8HWG6d033tall/9JvzvtNC1YuFD9+q6lTTfaRNf/6SpFFqzQ/lvtphfue1x/+ttV2n6nHVRbV6fR647QH35zqk6e+mt5qmLD3eKmnvob6dTfqKiwSGsPHKRttvip3nzseW264UbxJ4+FP6UFUjg255QLh+Jba7fJ1Xf6iRsSZxN+j1h3uHbbbVed9tuTNXDQoKRzC13I5BlU4dom7r2n7nr8AZ3zl0u0atUqDR48WHvvvbfOO+88eftWpvTTUxZ7rHdAeerr0sJ8VScceayu/vsNeuCBB3TggQc2Oz5ixAg3D9Sll16q3/3ud1qwYIH69eunzTbbTDfe2PJ8VOmsWLFCg+zrbMKuaSsMdgZPtKNnxuqB7BtTWVnpZqKvqKjo7u4AAAAAANCpbKhb6NnZCr38eSKU8u84Uv6JY+Sxip/4efUhRS0gWlnrttGVdapZtUpfV9Zr3cHrqMjXUAlkQZBN5r06EYQFNjanks+23pStm2vJ19AW8LkhdGmfw+ORZ0hli5OVd6do8rDDpiqK5LHbas6H1Zlqa2s1f/58DR8+XEVFRauVo1ApBQAAAAAAUiqkQs9/ptB/kibQrgnG9qOSd/RaCt7zngugVN98hbtwpV/ac+1YmOX3ZBgyxcKlRMiUdDzTQMatYFdemD7csXbLqrIv25H7+iqKXPfcUMJ45VR5YdYGUh2FUAoAAAAAADTyeWMVUmmEpn+uot3Wiw3tiwdSNpTNQp+yQrf19il0K8q5Kh+roEkJmmxOJctcPF0a7ux18P7676v/Tfu4P/zhD+7WnTwNfVdlUayizPat+z04kDKEUgAAAAAAwA3ZC3+0UN6hvRITfzdj7bUhFZ64nVToi4VRhf6UkClaWyvP/PnyWkhVVJgV4c7fb/u7ampqWlzFLht44gGUVYi5BvV4hFIAAAAAAOQxm88o9N95Cv13vu2p6MI9YhObpwumrL20QF4LfbJUunBn7bXX7tY+IT1CKQAAAAAA8lDkm2UKvTRX4Xe/kUIR1+bpXazoklVuUvOUOaUaWLutwmdD9oA1RSgFAAAAAECesMnAIx8tdGFU5LMfEu2edfvIv/Mo+TYaLI9NOD5xjGtva/U9YE0QSgEAAAAA0MPZxOTht750IVN0UVWs0euRb+PB8u80Wt7hqfMqWfDk33U9+XcfmwilrEKKQAodiVAKAAAAAIAeKrJ0lcLT5yn02vzGOaKs6mnrdeXbYaS8fUpafKynsCEysMnMDUP20MEIpQAAAAAA6GEiXyyJzRf1/rexVegsZFqrVP4dR8m31bDGwAnoRrwLAQAAAADoAaLhiCIfLFDopTmKzFuSaPeOXkv+nUbJu8GgxpXpgCxAKAUAAAAAQA6L1gQVev0Lhad/7lbOc3we+TZbJxZGrdOru7uINNZdd119+eWXzdp/85vf6Prrr1c+IJQCAAAAACAHRX6sVujluQq/+aVUG4o1lhbIv91w+bcbIU9lcXd3MadE64OS1yvV1kpFRVIkIk9BoNOeb8aMGQqHw4n9Dz/8ULvttpt+8YtfKF8QSgEAAAAAkCOi0aginy9280VFPvhOik0XJc/AclcV5dtiqDwFrJDXXtFgSKEX31L4v+9KNXVScaF8220m/y4/lSfQOdFJv379UvYvv/xyjRw5UjvssIPyBaEUAAAAAABZLhqKKPz+Nwq9OFfRr5cl2r3r95d/p9Fu6/EwX1Q8uJNVPWX+AIVenqHws683ttXUJfb9O24hZfraFgRW6/tQX1+vf/7znzrttNPy6vtIKAUAAAAAQJaKVtUp9NoXCr3yubS8NtYY8LqKKDdf1KCK7u5i9qkPqu7sazI7t7RYhef8KlYhlYa1+3f6ieouuVmqrmnzcoWXnSIVFrS3x3r00Ue1bNkyHXnkkconhFIAAAAAAGSZyMKVbohe+O2vpGDDvEMVhfJvP1L+bYfLU1bY3V3sETwVpYpWrYoN2UvH2qtrYudlEEqtrttuu02TJk3S4MGDlU8IpQAAAAAAOSNaF5J8XqkmKBUHpHBEnkJ/z5kv6tNFsfmiPv4+0e4ZUhmbL2rTIfIEmC+qTQWBWMVSpnw+N4dU2mDK2ivKVHDSLzN+7vb68ssv9fzzz+vhhx9WvukZP7kAAAAAgB4vGgwr9PxnCr38eSKU8u84Uv6JY3I6rLGvKzzjaxdGRResiDV6JO+Gg2JD9EatlVfzDK0p91q1Ywidrbpnk5qnzCnVwNrdKnyrMSQvU3fccYf69++vvfbaS/mGUAoAAAAAkBMVUi6Q+s+njY01wcS+f9f1srpiKl2Flw3LC03/XKH/zpeqGqp0CnzybbWuC9u8/cq6u9t5wVMQcKvsma5cfc9EIhEXSk2ZMkV+f/a+fztL/n3FAFpUEwrK7/WqKlinskChQpGIiv3tLz/tSrnYZ0O/u04u9hkAgHwWrQ8puqJOWlmn6Mpadz9aF5R/u5GxCqk0rN2/23qqu/NteSJRyaqmGm6ugqogft/b2F7Q9jnyezukQilthdcOI13wFH7vWxdIeXoXy2dtW68rT0nnVeUgPQue/DtvKf+uW0m1dVJRoRQJd2ogZWzY3ldffaWjjz5a+YhQKo/k4gezXOxzrqoLh3TXnPf0r88/0MpgncoDhTpo5ARNWW8zFfqy85+KXOyzod9dJxf7DAAdhd+jkC1zM9k8SaoLKWohkwubahvuN2xXNrStaLhv/WrCM7hCvo3WjvU1nZpg7FrfrVDku4bhbx3B8qjk4CoRXnkb99MFXBZsFcTue8cNUPjtrxV6ukmFV8N+4KCN3Qp7vo0Gy2PfD3RrxZRTVtLQ0vlDQidOnBj7GclT/EaeJ3Lxg1ku9jlXfwm0/tpr/fdPZyTa7DWP7x80YoJWhVv4BaCblPgCum/eB7oth/qcSb8PHrmRwtGo+/3H6/G4m/2f29q+u2/H7F7DePkseI8cPnrTrHuP52KfAaCj5PLvUbk6iXWu9XtN52ZyH6LjQZAFSYmAqTFcsvuKB1Hx1eMyZaFPeZFUXiiP3fqVyVNZFHtt0wVTxQF5Kork33W0tCrkvj73nMFw7H590n13iyja0JbuPMUzAttaW3040ZR4DTL5OsoKVLTVum6IXjrWXrTHWHn8hFHIT9n7ryRy+oOZWzVCUUWiUfcBOxKNJN23bWw/3hZNblNUvQqK9eD8WS1+cP/FiAnuly0Lfvwer/xenwJ23+uVz+Ptcb8E2mtj160JhVQbDqrW3U/dNrY33HfbkGoa2mvj5zccs61ds8Dr1792PdT1Nx1rt/fIL56/W8vqa5UNehUU6bHdp+j+HOpze/p9wDPTMu53PLxKF1zF76dsLdBK3E96XCshWEVBoa766V6tvkeOGL2pznjzKVWHgrGwzD1HvI+x+7ErJ/W94Xnd/yYdj5/b9Jx014u/Bk2vVeov0G/Gb9Vqn49cbzO998O3KvL7VREoUlmgQOUFhd3+b0iuhtsAskcuh/K5Ool1rvW7zbmZth/hqo1iFUwNQVNDuJQImuxYKNK+J7bKoYoiFzLFwqYieSoaQicLoNz9huNF/mZ/fLN+2+ua0u8G1q5IVP6fDFvNV6VJ4BaONoZV9S0EXCntsfmhXHiVFHR5ygoUra5vtcLL3exrBvIQoVQesA81bX2YPPX1J7S8vrZdQVLT47afuJ/Z3w3W6IP7QS0EDvYh2r5mC6nsw2XA62vY9zUEWN5m+y0diz82Hn41Xsv2fc3O37DPAD3x5ae6bXbzXwLtv20Th4zW9AXzVJMUEqUETA1BUXLgZPt1kXb+ZakdRlb01dK6GtfPdKx9WV2NBhWXu/5kA+tLrvU5037b8b5FpRmHUvaTZj937l60894jS9rotx3/pnqFPl+xWNnA9bl2Vat9/rF2lf78wSvN+lzqD6i8IaSyQM4CoYpAw7ag0AXNKbektiJf81+g863CAUD2/+531JjNlY3aDEp2GKlobcj+iuL23T+3sb9SNG4b/jjRrL2N42vyb3cmk2+7YV02qbXNdWRbd4sq2rBt1tbkPNtGm5wXv17sGsnXadIWSb5GxPWl4JBNWp+badf1VH/H21JVfdsvgIVHDeFS2qDJtg1B1JpWjtnjLeiL97OzAkD3fvDbzRurwFrD60UtvGulwsvdgDzFb7Z5wP7K3taHyYU1VV36YTJWlWGhUawiI7b1uvvDy/u0HTjUxwKHFfV1zQIw26+PhN2tKyXCtHnpfwm09iPW21T3zJ25RtU79qG32Bdw1R1FtrX9pPux/Xh7wH2ALY4f88fuFyadU+orUL/iUvehN91rbu1rFZdq2s4HKZsEI+Gc63Mm/bbvxT07H+zex67i0H6XTNyP2r1EOGzv/OS2xgrFxmrF+OMS9+OVjG1cK/m+T16tVVTS+utdVKLj1v+J6sNW2h77mbSsLHaVhr84uujM+hHLz9yR5HPSnrd617L3eN82+tynsFjlgQL1LyrVymC9C4WNVXvZTTXt//5aON00qGrcL3Bhl9sWNGyTzrHQyz5I5nKFg6HCC+h6C1et1P8WL9AHSxZoce0qnbTBNq3+HlUVrFfvwmJlHZ+3zaCk7pLnMgtKVkc8eUgXaJmGMCyl3YZmnblzm/2u/cNTndfvdrK5mdxwutbmZqqqk3d4X3c/FjY1hErJlUwWNJUVxuZS6sr+B3zuNfXvPjZ1qGQWVqQlhCOtV3hZWMjwPeQpQqk8YB8K2vowecK4n7pqi1hAFAuHksOieHjU/HjsfuPxpHPV9Hjj/bb+GtVm4FDUGDhYBZd96LGbPS6UZt9tra21Yw3H4/tBd27jsWC0od3tNz5P/Dr9ispctVlrvwSuCNZp8vAN3f3k8KgoHiK5UCkeODWGT/FQyT5od8YcQvYh0qowkj8Ex1m7fZ1WDZZNrE+51ueM++33yRf/S26WaOs9Yv9+7DR4pLJJW3228OqW7Scn2uxn2T6oraivjW2D8W2dqupjP78WtCS29an79hrYvwVL62vcbXUMLinXvbu0PpzWqqXilaT2b0Khz+e28X8jCr2NbSk3r6/T5yDL5QqvXAzTcrHPWHP2fZ674sdYCLV4of63ZIEW1VSl/JHMAqfWfo+yStCsFB/G1EpQ4ulTEpu7KfZXitTtmkrMIZQ8mVDrbI4jN4ytrX5XFCnaNJSykMtnN6/k9br7bpLreFvSfY9tvUltFmBYu7tG6mPcucltTa9d6G97bqbKYhX+aitlq0TFVXzIW5YHOl1V4QXkouz+DRFd8iHYPkhtO2i4cjVwsODL5/OqMAv+LW8rTLPKjF+N21LZxj7E2IdGkysfJnOxz4Z+Z2+f7d8U+yC3OtUDVr21KhRMhFT2XCvrG7bJt0RbvVYGLcSud23xKq1if0GblaJWBfHIFx+tVnWrBVOpYZUvKcjyNw+5Eu3pQ67kMKx/cZmrCL0tByu8cjFMy8U+Y/VYOP7hkoWuCsqCqI+Wfu/+vUlmf/AbXbmWNuo7SBP6DHLV4rn4h5vEMKZWghKrSmqJq6RNDpaaBlfGyokzOB7N9PH2N6RebQU8RSo8abuGEKoxWOqqxUrSaXNuJip3OlxOVngBXcATzee1BzO0YsUKVVZWavny5aqoqFAusl9ep332bk798pqLfU437CbumLFbZPWHstS/ute7v6Lmwl/dc7HPhn53nVzos1VfWkBVHax34c6k/9zeYrj91KSjdO2sV114FZ9zzm0Tt4b9SGw/NudY1wxf3vvpO1vs95N7HKnjXnnIzZdnH4bt3/HY1haq8KnAbj7b+pPux7buPK9fAQvH3MIWyccbzk9ua2iPX9+GVbb04S8X/93OxT4jM/Zr+cKalSlVUJ8vX9xsqgJbzGHDPgNjIVTfQRrfu79K/AU5/3tU2rmZGvgnjXUf6LNxNbuc7bdNzv7sbCp30Clqa2s1f/58DR8+XEVFRd3dHXTD9znTHCX7/nVEp7BfPuyXVJvYMvmDWbb+UpKrfc7FapJk8Q8x8UqRrPwrag/os6HfXScX+uxPqtJqc9hhNKrfb7xjuwKv2nhQFb+5wCqprVmwlRpu1TZtSwq9rG1ghpP4h6JRfVm1TN3BhVlNQq++hSW6duuftb4YyHqb6dwZz6o6lB1zwVgY8cdNd25ziOej8z907ys7vzRQoBJ/wN0vCRTEtv6AG1LfHRh22Mi+9jnLf0xUQX2weIEW1VY3O29QSXmiCsq2Iyr6tLlSaC7+HpWrQ5xytt9U7gDIAtn7XyXk5QezntDnXPwlEEDPDbctmCizWyfPIZPJXIDnbbqzW33UJsS38y0MC1rQFQm5fWuvT95GQon77vz448IN56eca/dDifNsfq9kLnhzC2A0hkv235Q2V5asXaW5Kxbn1MqSNsTzX/NmtdlnC6YSYVWT8CoWZtnxxhDLjpc22S9pZ8CV78MOLYibZUPxGqqgPlryfWL4bvJQvPUq+yWqoDbqM1D9isvy5veoXA1KcrbfOTY3E4Cep+f/1x/oBrn4SyCA7JGL4Xbb8xdGtH7vAV3WH1s5sr6N0CsSjbS5sqSt4njE6E27fEXXlliVV5srSxaVaFyv/upXVOoqvFaFbGhoMLYN1SeGdNq8RHb7UavWuF+N4VZjWBXft/evbSetM0bPfTNHt81+J+fmHVsdVtW4YNXKRBWU3SwobDqg1l4fG4oXr4Ia33tAj3od8ikoydV+A0B3yt7fbgEAyGO5Fm5n2/Blq9xxq5v6/CpXwwfENNoaLmnh1qShsWE52SKTIZ7nbrZL2sfaMasYs/nL4iGVBVO2b/erLagKNm939zMIuFqbd+zoMVvo/nmz0h6394yFUvs/e5cLMCsCRS6sqSiwleIKVeFWjCt0+/a+Srk1tHX2e6ytYYc2VPYzG4rXUAVlQ/F+SDMUb+3SChdAxaugRlT07bahlACA7nXjjTe62xdffOH2x48fr/POO0+TJk1SviCUAgAAeVvhlW1hWmf32ZMU1vVVyRr1oz0Bl1VKraivbXPeMeu7VRMt0MrVqiJrGlSl7heoPFAU2xYUpexbyNRaMNTSsMNfjt5Uj33xkV5ZMN+timfzryWzeZ/G9uqnCUmTkttQVgBAdorW10pev2R/VLB/ryMheQo6b6L2IUOG6PLLL9fo0aPdf1enTZumffbZR++//74LqPIBq+/lyep7AAAgt1dpzPU+2xDKPf7d8sqST+95tBvutqyuxn1NK4K1Dds6VdXXxbbBpG19bGvXW9NfZi2OsmGH6aqwDhwxQS9/93nKsMO4o8dsrvV79dcZb/078XVYAOWqoPoOcsMoi7L4ewIAnSUXV9+LBusVeukhhV97UqqplopL5dtmb/l3mixPJ8/NmaxPnz7685//rKlTpyrbsfoeAABAHg6XzMU+tzXvmB0fWtbL3drDhlhapVY8pFrREFQ1BldJAVd9UtDVcK5VQVmoZe12S67SsmGHp0/YvsVhhw/Mm6WnJh2l8zfdRWN799fw8j4MxQOALOBqb1qozk0rElHolccUfv5fjW011Yl9//b7SN4M54kLFLrK5PYKh8N64IEHVF1dra222kr5glAKAAAAOTtU0kIgG35nt9VhE98nQqykMMva/B6v27Y27NAq1vYatv5qPTcAoJPYHx3OOTizc0srVHj2LbEKqTSs3b/jfqq77DipekWblyu85D6pHUP+Zs2a5UIoqzoqKyvTI488onHjxilfEEoBAAAgb+cdK/D51NdX4lY1bGnYYWurHdrXAADIXZ7y3opWLY8N2UvH2qtWxM7LIJRqrzFjxmjmzJlumNuDDz6oKVOmaPr06XkTTBFKAQAAoMv0xGGH2f41AEDesVVZrWIpU/bveHFp+mDK2it6q+DEKzJ+7vYoKCjQqFGj3P3NNttMM2bM0LXXXqubb75Z+YBQCgAAAOhBKzQCQL5zczq1Ywidrbpnk5qnzCnVwNoVCXfqKnzJIpGI6uraMR9WjuO/ogAAAECODTsEAHQcC5xslT3TlavvnX322Zo0aZKGDh2qlStX6p577tHLL7+sZ555RvmC/5ICAAAAPWzYIQCgfSx4sgnN/Tv/QqqtlopKpUio0wIps2jRIh1xxBFasGCBKisrNWHCBBdI7bbbbsoXhFIAAAAAACDvJYbolVV2SWRy2223Kd95u7sDAAAAAAAAyD+EUgAAAAAAAOhyhFIAAAAAAADocoRSAAAAAAAA6HKEUgAAAAAAAOhyhFIAAAAAAADocoRSAAAAAAAA6HKEUgAAAAAAAOhyhFIAAAAAAADocoRSAAAAAAAA6HKEUgAAAAAAAF0sHA7r3HPP1fDhw1VcXKyRI0fq4osvVjQaVb7wd3cHAAAAAAAAulskWCOP169I7Up5i8oVjYTkDRR32vNdccUVuvHGGzVt2jSNHz9e77zzjo466ihVVlbqpJNOUj4glAIAAAAAAHktEqrTsremafm79ylSt1LewnJVbnawev30KHn9hZ3ynK+//rr22Wcf7bXXXm5/3XXX1b333qu3335b+YJQCgAAAAAA9Bg2/C0arG3H+REtn3GXlr5+a6LNgqn4fuUWh8vjyWz2I0+gSB6PJ6Nzt956a91yyy367LPPtN566+l///ufXn31Vf31r39VviCUAgAAAAAAPYYFUvOv2Tajc73FvTTsV0+6Cql0rL3XT6boy5v3VqRmWZvXG37Kq/IUZDbk76yzztKKFSs0duxY+Xw+N8fUpZdeqsMOO0z5glAKAAAAAADkJX/pWgqvWuIqo9Kx9nDNUndefQahVHvcf//9uvvuu3XPPfe4OaVmzpypU045RYMHD9aUKVOUDwilAAAAAABAj2FD6KxiKePzfX43h1S6YMra/WX9tPYv78z4uTN1xhlnuGqpgw8+2O1vuOGG+vLLL3XZZZcRSgEAAAAAAOQam9Mp0yF08VX3bFLz5Dml4qzdrcLXjutlatWqVfJ6U+eqsmF8kUhE+YJQCgAAAAAA5C1voNitsme6cvW9n/3sZ24OqaFDh7rhe++//76b5Pzoo49Wvshs+vgucPnll7s008ZPxtXW1uqEE05Q3759VVZWpsmTJ+v7779PedxXX33llk8sKSlR//79XflbKBRKOefll1/WpptuqsLCQo0aNUp33plZ2R0AAAAAAOj5LHjqteUUrXvic1r3xOfd1iY476xAyvzf//2fDjjgAP3mN7/R+uuvr9NPP12/+tWvdPHFFytfZEWl1IwZM3TzzTdrwoQJKe2nnnqqnnrqKT3wwAOqrKzUiSeeqP3331+vvfaaO24z01sgNXDgQL3++utasGCBjjjiCAUCAf3pT39y58yfP9+dc/zxx7sJxF544QUdc8wxGjRokHbfffdu+XoBAAAAAED2VUwZX0lvt/X4Ap36fOXl5brmmmvcLV91e6VUVVWVW+7w1ltvVe/esW+8Wb58uW677TZXurbzzjtrs8020x133OHCpzfffNOd8+yzz+rjjz/WP//5T2288caaNGmSSxSvv/561dfXu3NuuukmDR8+XFdddZVLHi3YsiTy6quv7ravGQAAAAAAIN91eyhlw/OskmnXXXdNaX/33XcVDAZT2seOHevGWr7xxhtu37Y2O/2AAQMS51j104oVK/TRRx8lzml6bTsnfo106urq3DWSbwAAAAAAAOghw/fuu+8+vffee274XlMLFy5UQUGBevXqldJuAZQdi5+THEjFj8ePtXaOBU01NTUqLm4+g74tv3jhhRd2wFcIAAAAAACArKqU+vrrr3XyySe7eZ6KioqUTc4++2w3fDB+s74CAAAAAACgB4RSNjxv0aJFblU8v9/vbtOnT9d1113n7ls1k80LtWzZspTH2ep7NrG5sW3T1fji+22dU1FRkbZKytgqfXY8+QYAAAAAAIAeEErtsssumjVrlmbOnJm4bb755m7S8/h9W0XPVsuLmz17tr766itttdVWbt+2dg0Lt+Kee+45FyKNGzcucU7yNeLnxK8BAAAAAACAPJpTypY+3GCDDVLaSktL1bdv30T71KlTddppp6lPnz4uaPrtb3/rwqSf/vSn7vjEiRNd+HT44YfryiuvdPNHnXPOOW7ydKt2Mscff7z+9re/6cwzz9TRRx+tF198Uffff7+eeuqpbviqAQAAAAAA0O0Tnbfl6quvltfr1eTJk92KeLZq3g033JA47vP59OSTT+rXv/61C6ss1JoyZYouuuiixDnDhw93AdSpp56qa6+9VkOGDNHf//53dy0AAAAAAAB0D080Go1203PnDFupr7Ky0k16zvxSAAAAAAC0rLa2VvPnz3dFItm2sBm65vucaY7SbXNKAQAAAAAAIH8RSgEAAAAAAHSxCy64QB6PJ+U2duxY5ZOsnlMKAAAAAACgK4SDNfJ4/QrVr5S/oFzRSEi+QHGnPuf48eP1/PPPJ/b9/vyKafLrqwUAAAAAAGgiEqrTN+9P03ez7lO4bqV8heUavOHBWmfTo+T1F3ba8/r9fg0cOFD5ilAKAAAAAAD0GLaeWyRU247zI/p25l36+p1bE20WTMX31974cHk8mc1+5PUXuWF4mZozZ44GDx7sJgrfaqutdNlll2no0KHKF4RSAAAAAACgx7BA6o1bt83oXH9RL21x+JOuQiodax+yyRTNuGtvhWqXtXm9rY59NeMhf1tuuaXuvPNOjRkzRgsWLNCFF16o7bbbTh9++KHKy8uVDwilAAAAAABAXiooWUvBmiWuMiodaw/WLHXnZRJKtcekSZMS9ydMmOBCqmHDhun+++/X1KlTlQ8IpQAAAAAAQI9hQ+isYilTNrm5zSGVLpiy9oLSftpo8p0ZP/fq6tWrl9Zbbz3NnTtX+SKzQZEAAAAAAAA5wOZ0siF0md5slT2b1Dwda4+vwpfJrT3zSTVVVVWlzz//XIMGDVK+IJQCAAAAAAB5y8IkW2Vvnc2PdZVRrq2w3O1be6ZzRLXX6aefrunTp+uLL77Q66+/rv32208+n0+HHHKI8gXD9wAAAAAAQF7z+gvdhObrbDZV4foq+QrKXIWUtXeWb775xgVQixcvVr9+/bTtttvqzTffdPfzBaEUAAAAAADIe/GKKG9x73hDpz7fffelX/EvnzB8DwAAAAAAAF2OUAoAAAAAAABdjlAKAAAAAAAAXY5QCgAAAAAAAF2OUAoAAAAAAABdjlAKAAAAAAAAXY5QCgAAAAAAAF2OUAoAAAAAAABdjlAKAAAAAAAAXY5QCgAAAAAAAF2OUAoAAAAAAKAbfPvtt/rlL3+pvn37qri4WBtuuKHeeecd5Qt/d3cAAAAAAACgu4WCNfJ6/QrWr1SgoFyRSEj+QHGnPd/SpUu1zTbbaKeddtJ//vMf9evXT3PmzFHv3r2VLwilAAAAAABAXguH6jRn1jR9/vG9iVBq5LhDtN6Eo+TzF3bKc15xxRVaZ511dMcddyTahg8frnzC8D0AAAAAANBjRKNRV/WU6S1YX63PPrhDn868xQVSxra2b+12PNNr2XNn6vHHH9fmm2+uX/ziF+rfv7822WQT3XrrrconVEoBAAAAAIAeIxyq1RN3bZPRuQVFvbT7L55yFVLpWPvoDafomQf2Un3tsjav97PDX8t4yN+8efN044036rTTTtMf/vAHzZgxQyeddJIKCgo0ZcoU5QNCKQAAAAAAkJeKitdSXe2SRIVUU9ZeV7vUnZdJKNUekUjEVUr96U9/cvtWKfXhhx/qpptuIpQCAAAAAADINT5/katYypRNbm5zSKULpqy9uKSfdth7WsbPnalBgwZp3LhxKW3rr7++HnroIeULQikAAAAAANBjeDyedq2aZ3NB2aTmNodUU9beWavwbbPNNpo9e3ZK22effaZhw4YpXxBKAQAAAACAvGWBk62yZ7py9b1TTz1VW2+9tRu+d+CBB+rtt9/WLbfc4m75glAKAAAAAADkNQuebELzMRtNVTBYpUCgzFVIdVYgZbbYYgs98sgjOvvss3XRRRdp+PDhuuaaa3TYYYcpXxBKAQAAAACAvBcfolfo6+22Xl+g059z7733drd85e3uDgAAAAAAACD/EEoBAAAAAACgyxFKAQAAAAAAoMsRSgEAAAAAAKDLEUoBAAAAAACgyxFKAQAAAAAAoMsRSgEAAAAAAKDLEUoBAAAAAACgyxFKAQAAAAAAoMsRSgEAAAAAAKDLEUoBAAAAAAB0g5UrV+qUU07RsGHDVFxcrK233lozZsxQviCUAgAAAAAAeS8YqlE4HFRN7RK3tf3Odswxx+i5557TXXfdpVmzZmnixInadddd9e233yof+Lu7AwAAAAAAAN0pFK7TzI+nadbse1Vfv1IFBeXacMwh2mT8UfL7CjvlOWtqavTQQw/pscce0/bbb+/aLrjgAj3xxBO68cYbdckll6inI5QCAAAAAAA9RjQaVShc247zI/rfJ3fp3Vm3JNosmIrvb7T+4fJ4Mhto5vcVyePxZHRuKBRSOBxWUVFRSrsN43v11VeVDwilAAAAAABAj2GB1G3/2iajc4sKe+mwfZ9yFVLpWPvG46bo7kf3Um3dsjavN/Wg1xTwF2f03OXl5dpqq6108cUXa/3119eAAQN077336o033tCoUaOUD5hTCgAAAAAA5KWS4rXcHFJWGZWOtdfWLnXndYa77rrLVXatvfbaKiws1HXXXadDDjlEXm9+xDVUSgEAAAAAgB7DhtBZxVKmvB6/m0MqXTBl7SXF/bTf7tMyfu72GDlypKZPn67q6mqtWLFCgwYN0kEHHaQRI0YoHxBKAQAAAACAHsPmdMp0CJ2xVfZsUvPkOaXirD0SDbXrequjtLTU3ZYuXapnnnlGV155pfIBoRQAAAAAAMhbFjjZKnumK1ffMxZA2fC9MWPGaO7cuTrjjDM0duxYHXVUrD89HaEUAAAAAADIaxY82YTmm46fqvpglQoCZa5CqjMDKbN8+XKdffbZ+uabb9SnTx9NnjxZl156qQKBgPIBoRQAAAAAAMh78SF6xb7ebutT5wdDBx54oLvlq/yYzh0AAAAAAABZhVAKAAAAAAAAXY5QCgAAAAAAAF2OUAoAAAAAAABdjlAKAAAAAAAAXY5QCgAAAAAAAF2OUAoAAAAAAABdjlAKAAAAAAAAXY5QCgAAAAAAAF2OUAoAAAAAAABdjlAKAAAAAACgi73yyiv62c9+psGDB8vj8ejRRx9VviGUAgAAAAAAea8+VKNQJKiq2iVua/udqbq6WhtttJGuv/565St/d3cAAAAAAACgOwXDdZo+e5pen3uvaoIrVRwo19ajDtGOY49SwFfYKc85adIkd8tnhFIAAAAAAKDHiEajCoZrMz4/Eo3ov5/dpRc+uSXRZsFUfH+79Q6X15PZQLOAr8gNxUNmCKUAAAAAAECPYYHUeY9uk9G5pQW99Ps9n3IVUulY+w5jpuiKf++l6vplbV7von1fU4G/uN19zlftnlPq66+/1jfffJPYf/vtt3XKKafollsaE0UAAAAAAIBsV1a0lqrqlrjKqHSsvbpuqTsPWVApdeihh+q4447T4YcfroULF2q33XbT+PHjdffdd7v98847rxO6CQAAAAAAkNkQOqtYypTX63dzSKULpqy9vLifTth5WsbPjU6slPrwww/1k5/8xN2///77tcEGG+j11193odSdd97Z3ssBAAAAAAB0GJvTyYbQZXqLREJuUvN0rN2OZ3ot5pPq5EqpYDCowsLYzPPPP/+8fv7zn7v7Y8eO1YIFC9p7OQAAAAAAgG5jYZKtsme6cvW9qqoqzZ07N7E/f/58zZw5U3369NHQoUOVD9odStlQvZtuukl77bWXnnvuOV188cWu/bvvvlPfvn07o48AAAAAAACdxoInm9B8p/WnqjZYpaJAmauQ6qxAyrzzzjvaaaedEvunnXaa206ZMiVvRqK1O5S64oortN9+++nPf/6ze6E22mgj1/74448nhvUBAAAAAADkkviqeWWFvWMN3kCnPt+OO+6oaDSqfOZfnRftxx9/1IoVK9S7d8M3SnKTn5eUlHR0/wAAAAAAANADtXuic2NJ3rvvvqubb75ZK1fGZqcvKCgglAIAAAAAAEDnVEp9+eWX2mOPPfTVV1+prq5Ou+22m8rLy92wPtu3+aYAAAAAAACADq2UOvnkk7X55ptr6dKlKi6Ojbc0Ns/UCy+80K5r3XjjjZowYYIqKircbautttJ//vOfxPHa2lqdcMIJbgL1srIyTZ48Wd9//33KNSwcs0nXrUqrf//+OuOMMxQKhVLOefnll7Xpppu6VQNHjRqVNxOGAQAAAAAA9JhQ6r///a/OOeccN1wv2brrrqtvv/22XdcaMmSILr/8cjcU0Gad33nnnbXPPvvoo48+csdPPfVUPfHEE3rggQc0ffp0t8Lf/vvvn3h8OBx2gVR9fb1ef/11TZs2zQVO5513XsqSinaOzWhvSyuecsopOuaYY/TMM8+090sHAAAAAABAdw3fi0QiLgxq6ptvvnHD+NrjZz/7Wcr+pZde6qqn3nzzTRdY3XbbbbrnnntcWGXuuOMOrb/++u74T3/6Uz377LP6+OOP9fzzz2vAgAHaeOONdfHFF+v3v/+9LrjgAhec2XDC4cOH66qrrnLXsMe/+uqruvrqq7X77ru398sHAAAAAABAd1RKTZw4Uddcc01i3+PxqKqqSueff7723HPP1e6IBV333Xefqqur3TA+q54KBoPaddddE+eMHTtWQ4cO1RtvvOH2bbvhhhu6QCrOgiZbGTBebWXnJF8jfk78GgAAAAAAAMiBSimrOLJQZ9y4cW7Op0MPPVRz5szRWmutpXvvvbfdHZg1a5YLoexaNm/UI4884q5tQ+2s0qlXr14p51sAtXDhQnfftsmBVPx4/Fhr51hwVVNTkzIvVpxN2G63ODsXAAAAAAAA3RhK2bC6//3vf/rXv/7ltlYlNXXqVB122GFpA562jBkzxgVQy5cv14MPPqgpU6a4+aO602WXXaYLL7ywW/sAAAAAAADQk/lX60F+vwuh7LamrBrKVsQzm222mWbMmKFrr71WBx10kJvAfNmyZSnVUrb63sCBA91927799tsp14uvzpd8TtMV+2zfVvtrKUQ7++yzddppp6VUSq2zzjpr/LUCAAAAAABgNeeUshXunnrqqcT+mWee6UKjrbfeWl9++aXWlE2kbkPnLKAKBAJ64YUXEsdmz56tr776yg33M7a14X+LFi1KnPPcc8+5wMmGAMbPSb5G/Jz4NdIpLCx010i+AQAAAAAAdJRXXnnFLQA3ePBgN1/3o48+mnI8Go3qvPPO06BBg1xRjc2XbdMn5XUo9ac//SlRYWSThf/tb3/TlVde6eaUOvXUU9t1LatIsm/CF1984cIl23/55ZddBVZlZaUbFmgVSy+99JKb+Pyoo45yYZKtvBefdN3Cp8MPP9wNJXzmmWd0zjnn6IQTTnDBkjn++OM1b948F559+umnuuGGG3T//fe3u68AAAAAAKDnqgnVKhgJakndUre1/c5UXV2tjTbaSNdff33a45a1XHfddbrpppv01ltvqbS01M3xbXNy5+3wva+//jox3M5SvAMOOEDHHXecttlmG+24447tupZVOB1xxBFasGCBC6EmTJjggqXddtvNHb/66qvl9Xo1efJkVz1lL76FSnE+n09PPvmkfv3rX7uwyr5BNifVRRddlDhn+PDhrrLLQigbFmhzYv3973931wIAAAAAAKgL12va5/fo3i8e0spglcoDZTpk3ck6atQvVegr6JTnnDRpkrulY1VS11xzjSu82WeffVzbP/7xD7dwm2UxBx98sPIylLIV8hYvXqyhQ4fq2WefTcy9VFRU5Faza4/bbrut1eN2TUsMW0oNzbBhw/Tvf/+71etYWPb++++3q28AAAAAACD3WKBTG868migSjeiuef/SLXOmJdosmIrvHz7iIHk9mQ00K/IVuaF4a2r+/PlauHChG7IXZ8U8W265pRu1lrehlFUxHXPMMdpkk0302Wefac8993TtH330kdZdd93O6CMAAAAAAEBGLJDa5uk9Mjq3V0Glntr5X65CKh1rnzLyEO314kFaVr+8zeu9tsfTKvanX1StPRYuXOi2VhmVzPbjx/JyTimrWrKhcj/88IMeeugh9e3b17XbnE+HHHJIZ/QRAAAAAACgw61V2FdL6pe5yqh0rH1p/TJ3HrKgUspW2rPJzZu68MILO6pPAAAAAAAAq8WG0FnFUqb8Xr+bQypdMGXt/YrW0rRtbsj4uTvCwIED3fb77793q+/F2f7GG2+svA2lzLJly/T222+7icojkUii3cZN2kp4AAAAAAAA3cGyifYMobNV9mxS8+Q5peKsPRQJd8iQvPYYPny4C6ZeeOGFRAi1YsUKtwqfLfaWt6HUE088ocMOO0xVVVWqqKhImcCLUAoAAAAAAOSSYn+RW2XPdOXqe1VVVZo7d27K5OYzZ85Unz593OJyp5xyii655BKNHj3ahVTnnnuuBg8erH333Vc9hSdq09K3w3rrrecmN//Tn/6kkpIS5QNLI22W++XLl7sgDgAAAAAApFdbW+sCFgtSioo6ZjhbV7CKKb/Xp6pgtcoCpQ0VUp3X/5dfflk77bRTs/YpU6bozjvvdKsInn/++brlllvciLVtt91WN9xwg8tlsv37nGmO0u5QqrS0VLNmzdKIESOULwilAAAAAADo2aEUuj6Uavfqe7vvvrveeeed9j4MAAAAAAAAWP05pfbaay+dccYZ+vjjj7XhhhsqEAikHP/5z3/e3ksCAAAAAAAgz7Q7lDr22GPd9qKLLmp2zCY6D4fDHdMzAAAAAAAA9FjtDqUikUjn9AQAAAAAAAB5o91zSjWd1AoAAAAAAADo9FDKhuddfPHFWnvttVVWVqZ58+a59nPPPVe33XZbuzsAAAAAAACA/NPuUOrSSy/VnXfeqSuvvFIFBQWJ9g022EB///vfO7p/AAAAAAAA6IHaHUr94x//0C233KLDDjtMPp8v0b7RRhvp008/7ej+AQAAAAAAoAdqdyj17bffatSoUWknQA8Ggx3VLwAAAAAAAPRg7Q6lxo0bp//+97/N2h988EFtsskmHdUvAAAAAACAvHD55ZfL4/HolFNOUT7xt/cB5513nqZMmeIqpqw66uGHH9bs2bPdsL4nn3yyc3oJAAAAAADQA82YMUM333yzJkyYoHzT7kqpffbZR0888YSef/55lZaWupDqk08+cW277bZb5/QSAAAAAACgE9WE6hWMhLWkrsptbb+zVVVVuTm7b731VvXu3Vv5pt2VUma77bbTc8891/G9AQAAAAAA6GJ14aD+Mfe/um/e61oZrFV5oEgHj9haR47eXoW+QKc97wknnKC99tpLu+66qy655BLlG//qlJXZsL0tt9wypf2tt95yq/FtvvnmHdk/AAAAAACAjEWjUdWGM1+ILRKN6J+fv6pbZ7+UaLNg6tbZL7r7vxy5jbyezAaaFfkCbm6oTNx333167733XM6Sr/yrk+KdeeaZzUIpm2PqiiuucOEUAAAAAABAd7BAarunLszo3F4FJXpitzN037w30h63yqkjRm2nnz33Zy2rX9Xm9f671/kq9he0ed7XX3+tk08+2Y1CKyoqUr5q95xSH3/8sTbddNNm7bbynh0DAAAAAADIBX0Ly90cUlYZlY61L62vdud1pHfffVeLFi1y+Yrf73e36dOn67rrrnP3w+Gw8kG7K6UKCwv1/fffa8SIESntCxYscC8cAAAAAABAd7EhdFaxlCm/1+vmkEoXTFl7v6Jy3bn98Rk/dyZ22WUXzZo1K6XtqKOO0tixY/X73//eTY+UD9qdIk2cOFFnn322HnvsMVVWVrq2ZcuW6Q9/+AOr7wEAAAAAgG5lczplMoQuzlbZs0nN43NIJbP2UCTSrutlory8XBtssEFKW2lpqfr27dusvSdrdyj1l7/8Rdtvv72GDRvmhuyZmTNnasCAAbrrrrs6o48AAAAAAACdwgInW2XPdPXqe/nOE7Vp6dupurpad999t/73v/+puLhYEyZM0CGHHKJAoGd+o1asWOGqwpYvX66Kioru7g4AAAAAAFmrtrZW8+fP1/Dhw3NqEm+rmPJ7faoK1qosUKRQJNzhFVL58n1ekWGOslqTQFlJ2XHHHbc6DwUAAAAAAMg68QCqd2Gp2wa8+TGvU3fKKJR6/PHHNWnSJFcJZfdb8/Of/7yj+gYAAAAAAIB8DqX23XdfLVy4UP3793f3W5tMLF+WLQQAAAAAAEAnh1KRSCTtfQAAAAAAAGB1eNVBvvnmG+aZAgAAAAAAQNeGUosXL9Ztt93WUZcDAAAAAABAD9ZhoRQAAAAAAACQKUIpAAAAAAAAdDlCKQAAAAAAAGTn6ntm//33b/X4smXLOqI/AAAAAAAAyAMZV0pVVla2ehs2bJiOOOKIzu0tAAAAAABAD3DZZZdpiy22UHl5ufr37699991Xs2fPVj7JuFLqjjvu6NyeAAAAAAAA5Inp06frhBNOcMFUKBTSH/7wB02cOFEff/yxSktLlQ8yDqUAAAAAAAB6qppQUH6vV1XBOpUFChWKRFTsD3Ta8z399NMp+3feeaermHr33Xe1/fbbKx8QSgEAAAAAgLxWFw7prjnv6V+ff6CVwTqVBwp10MgJmrLeZir0dU10snz5crft06eP8gWhFAAAAAAA6DGi0ahqw6GMz49Eo7p77vv6+6czEm0WTMX3Dxu1ibweT0bXKvL55cnw3GSRSESnnHKKttlmG22wwQbKF4RSAAAAAACgx7BAaocnbs7o3F4FRXps9ymuQiodaz989Kba55lpWlZf2+b1pv/sV6s15O+EE07Qhx9+qFdffVX5JKPV9zbddFMtXbrU3b/ooou0atWqzu4XAAAAAABAp+pbVKqldTWuMioda7fjdl5nOfHEE/Xkk0/qpZde0pAhQ5RPMqqU+uSTT1RdXa3evXvrwgsv1PHHH6+SkpLO7x0AAAAAAEA72BA6q1jKlE1ubnNIpQumrL1fcalu3+GAjJ+7PcMMf/vb3+qRRx7Ryy+/rOHDhyvfZPRqbbzxxjrqqKO07bbbuhftL3/5i8rKytKee95553V0HwEAAAAAADJiczq1Zwidrbpnk5onzykVZ+2dtQrfCSecoHvuuUePPfaYysvLtXDhQtdeWVmp4uJi5QNP1FKmNsyePVvnn3++Pv/8c7333nsaN26c/H5/2m+8He9pVqxY4d4UNhN+RUVFd3cHAAAAAICsVVtbq/nz57vKn6KiIuXK6nvTPnu3S1ff87QwIfodd9yhI488Urn8fc40R8kolErm9Xpdete/f3/lC0IpAAAAAAB6bigVr5iyoXxVwXqVBQo6rUKqp6jtgFDKvzrLFAIAAAAAAPQk8QCqd2Fs6FzA6+vmHvV8q1WDZsP4rrnmGjcBurHhfCeffLJGjhzZ0f0DAAAAAABAD+Rt7wOeeeYZF0K9/fbbmjBhgru99dZbGj9+vJ577rnO6SUAAAAAAADyu1LqrLPO0qmnnqrLL7+8Wfvvf/977bbbbh3ZPwAAAAAAAPRA7a6UsiF7U6dObdZ+9NFH6+OPP+6ofgEAAAAAAKAHa3co1a9fP82cObNZu7Xl04p8AAAAAAAA6MLhe8cee6yOO+44zZs3T1tvvbVre+2113TFFVfotNNOW4OuAAAAAAAAIF+0O5Q699xzVV5erquuukpnn322axs8eLAuuOACnXTSSZ3RRwAAAAAAAOR7KOXxeNxE53ZbuXKla7OQCgAAAAAAAOi0UCoZYRQAAAAAAAC6ZKJzAAAAAAAArJlXXnlFP/vZz9yUSDYq7dFHH1W+IZQCAAAAAADoYtXV1dpoo410/fXXK1+t0fA9AAAAAACAnqAmFJLf61FVMKiyQEChSFTF/s6LTSZNmuRu+axdlVLBYFC77LKL5syZ03k9AgAAAAAA6EJ14bDu+uxjTXrqYe3x1ENua/vWjs7TrsgvEAjogw8+6LzeAAAAAAAArIFoNKradoRJkWhUd8/5RLd9OivRtjJYn9g/bPT68no8GV2ryOdz80MhM+2uQ/vlL3+p2267TZdffnl7HwoAAAAAANCpLJDa8fF/ZXRur4JCPbrHvrr/89lpj1v74euN075PP6pl9XVtXu/lnx/UqUP+epp2v1KhUEi33367nn/+eW222WYqLS1NOf7Xv/61I/sHAAAAAADQKfoWFWtpXa2rjErH2u24nZdJKIVODqU+/PBDbbrppu7+Z599lnKMEjUAAAAAANCdbAidVSxlyiY3Lw8UpA2mrL1fcbFu23H3jJ8bnRhKvfTSS+19CAAAAAAAQJewgpn2DKGzVfcOHDkmZU6pOGvvrFX4qqqqNHfu3MT+/PnzNXPmTPXp00dDhw5VPljtV9VeuM8//1zbb7+9iouL3URiVEoBAAAAAIBcYoHTlDHjE3NIWcWUVUhZIGXthZ1U/fTOO+9op512SuyfdtppbjtlyhTdeeedygftDqUWL16sAw880FVMWQg1Z84cjRgxQlOnTlXv3r111VVXdU5PAQAAAAAAOoEFTzah+VFjx6sqGFRZIOAqpDorkDI77rijK/DJZ972PuDUU09VIBDQV199pZKSkkT7QQcdpKeffrqj+wcAAAAAANAlFVMBr0+9C4vcllX0Ol+7X+Fnn31WzzzzjIYMGZLSPnr0aH355Zcd2TcAAAAAAAD0UO2ulKqurk6pkIpbsmSJCgsLO6pfAAAAAAAA6MHaHUptt912+sc//pHYt3mlIpGIrrzyypQJugAAAAAAAIAOG75n4dMuu+ziZomvr6/XmWeeqY8++shVSr322mvtvRwAAAAAAADyULsrpTbYYAN99tln2nbbbbXPPvu44Xz777+/3n//fY0cObJzegkAAAAAAIAeZbWmkq+srNQf//jHju8NAAAAAAAA8sJqhVJLly7Vbbfdpk8++cTtjxs3TkcddZT69OnT0f0DAAAAAABAD9Tu4XuvvPKK1l13XV133XUunLKb3R8+fLg7BgAAAAAAAHR4KHXCCSfooIMO0vz58/Xwww+727x583TwwQe7Y+1x2WWXaYsttlB5ebn69++vfffdV7Nnz045p7a21l23b9++Kisr0+TJk/X999+nnPPVV19pr732UklJibvOGWecoVAolHLOyy+/rE033VSFhYUaNWqU7rzzzvZ+6QAAAAAAAOiuUGru3Ln63e9+J5/Pl2iz+6eddpo71h7Tp093gdObb76p5557TsFgUBMnTnSTp8edeuqpeuKJJ/TAAw+487/77js3sXpcOBx2gZStBPj6669r2rRpLnA677zzEudYgGbn7LTTTpo5c6ZOOeUUHXPMMXrmmWfa++UDAAAAAAB0iG+//Va//OUvXSFOcXGxNtxwQ73zzjvKF+2eU8qqjWwuqTFjxqS0W9tGG23Urms9/fTTKfsWJlml07vvvqvtt99ey5cvd3NX3XPPPdp5553dOXfccYfWX399F2T99Kc/1bPPPquPP/5Yzz//vAYMGKCNN95YF198sX7/+9/rggsuUEFBgW666SY3vPCqq65y17DHv/rqq7r66qu1++67t/clAAAAAAAAPUxNKCS/16uq+qDKCgIKRSIq9q/WVNwZWbp0qbbZZhtXQPOf//xH/fr105w5c9S7d2/li4xe3Q8++CBx/6STTtLJJ5/sqqIsFDIWEF1//fW6/PLL16gzFkKZ+ITpFk5Z9dSuu+6aOGfs2LEaOnSo3njjDff8trUk0QKpOAuafv3rX+ujjz7SJpts4s5Jvkb8HKuYAgAAAAAA+a0uHNY/Z8/T/XPna2UwpPKAXweOGq4jxo5UYdJIsY50xRVXaJ111nHFN3FWUJNPMgqlrPrI4/EoGo0m2s4888xm5x166KFuvqnVEYlEXEhkKeEGG2zg2hYuXOgqnXr16pVyrgVQdix+TnIgFT8eP9baOStWrFBNTY0rkUtWV1fnbnF2HgAAAAAAyH6WXdSGwxmfH4lGdfdn83X7J3MSbRZM3dawf+h6w+X1eDK6VpHP5/KTTDz++OOuYOYXv/iFm65o7bXX1m9+8xsde+yxyhcZhVI2J1Nns7mlPvzwQzesrrvZBOwXXnhhd3cDAAAAAAC0kwVSOz2a2RzSvQoK9MieO+mBuelzD6uc+uWYEdrv3y9pWX19m9d7ad/dMx7yN2/ePN14441uju4//OEPmjFjhhudZsU5U6ZMUT7I6JUaNmxYp3bixBNP1JNPPqlXXnlFQ4YMSbQPHDjQTWC+bNmylGopW33PjsXPefvtt1OuF1+dL/mcpiv22X5FRUWzKilz9tlnuzdFcqWUldQBAAAAAICeo29RoZbW1bvKqHSsfVldvTsvk1CqvSPGNt98c/3pT39y+zb9kBXr2LzYhFKtsBXwrKJp0aJF7kVMZqlee0rqfvvb3+qRRx7Ryy+/3Gzs5GabbaZAIKAXXnhBkydPdm2zZ8/WV199pa222srt2/bSSy91fbFJ0o2t5GeB07hx4xLn/Pvf/065tp0Tv0ZThYWF7gYAAAAAAHKLDaGziqVM2eTmNodUumDK2tcqLtLfd9464+fO1KBBgxK5RZwtzPbQQw8pX7Q7lLIV8n71q1+5cjJbsjB5rKTdb08oZUP2bGW9xx57TOXl5Yk5oCorK10Fk22nTp3qqpZs8nMLmizEsjApPsn6xIkT3Tfx8MMP15VXXumucc4557hrx4Ol448/Xn/729/cPFhHH320XnzxRd1///166qmn2vvlAwAAAACALGbZRHtWzbNV92xS8/gcUsmsvbNW4dtmm21c4U2yzz77rNNHq2UTTzR59vIM2DA2C3lsiJvX612zJ29h8i+bef7II49092tra/W73/1O9957r5t83CYBu+GGGxJD88yXX37pVtuzaqvS0lJX5mYrAfqT3jR27NRTT9XHH3/shgiee+65iedoiw3fs4DMVge0YAwAAAAAAKRnn+NtbmobDVVUVKRcWX3vH59+3qWr782YMUNbb721m9P6wAMPdFMT2STnt9xyiw477DDl8vc50xyl3aGUVUfZCzVy5EjlC0IpAAAAAAB6bigVr5iyoXxVwaDKAoFOq5BK9uSTT7qinzlz5rjXy0aK5crqex0RSrX71bXhdA888IDOOuus1es1AAAAAABAlokHUL0bpgIKrOHosEzsvffe7pav2h1KXXbZZe4Fe/rpp7Xhhhu6iciT/fWvf+3I/gEAAAAAAKAHWq1Q6plnntGYMWPcftOJzgEAAAAAAIAOD6Wuuuoq3X777RlPEg4AAAAAAAA01e4BkoWFhW7ZQgAAAAAAAKDLQqmTTz5Z//d//7faTwgAAAAAAAC0e/je22+/rRdffNEtWzh+/PhmE50//PDDHdk/AAAAAAAA9EDtDqV69eql/fffv3N6AwAAAAAAgLzQ7lDqjjvu6JyeAAAAAAAAIG+0e04pAAAAAAAAoMsrpYYPHy6Px9Pi8Xnz5q1pnwAAAAAAANDDtTuUOuWUU1L2g8Gg3n//fT399NM644wzOrJvAAAAAAAAPdKNN97obl988YXbt8XkzjvvPE2aNEn5ot2h1Mknn5y2/frrr9c777zTEX0CAAAAAADoUjWhsPxej6rqwyor8CkUiarY7+u05xsyZIguv/xyjR49WtFoVNOmTdM+++zjCn8soMoHnqh95R3Ahu1tvPHGWrFihXoa+5oqKyu1fPlyVVRUdHd3AAAAAADIWrW1tZo/f76b/qeoqEi5oC4c0T8++UYPzFmglcGwygM+/WL0IB2x/hAV+rpuOu4+ffroz3/+s6ZOnapc/j5nmqO0u1KqJQ8++KB78QAAAAAAALqL1d7UhiMZnx+JRnXP7O90+8ffJNosmIrvHzpmsLytzK2drMjnbXUe7paEw2E98MADqq6u1lZbbaV80e5QapNNNkl5ge2bvXDhQv3www+64YYbOrp/AAAAAAAAGbNAaueH38ro3F6Ffj2812auQioda//l2LW1/1PvalldqM3rvbj/lu0a8jdr1iwXQlnVUVlZmR555BGNGzdO+aLdodS+++6bsu/1etWvXz/tuOOOGjt2bEf2DQAAAAAAoNP0LSrQ0tqgq4xKx9qX1QXdeZmEUu01ZswYzZw50w1zsxFoU6ZM0fTp0/MmmOqwOaV6MuaUAgAAAAAgN+aUau/wPb/Ho70en5E2mLK5pZ76+RYKZRidrO7wvbhdd91VI0eO1M0336xsl1VzSgEAAAAAAHQ3C4XaM4TOVt2zSc2T55SKs3YLpDpzFb5kkUhEdXV1yhcZh1I2TK+ttM+Oh0IdX84GAAAAAADQGSxwslX2TFeuvnf22Wdr0qRJGjp0qFauXKl77rlHL7/8sp555hnli4xDKZtsqyVvvPGGrrvuOpfoAQAAAAAA5BILnmxC8yPHDVFVMKyygE+hSLTTAimzaNEiHXHEEVqwYIEb6jZhwgQXSO22227KFxmHUvvss0+zttmzZ+uss87SE088ocMOO0wXXXRRR/cPAAAAAACg08WH6PUujAVRgc7Lo5zbbrtN+W61XuLvvvtOxx57rDbccEM3XM9mip82bZqGDRvW8T0EAAAAAABAfodSNmv673//e40aNUofffSRXnjhBVcltcEGG3ReDwEAAAAAAJC/w/euvPJKXXHFFRo4cKDuvffetMP5AAAAAAAAgA4NpWzuqOLiYlclZUP17JbOww8/nOklAQAAAAAAkKcyDqVsRniPx9O5vQEAAAAAAEBeyDiUuvPOOzu3JwAAAAAAAMgbnbzAIQAAAAAAANAcoRQAAAAAAAC6HKEUAAAAAAAAuhyhFAAAAAAAALocoRQAAAAAAEAXu+CCC+TxeFJuY8eOVT7JePU9AAAAAACAnqomFJHf41FVMKKygFehaFTF/s6t5Rk/fryef/75xL7fn18xTX59tQAAAAAAAE3UhaO6++PlenD2Sq0MRlQe8OqAMeU6fHwvFfo8nfa8fr9fAwcOVL4ilAIAAAAAAD1GNBpVbTia8fmRqHTvJ8t1x4fLE20WTMX3D1m/Ut4Mc6kiX2wYXqbmzJmjwYMHq6ioSFtttZUuu+wyDR06VPmCUAoAAAAAAPQYFkjtev9XGZ3bq9CrB/cZ4iqk0rH2w8ZV6oDHvtGyukib13v+wKEq9mcWSm255Za68847NWbMGC1YsEAXXnihtttuO3344YcqLy9XPiCUAgAAAAAAealPkU9La8OuMioda19WG3HnZRJKtcekSZMS9ydMmOBCqmHDhun+++/X1KlTlQ8IpQAAAAAAQI9hQ+isYilTNrm5zSGVLpiy9rWKfbpl90EZP/fq6tWrl9Zbbz3NnTtX+aJzp5EHAAAAAADoQjank62al+nNVtmzSc3Tsfb4KnyZ3Nozn1RTVVVV+vzzzzVoUGYBWE9AKAUAAAAAAPKWhUm2yt5RG1S6yihjW9s/Ynwvd7wznH766Zo+fbq++OILvf7669pvv/3k8/l0yCGHKF8wfA8AAAAAAOS1Qp/HTWg+ZXwvVQcjKg3EKqgK1mA4Xlu++eYbF0AtXrxY/fr107bbbqs333zT3c8XhFIAAAAAACDvxSuievl8bhtQ5wVS5r777lO+Y/geAAAAAAAAuhyhFAAAAAAAALocoRQAAAAAAAC6HKEUAAAAAAAAuhyhFAAAAAAAALocoRQAAAAAAAC6HKEUAAAAAAAAuhyhFAAAAAAAALocoRQAAAAAAAC6HKEUAAAAAAAAuhyhFAAAAAAAQDdYuXKlTjnlFA0bNkzFxcXaeuutNWPGDOULQikAAAAAAJD36oNRhcJRrayJuK3td7ZjjjlGzz33nO666y7NmjVLEydO1K677qpvv/1W+cDf3R0AAAAAAADoTsFQVM9/ENQrHwVVUy8VF0jbjw9ot40CCvg9nfKcNTU1euihh/TYY49p++23d20XXHCBnnjiCd1444265JJL1NMRSgEAAAAAgB4jGo2qPtSe86UXZwX1zPvBRJsFU/H9nTcMyJNhLlXglzwZnhwKhRQOh1VUVJTSbsP4Xn31VeUDQikAAAAAANBjWCB15rRVGZ1bWiSdf1CJq5BKx9p3mRDQhf9aperatq935ZQSFQYy62d5ebm22morXXzxxVp//fU1YMAA3XvvvXrjjTc0atQo5QPmlAIAAAAAAD1GNJL5XFAVxR5V1UZdZVQ61m7H7bzOcNddd7nKrrXXXluFhYW67rrrdNDBB8vr9SpiJVw9HJVSAAAAAACgmZpQWH6vR6uCYZUEfApFoir2+5TtgVRgVVCX7Ww7kjySp8IvT3lAHm/6YMnnjc0hlS6YsvbKEo9O/XlxxsP32mPkyJGaPn26VlZVacnSZVpn7bV18MEHafjwEQqFI/L7vPJmOnYwB1EpBQAAAAAAUtSHI1q8vFYKWcgTcdsfl9e69mwOpKIrgtLykAq9UqFPbltQFVJBTUgFth/wNLtFIrFJzdOxdjue7nHpbpnOJ5UsEo2qtKRU65T315KPvtOzTz+rn28/Sf6qsAvWenLFFJVSAAAAAAB0smhdWPJ5pJqwVOyTwlF5LDXJQrWhsLzhqPq9ukzBl36QVoUVLPGp3079pD0KtSoScUVIkYbAJLFtCFjqautcVZUFWB4XYkXdZOJxyRFLvD2a1Ora3C3asG2872mpXR4V9ypQdEX6Gc6t3VMRUM2imsa+NFzG45N2mxCbbLzZ6nsTAqpfVqu6cFL/ml67yZ7bb+nrbfLYF19+XqVlfq03dJTmfPCZzrrsjxozcj0dOfmXii4LWqGX67e70wMRSgEAAAAA0ImiwYiCzyxU6MVYwKMSn/w791Ng0iB5Ap03gMnmKloViqg6GFJ1MKzqUFhV8fsNt/h+VTCsVaFYoHPxpqMUeuZ7hZ9a2HixVWFFnlrospGCHfvplEdnqr42rAKrIgp7VBhRw32pV5FHm21WqKrFNar3R+S1yMgFR5K3YWv79pWn3E861l6eAq8L+lxClo61h6MqDEnR+jTVXvU12mW9Ak3cuES1dVEVFXoUXhWWd1GNioKdV6kUWrpCJ55zgb755hv1qeyt/ffYRxeffr4CgUBjmFaZ4czpOYhQCgAAAACATqyQcoHUk6kBT3w/sOsANzQuGoq6rayyKBRVfX1YNXUh1daFVVcXdtv6+pDq6sMK1kcUtG0wolAwrHAwEruFIooE7VqR2PXCUfkjcrdANLb1Rz0qikhlSW2xrcfdLykLyLuZR2GrkErD2gv2GKgr/1coVaWvSqrrJX23kUeVQXuuNSvxiXoaCqJs23Cp2H1PSrvXZwVodseTPpiydp9HNUUehQMWkzUkYo0bqS6oYH1QXq9HdTWxsqZQoVeewsbLNP1qkq/T/Lin5cc0OODQg3TQcYcp8o09YRqxMrRYlV0PRCiVR6L1tZLXL9VWS0WlUiQkT0GsRDFb5WKfDf1GT5WL75Fc7HMu9xsAgHwXDUcVXVqv6KI6RZbVy795n1iFVBrWHth9oGrO+ShtwGNZSFIe0g6u3mj1HrmWX9GVoVhFVzqrwopWheRZp1jRxfWxCiULedzW47a+MhuaWCNPqV+ewoahZzbXkv1/0v1Y6VTS/UR7Y1t75miyOaVsUnMb9tbs66qIxR+lfbLv9ymraGs1TGthgvaegFAqT0SD9Qq9/IjCrz0p1VRLxaXybbO3/DtNlidQoGyUi3029Bs9VS6+R3Kxz7nc71wO03K13wCA7hGtCSu4qEYrv1ulVQtqFPqhVp4f61W0NKTSlRH5GrIFz9pF8q1X3nrAs9KGZ/lVVx1UyCt3C3ri26giPo8iXrlt1Kpl/LGKH49t/V55/R55/V75Al75Aw3bAq8CAZ8KCmI3a7dz3WPi1/B75LFl55La3HELmGy4WIkvfb9LfO548anrtfz61NbKM3++vL0K5C3qut9dXCVVRcDlWW5uKQt5vJ5YIFURcMezMt6JqvUwrWEVwZ6IUCoP2C/a7sPN8/+SSivkGThM0ZVLY/u2/OVPdlV00TfKJp7+QxR++zmFn78/Z/qcUb+32EXRhV+lPih5lr2kTeN+dPXOb/E6zY97ho5R+L2XWu73pjsq+uWnDX/WSPuVt6u55fNX8/o+v2Qf1IP1UjjUjf1U+873BSR/QAoFY/1enf50VF/aeM3ce3tGw3s7rqY66WdyN0V/+DbN9VJrom0CypTjiadt0q62jrf+PO6ZKvoo9ObTiT427bN/m72k+jrJ643Ve7utNzbTpf2C5om1e6ytu/7NTtfvHffL2rAkV8O0nO03QRoAdJpV9SEt+X6VVny3SrULVyn6Y718i+tVsiysyhURldfHzituuDVV741qQVFUqwpD2rSijYCnV0Af/mqwG7lXGvCpLOB32z4Bn4r9PnlXYzW3jhhyaHNepQw5bGDtbu6mLEwT7LWyKdhDZT75LYSyyimvR6FIxGVv3fFaZsJjlVD2PkkTptkk5+54D5WFbyN0OK9fkdnvKXzUWSoYtbFW1i5VeVFv1c+dKc/zD7kPOPX3Xi1Vr1BWKK1Q4dm3KDL7/dzpc3v6ff91udnvJ+/Irn43BCWhvX7ZrM/+p/6ZlaFls36PHJcb/W54j4Rfeyqx7ynv7YJLe0/YB3n3Hrnnqux5jyT6/GSrfa77y4mZ9TkRWiVtXWgVu3laOu5r5byU4w3txaUK7DWl9X7vNFlBC6gshHWl7Yna9lh5e/LNtVvA5n7biV0zeT8+CULiMenP8aRrtzvepOdee4TC77zQyh8TdpOWfN8Q/MX7FQ8C7VoN+57kfU8sFEw+r43HtTdEbOsPN9kaAiaCtPenyxMoVDRYJ98mO2R9kJYSptXXSAXFhGlAN8ql1eCShWpD8vm9iq4Ky1Pic/Mo+Yv8GQ+TWlEf0qKaev24olZV361ScFGt9GO9CpYGVbY8rN4roxpQI/WJeNSnlWstC0S1sDiqJeVeVVV6Vd8nIPUtUGBAscr7F6lfSaGGFBe4YMS7Uz83SXhT1m7D/bYY2FvZxN4HNgm76erJ2deUBU9++wOjfb8bfl2w/WwNpJoGU65KrSGUchVUPTiQMoRS+cBmaJt6ju766kHd++LFWhmsUnmgTIcM219HTT1Hqlkl74gNFF28QNnA03eQovaX6hzqc7v6PXJDRe2DWTurPtpzfubVKJKnd39Fa1a13u/aGvk2+KmiSxc1/8KbVnK1pcXzW2hv6fTKtRTd92jd9cX9zft84mXyPnqbosuSxu632M2Wnrdzvi73eu9/XMv9fujmNX+dWzp3NV97996uXuHCkdDBv00bAqp6pbzDxyn644L2V/21WQ2Y/ni0lefx9Ftb0aq2+rxCnl79Yj+3kRZK6uPsuDuneUl1Shfa0NZ5sUBkWev9XrlMkQ9eV3Thl8q1cLvu2tO6JrhsFmIlhVfJ7WUVKjzhilb/cKMd91f9P6+MhYBWleluPnlsa8GKBYuJdr88bj/QQnvjfvy4J2U/EKvO8zdc2219DVu7eV3w6IK0GS+ofp3hKthpv5Q+6+3n5N9il6wNeSxMq1m2UIHeA7UyXKXyaEDBpQtU3GdtwrROkIt9zmVrEpTk02pwHdHv8DPfq/6lxn77du4n36RBCvs8WlJbrx9q6l3o9EN1nVYsqVX4hzp5bWjdspCrchqwShq0yqON6luvFA97ovqxxKPl5V7V9PIp1Dcg71pFKhxYpIrBJVqrd7E2Lgy0GXbUhsLy7jHA3Y8k9dsCKWuv90nZ+JNp7wOb7yqw56DU4DKL3x+5LtrwVrK54d2rnK3DDTuQJ+pm1EJrVqxYocrKSi1fvlwVFRXKNTXBGk37/B7dMvcfzY4dN+oITRl5iIoDJcomudhnQ7+7Tk2oNtbnOdOaHTtu9BRNGXmoiv3Z95/3XO13NBRSfbBad3z5oO798uHUMG3YASoIlMY+SOdwn6ORiP1PQwCVvI3fwora8XC45fOiYUVtxZxmx1PPdc8V308+1+eT7ycTVR+qabnf/mKFXnww9gcH95/waGybcmtY5ti2ril1P2Wb/PgWz4nvx8+LrQLjgkELAXv3l3/SEQoGfLrjqzT9HnqACoJhBR++MVYNGI3E+mTXiiRv47ek/fjxeHsHshAwcPS5ChYEWu53fUj1t1+UHSGgfegp763CM29Ufbi25feIr1j1d10hBWsbwrN4IGYVefFQrfF+8rFYeNbkWMPjUx/TeCwWrKV7TPNj9Z6I7ph3X/N+jzhYBfLLU7B60/l2SZi29LtYmNYQAgaXZHeYlot9ztVwJx6U1P97QWy1sqSgpCBLA560q8E18O890AURnVUxFYlGVR+OKBiJKhiJqD7csI1EFAxHY9tI4zmx9tj93Qb0kff5RQqnqTjy7TVQwU0r9dC0jzSoxqPBNR63LQ63ERgFpBUVPtX18SvSNyB//2KVDChWryElKulfIk8HrXhmX8/3y2o0sLxIweqQAqV+LVxZqwG9ilXQUNWTjWpCIfm9Xq0KhlQS8LthcMUZ/M5XW1ur+fPna/jw4Soq6trfbe09tri2Tkvr6hSOROXzetS7sFB9iwqzuloqkoP9bu37nGmOkt3/uqND+H1+98tfOtY+ZdRhOnj60VoezI5hN5WBCt2xzQ1t9vkXLx+p5cHlri1RV9GkgqJ5JUXzY4ltk2qLxvb4furjm1ZrVBZU6pEd72qj34dq9+cna1l9rN/ZoFdBpR7d8Z9t9nufFw91HyDsr/Rejy2hGtu6e7a1YTOKbV1rS+clnZ84L+n8ts6z/bJAmc4Yf5Lu/eKh9H3+4iEdOeowXfnhtVoVbmFp1W5Q4ivWSesf32a///Lh/7l+Nxa4xZeSbdw2FsGlVsslzmlyvGn1XGN7vLnJeU2OTxq8q178/hXdmhRc2vvBgkz7i87OA7fXs9+9pGyy++Cd9MLC1vv83IKXm7xuTZftbfq6NnndmrSnvG5ueqrm37tkTV93225T862eWfBii/3eY9CuemdMiTyesoYFa2I/Z3at2M9bbEhd7OfGuhGrDGo4y/1cJT/OjcJT82s0PVcp7Q3nNTyH3etfENEDXz6Stt/moHX316qDjk77b0em/xZ4ovboaNthVlJbtMWAKxa21ZWWaNrn96aE8sn9tlC+YJdfKGohoM39ZqGk28ZuUbcfTGmPJp8XCUkh24ZdUJq8n/b85FuaKkFPSblqw3Wa9uWDLfd52AHyLv/RBWlZ85fH0gpF/3CTpn1+X6uvtfea0ySr7nFBVrrArDHwSlStpQnDWg3M3GOaBHX+ls/3lPVSfcCrfyx5Qfe+3yRM632wCmobvl8ZVzs3Od7W41LOyfAxoaDqFWq5z/XRLA4AW66CycZwJx6iWZ9TgpJVYYWfXCibdsg3cUCroZoN7XLz88RvoagbzuUmGEq0R1Lb4ufYKm+hiCKhqCKhiKIN2/h9d8ydY+fH2mxinbUOWrf11eD2GKSvr/lE4VWhhr9HRN1oosT9ht+R4/vun1r3xcTPi/2GnHzc/SmjSTF0k3dy41s5Kll0areyhqbCsoCK/rCWauy9kYYFgqV7DNQvlhSlrGJnT1VT7lXQhtatVaiCAUUqHViiwMAiedcqVHGpT3264AO/BU9rVRa5IVnBUq8C9n2oLMrqQKouHNY/Z8/T/XPna2UwpPKAXweOGq4jxo5Uof0bmcXBzo81tYk2C3ji+9ka8ERytN8dgVAqD9gvInZr6djS+qVuMrjva9P/A9/VygPlWlK/tM0+2weXH+uWKFtUuH4va6Pfy1zo9kPtj8oW1p9M+l3oK9TXq5Imsu5Go8pHaHHdklb7vKRuid5ZPFNzV85Ttsi0328vfi+r+m3B5a/WO1L3vZU+uLzvi4d15MhD9cjXT2ZN4Gp9Pmb04a5vrfX54a+eyJo+x/t9wLCft9nvG9+8Pev6/dTO/9J9bYTbk1+c0iH9jgfUKaFVQ9iVEm7Fz2tyfjxk61VQoZv7X9PmH0F+Vf2AVgZXph6038U79Pdx+0XTJjiNTXIa4z7FNVaz2X8j/SH9X0FB630efZhO3KRGK+uLrCQ+dvXEdWJbTwvbhk+ODeGfK6lv/jgLxxra4/uuLV45F29L2i+rKNZlXm+r/T5y9GH609AfVLNsgbxRj3t5vTalRlRuFSv3vQs13Hf7dt+TdD9+fguPTdxPOi9pP/Z4T+q1iko18td/00PznmgxcD1g2D5acP2J8tTE/m238LTpdzZl2yQp9KQ51vRjR9vXSArEi8vU67QbdM8XD7XYZ1cBrRwLd+z7se1aWvTFChfGWJATy5cjjfctpIlEFbFUxB1rqOpsuDW2NR5zSYodj6cq8XZ7jZOOe5L37Wej4byCYr+GHz8mFqKlEX7xBxXsPlALz5+l6IqgvFYUa/MLua1i2w5Oj917upXjthqc9aXV1eBWBLXW8oii3zbM5r1GmkVOq3eV8kBsAujW+l0dln/iAHkKvS5w8vQrlKdvgUqzJtBsWEKtaTqXZcLRqGqCId0zZ75u/2ROot2Cqds+meN6vfe6QzR72fJYINkQQto2ft8TCqp/KKQV9fWqsTAl/p+SJMl/+k/+O0zyebH//KQWCTQ7r+E57b/1/YqLXKVROtZu4c6C6lXux7n5s6XvQybaPVNI0n2fRxpUWtJmv3sqQqk8YH8Zs1u6D8LWvlZhX1288R8VjrYxp0oX8Xl86lfYt80+/2mTc12f01YopK1saLtCIeW8FipNWqqk8Hm86l3Yu/V+F62lv/3kysZqqyxgX1evwl5t9vsvm12sUDTk+h6x6oOGbew/PLFtxOLNaJPj7q9i7TsvcTzpvMRxRVXg8Wutwj6t9rlvYR/tt87eqouk/8e9OxR6CzPq977r7KmacOyvIo3vlMbKvcYqv4YjTedYauN40wrC5lWDqY/vW9hbK9oIt+02ZcQh+rFusbKB/RuxIriyzT4fPuJg/dgQErdUPdn8dU1/vHkVZfrjTUfNJ7cPKOqn5W30276uPdeeqAU1CxPvh9jPUmyYXuwnLRYGxH5uGlrcZ6nY8cbHxYKDxOMbfs5iv1jGPnnFfnaTHxM/N/5zGtW6Jetoaf3yNsLt5Vq7eLBqQ7XuMck//+39N9G+DvfL5Br+d6vIV5jRH0FWBFdkTVBs4faSujb6XLdUy71BzQ0u6OrPjC0aVV6kxW30276uT/r6Nbcg/dxt3aFXgU9PFZS3GbievPEqLatvElx2k14F0lP+wlb7PHW9I5SNbMhei+HOSz+oYI+B6n33dylVMN3Ns7a37YBnZUiVXq+i1Zn/W1fviSrslYIeJbYhrxTyRBVK3G+6jabs22Mi3tjjI16Pwr7YpM99e0e0d1urwVUG9N8JBVo6Iiqv1+OGb9kHZ5/XK7+t0+HxuoVqXbsd93jk8zVsk863yaV9Num0N95u53jlt0JE29oEzvFFN5I2jS9ww8a2Pk9sAujW+l3hd++TfK06sv8u14bDqgqGVB0MqSoYVHUodj95P368uoX9Aq9Pj+y5kx6YOz/t81j74WNG6Ip3P9Sy+vTB5YCATycP6a+iVbXyhhqmAuhk9jr2Loy4CqN0rN2GH9aEwu77kS0KfT7Xr9b6bb+PUSmFnBWKhHXIupPTzmFj7eFoRGMqRynb5t1pq8+jKkYo27TZ70hY/Yv7KRf7PbRsiHKpz/YP9yEjJivbZNLvQ0f8QtkmGAm2Gqb1LuylKaMOUa71+ahRhyrbtNXvPoW9dfr4E5Vr/e5X1Fd3bXdT2semBl6dF2g3Pc/9RTWDP4KcOf4kF8pnA7/Hn1GfTx/3WwWj8XCn9SC1vUG1O9JC2J38V+vk9oDX/pjQt81Q/hAb5hmudd87+8NTLIC0+7YNN2wb9xP31Xgs8djEeQ2PbeFaKec3nBM/PqRkcJuBq1X/jSwbri+qGodLNn/topl/L5pNJ9DSNZueF9sOLOrfZgV0VbDa/RuYbWwOqVbDnaqQFq8d0Mrvgm4SYCtKS2y9nsT9+M3tez0pbSn7XtvGQpHEfds2BCWu6M3OTzrmVsNquI5tS8sC2q6toKQyoHd2rVBNuMwN6/b4vPIEbIi3V95AbN/r98rj97hgzsIdX0OY424uBIrdL/LGhlI3HrOtGoOfpPbWPsBG6sKtrwYXiWrifqOVlfON7dzPVc815dpt/jFLzbJwXiYLpKzKqGnVkfnlmBHu+9ZaYOQCJbvfQshkcz7ZfatyWlODKqxqp971MR1rX14f1FYD+2nhqpqG6QJiw/tjPxoe9fLaH3+8bh6qQEFjFXDyn/eT36LN8sjkhZmS25PuJBcduKpT93MQC0rTBTzxwLR3UUG7pqls9pPUwo9W8+bWQ6TkUdz+NvrdUwMpQyiVBwJRacqIA90v4/d9+UhiXoGDh+3n2u14tsnFPhv63XVsMvCjRh3mfg2/94uk+TLW3d+123DDbJSr/W4r3LbjAW/ysKPul4t9ztd+N85l5c3KP4JsvtYmyiaZ9Pkn/TZVLoby+w37mXItcF2rqK9u3fpa5VKfywKlykY2qXlb4c46vxunnAtKwhFtt806yia22lsurgZnc3PZ/GL1DUMjO2tSeataiU+wXtewrY+E3WTl1h7bht0E7XVuEvbGtuRzrN1CmmPGrecqpNKxdgulfv7Uiy1WHbWXvQplgYALhMoCfpX6bRtQqd1vsl+WaGvcj7UFXDVXumDK2m042fk/2bjNCbBtWFpXTnRu/y2xycGT52aKs/bkbTaJRKO66/+u0yXnnafDf3W8zv7TZYlj2djfjkQolQe8Xp/eeuo47bnx0Tp6lwe1om6ZKgp7aeG3b+qt//xG2066WS88cpDq67JjfpKCwkrtsPedrm+50ueM+73nzXrpsV8qGFzp5jixWDz2V4DYXCcmtm3abn8KiLfFJhZWYpLi2Ie5dPuxvyA0PI/bNr9+oKBcE7b8nd76d8v93m7PWzTrzasUcpOGNz421t+G+/HnjTXGp+NO2k86N3EN19rkGrG2xq8jfq3G69pt0NDttei7tzWpfKSOatLnr2c/rP6Dt9T337yubDNgyDZa9O2bOdfvQUN3bDW4jKz6UfO+fb35ezfp+5j6HozN+ZM4v433f+yclt/H6faLywa32mdfJKi6mho3SbK34Wb3k/8y1x1yNbik310nF/ucy/3OxaA4F/tsrMolF6tguioo6UhF/thqmD9s20sDJw1MXQ3O73UVLl3Fqv+suscCnNiKfOHE6nvxcCi+Xbu0RO8tWqwtd+yr3nsOUrQmLE+xT0tW1entb7/T6N4Veu7r7xKBUGNgFE4JihLtSSFSLHiKnduRg81GVpRrvxHDWq06WlZX70IeC6VK/D4XGpUmh0Zp9lsLmYpsQYc1/H3GqrtseGFydVectdv3JODNvve2VRTF519anVXsQsGo+7U0WBdVoNDj5qvzBzr/d8N333lH/7z9do3bcMNEBVkurL7XEQil8kCwfqWW/vihlj5/mgqKeqmoeC3V1vyo+tpl7nhd7VL3C2LtqkXKBgWFFaqrXZJTfc643zVLFYnUq3rF18oWFb1HqbZmcav9rq1ZokUL3tKKpXOVDayPI8cdrE/fv8m9v5v22YK2dUfvq88+uD3xNWQD6+fwMZNztt+v/udXrQbFn7x/U9b02/q8+y+earPPzzyyT7M+ezyx1bziIVUisPKkaWth6/W0cqyN8/sO3FQLv341bXD5zeyHNWjoTqpe8VVKEN0YAiYF0RkFfWnC7YalAxuPp4bgLYWFFv59M/cJTSpL1+9HNGz0PvIHsm9q5VCwRt/MeSyn+t12n38unz/+V+mmK0R2n1x8rXM1TMvFPudquBMX9EYV2qWfSpKCklV1IXm8UbeCXHdWX1h4EHLbxvsFXq+e/epbDSgpcSvAVRdKZV7p89qVemPeD9pucH99vHR5LChqCHDit0RI5EKjaEPFUDxUSrqlPC52Xuz85MfHrpdJUX6vggI3z9Ff//eRC3KGlZVqeEWZ5q+o0pdV1a565/G9dtFj877usIojY8Pq7PWyVfJiW58LYxr3betzW2svbNjaeXa8IhBwoULrVUdFunnHrVQc8LvnywbFfr+b78rk0up7ycGU3ZLnYmor2AmHovr47aBmvx9UfZ19vpPGbBrQ+J8E5PN33velqqpKhx12mG699VZdcskl7r0+uldFxv3OdYRSecA+6NrNPgTbh6/kD2DWXlSyljbf4VJFs2Sic/tAWFTSL6f63J5+b7LteYpGbHldN5Vww0oUsWXKY22xeU8a5+yI78cmMY6tLhGbxDj9eS0/LnEsPrGwrYrkK3DBSKv9Lu6roaN+rrBVSiU9f2IGi+Rrp8x5kdweXxmjcUUm15R8raSVSBKPb1hNo/F+1L3OViVn/TVN+2ztwfoVWne9fVVT/b2yRXHpgJzud2vBpfV7nZF7aVXVd6nv6Yb3ePJ7LrZNs+++0bG5ftTmezqacm78GrFjEZVVDnXhdVvhtrU1DaXs35Wo/ZU0XNdtYVprweWw0fvqpZfPypoAMLnfn7x3Yyv93kf/uW+Se69YqBUL0WLbpjcXinndemluGwvJmpyT7nFtnZN8Pa9XgUCZxm/+21b7bT+PM1+/TKFgVWyVL/e+a7zF3rst77fYZteJXy/SsJ/BYwsKKrTbAY+2+Vr/+95d23iPNKlkbTrTeco8H6nnNs4I0vRcT4vnWzXxLvvd33q/19tHLz9xpELBalflHQuIbetP3ff6GoLcWFvsWNP9WLjc4n7i3Fhby/s+lfcaqe++eqnFMG3wuruotnpR6uQoq/O6NTmvyTehXde01/ObeU/nXABolRnTv/1eP9mxT7MqmBnfLtA2g/unrPIVW+AhddvYHvsdIzY9S2wbW7QhvrBe7LeLptdp3p7uOqnnj6go1+NffKXbP5nbLCg5ev1R2n3o2nr7+x+TwqFYmBOKxrbhpPuJbZpz45M0JwKmNOemXCti8621HO7c+vFnLmiwffvwbsvRW5hjwcPPhg/Rn99reRLrzmZhTiB+cyGPx73OVlEUD3bs9bVbnLWvrA/q0PWGa0V9MBEW2eMLG64TD5XcNqWtMViKtxc2PLYjQqK2qo5s2HVZ0rxL2cKCJxtaeOT6o9z8VVaNZe+rbA6k4uy7FnZvFU/i56C1+NP+k/vJO0HNerNxsQ0Lpma9Edtff7NAvLC/TT5/+/4YdMIJJ2ivvfbSrrvu6kKp+NxY+YJQKg9EIiGNHHeIPp15S7Nj1h6NhFXZJ7smMrS/puZanzPtd59+Gyjn+h2NaPSGv1Q2iYSDiSCtKWsvLOqj8ZufpGzTE/qdLri0ftsw0Fzqc3FJP+28733u59L+nbSbBcYRW2UyEkxtS7NNaYuGMj/fXT/9+bHAdVmrwaUd79N/E1Wv+DI1eE6E1UmBXUoQHQ8HG8LwTELtpICxtcWRLVywStHW+m0hYEFhuWpXfZ91laKt9dsqRRd//34WVYpWZvRapwtcU6VfLbLp4bTHVkNJ2cC2+12zVOHQKq1c9rmyRSIofq+1oHgfvfjcQVkTFDeGxC332apfs5F9CLvqfx+2WAWzw5BdtN+/X+62oEStBDwPzP0ibVBi7YePGanbPp6TNf3uV1yUMom19Su5b/FJrLcZ1F+LampdSGOTqMcqhDyNYVHTW0N4ZOGOO989riHkSRxverPrpp5nIVBLH+it6qq1iqPeRYU6Ymx2LeCU61VH1vfkeY2yccheOhZI/eu6VRmdW1gs7XtsiauQSmf2e0GN2yKgR29dpTqbzaQNB51UIn+GGeN9992n9957TzNmzFC+6tZQ6pVXXtGf//xnvfvuu1qwYIEeeeQR7bvvvonj9ovx+eef78rYli1bpm222UY33nijRo9uDCOWLFmi3/72t3riiSfk9Xo1efJkXXvttSorK0uc88EHH7j00b7R/fr1c+efeeaZyhf2l7D1Jhzl7n/+8b3uFxT7hcTCBmv3+bOvhDsX+2zod/aErXbc68u+vzjR7+zqs98XiK16lEV9byu4tA+XW+16Vbf0rWmlZXLVm1WutNrvkrW01W7XxSrR3M2Cr3BDkJb5fqLdnjUSjlU+RBr23fHMK5m83tRK0bT9Lu7rPsBHIsG2K7HczT5YeGKVNg3b2FDH2PweyVu1cz+29buQobU+W+C67aRbY9W47huX+A42/G9qINV0lbdm7U32Y6916jWbrraXtJRfjK0allRN3NJ7ZOOt/+iqFG31O/f9tVXxXGjb8L6xEDnadN+2obT7kaTzYqFw/Lr2Hohdp7GtyX4krJKyQRkFxZV9xqpqeSyUaPW1S7dyXhuvXUvfr6Yr+cX3S8uGtBkABoNVKvT1Vrapqg+2WgWTPO9OXGyBvMYhLrEVuGLVY/FVwOIrgymxQlhye+wBblBy0uNbPj+1fZ3SEi2ra+x3U9ZuVTt7DltbP9bWufDFAht/QyVEYuvaYltfC+2N57fn3CbXbgh82gp37HU+d4uNlG2sSicX5znK9aqjnq641KPaVVFXGZWOtdtxO6+upuNWgPr666918skn67nnnuvSyeCzTbeGUtXV1dpoo4109NFHa//99292/Morr9R1112nadOmafjw4Tr33HO1++676+OPP05802zspQVa9o0MBoM66qijdNxxx+mee+5xx1esWKGJEye6UribbrpJs2bNcs/Xq1cvd16+sFBh9IZTNGajqe4XERuyYL/kZWPYkMt9NvS7a+RikGbod9fJxT5newAYm0PKwpbVqxS1aplcrBQdMe4g5VKf7T1SWFSpbJPJe6TvgOz7EJxJULztHjcol/ps/43PRjZ8qbWgZK3iIk3bdduk8Ck75llpK+DpU1SokzbKrlUDczXcyeWKo1yuOspFNoTOKpYyZX9rsjmk0gVT1l5c5tHuhxZn/NyZsOKcRYsWadNNG1fMDYfDrnjnb3/7m+rq6uTL8vd0R/BEG/+E063sPyrJlVLWrcGDB+t3v/udTj/9dNe2fPlyDRgwQHfeeacOPvhgffLJJxo3bpyrgNp8883dOU8//bT23HNPffPNN+7xVln1xz/+UQsXLlRBQWyawbPOOkuPPvqoPv3004z6ZsFWZWWle/6KiopOew0ArN6HHJsDJDlIy8Z5Mpqi310nF/scDtXpsw/uyKkwzdDvrpOLfc7Vftu/IXNmTUsbpo3d+Dj3B51s+zclF/scn3fnn7PnpQ1Kpq4/2lWZxD/UZ5Nc7XddOKx/fPp5ToY79ppbFVhyxVE2vsb5rLa2VvPnz3fFJblQBWSr7n08I5iYQyrZhlsF3PC9jl6Fb+XKlfryyy9T2qzIZuzYsfr973+vDTbIvmlf2vN9zjRHydpQat68eRo5cqTef/99bbzxxonzdthhB7dvQ/Ruv/12F1otXWorscWEQiH3YjzwwAPab7/9dMQRR7gXw0KouJdeekk777yzG/rXu3fz0mVLJO0WZ49fZ511CKUAAF0mF8M0Q7+7Ti72OVf7nYthWi72OZeDklztN+EOOkuuhVLx1fc+stX33uva1feS7bjjji7vuOaaa5QLOiKUytp/cayyyVhlVDLbjx+zbf/+/VOO+/1+9enTJ+Uce4GaXiN+LF0oddlll+nCCy/s4K8IAIDMxT+kx+d9yaZ5r1pDv7tOLvY5V/uda0Pcc7XPuTzvTq72m+FkQCMLnqwiavyWAQXrpEBhbFW+rgqk8lXWhlLd6eyzz9Zpp53WrFIKAAAA+SkXw7Rc7HMuByW52m8AjeJD9Hzx6ai6OFd++eWXlW+y9l/KgQNjk6F+/33q0tG2Hz9mW5sYLJkN37NhecnnpLtG8nM0VVhY6MrLkm8AAAAAAADIg1DKhtxZaPTCCy+kVCy99dZb2mqrrdy+bZctW+ZmrY978cUXFYlEtOWWWybOsdnrbWW+OFupb8yYMWmH7gEAAAAAAKCHh1JVVVWaOXOmuxmbIMvuf/XVV27i81NOOUWXXHKJHn/8cc2aNctNWm4r6sUnQ19//fW1xx576Nhjj9Xbb7+t1157TSeeeKJbmc/OM4ceeqhbdW/q1Kn66KOP9K9//ctNkp48PA8AAAAAAAB5NKfUO++8o5122imxHw+KpkyZojvvvFNnnnmmqqurddxxx7mKqG233VZPP/10yqzud999twuidtllF3m9Xk2ePFnXXXdd4rjN9v7ss8/qhBNO0Gabbaa11lpL5513nrsmAAAAAAAAuocnGo1Gu+m5c0amSxkCAAAAAJDvamtr3Ugom5YnuagE+fN9XpFhjpK1c0oBAAAAAACg5yKUAgAAAAAAQJcjlAIAAAAAAECXI5QCAAAAAABAlyOUAgAAAAAAQJcjlAIAAAAAAOhi4XBY5557rlu9rri4WCNHjtTFF1+saDSqfOHv7g4AAAAAAAB0t3B9VB6fFK6JylfsUTQs+Qo8nfZ8V1xxhW688UZNmzZN48eP1zvvvKOjjjpKlZWVOumkk5QPCKUAAAAAAEBeiwSjWvjfoH54PahwreQrkvptHdCg7QPyBjonmHr99de1zz77aK+99nL76667ru699169/fbbyhcM3wMAAAAAAD2GDX+zqqdMb6HaqBZMD2rhi7FAytjW9he8EnTHM71We4bebb311nrhhRf02Wefuf3//e9/evXVVzVp0iTlCyqlAAAAAABAjxEJSjMvXJXRuf4SaYMzSvTDG8G0x61yauB2AX3451UKZXDJjc8vka8gs36eddZZWrFihcaOHSufz+fmmLrkkkt00CGHKNIQbnk9nTd8MBsQSgEAAAAAgLzkL/coVBVNVEg1Ze2h6mjsvFUdOwH5/fffr7vvvlv33HOP1h83Tq/OeFt/PONMeXpVav9DD1GfwiL1LSru0cEUoRQAAAAAAGimJhSS3+tRVTCoskBAoUhUxf6uiRFsGJxndcMYf1QTzit21UbxQKe1YMfjjc0hlS6YsvZAuUdjjy/O6Km9gcy7ecYZZ7hqqV8ceKCW1NVq53XW1pR583TrNddo30MO1o+1Ne68nhxMEUoBAAAAAIAUdeGw7vrsY93/+WytDNarPFCgA0eO0ZQx41Xo8ylbWRBlAY/d4qFUWxVHNheUTWpuc0g1Ze2RSFRRX1SRhrAsoqi7to2ws/uuLX6/tuFYQ19i5zfcb3icnWv3V1ZX68e6Whe+WX+N1+dTJGKPiLF263tPRSgFAAAAAABSKqQskLrt01mJNgum4vt7Dh2uj5b+2OLjfaGw+oRCWllfrzpv11X4FPv8Wl5fl6gwMhYCxfctWFtWX5cIimJhUlQ+r0cDti+1Fv3weihp9T2/Bmzv15erVqg+Eu7w/u60x+666aq/aqNRo1U2bB198sEsTbvhRu1/2KEp/U+u+OppCKUAAAAAAMgz4WhEP9bU6rtVVVqwqkrfVVe77Yr6el20xTauQiodaz98vXH66//edQFPOgP8BTpl7eEqrKmWN5x+AvGO5vN4NKqyd6LiqKl4xdGK+jqF06yQVxsKq99PSzRwhxKFa6PyFXlUXRdMBFIWCVkwZFVN9n+WtXkT9z3y2jBA27q2xnO9DefG71u2FDvfo1tvuFEXnX++Tv7tb/X9okXqP3CgDjxyin59xumJfrlze2ggZQilAAAAAADoYawKyIKY76qr9N2qai2IbxsCqIWrqhWKNg4TixtZ0UtL62pdZVQ61m7Bzg6Dh7jrpMtLKj1eFXp9KvYH5Pe3Y5KlNRDwehWORBKr1jVl7RbErVVkc00pJRxKvl+vsHzFksVQJcV+reupaDin44Ohol69dN211+qaa67R4tqalAqvOBt62JMRSgEAAAAAkGOThlvoZJVKCxoqnFzFU3V1Q+WThVDVqmtjyJlVFw0sKdWgklINLinToNJSDSurcMGNDXVLF0xZe5+iIv1h05+2eN3a2lrNnz9fg0vLVFTUdaFKfJhbumDK2n0er/pk4fxMXo8nMW9Ue+bC6gkIpQAAAAAAyMJJw60iyQImq3ZK2TYEUDXhUKvPaxU+/YuLNai0LBY6WfhU2ri18MnvtYFnzQM061/ynFJx1m6BWqD5w7KCBTm5WHHkbQim7JbpqoE9AaEUAAAAAADdNGn45BGj9dGSxQ3VTqnD7Kyqqi39iuKhk1U8lWlwaeN2QHFp2tCpLVbBZYGZyaXV93K94sibJ0FUMkIpAAAAAAA6QW0o5IbItTVp+KXvvdnipOG9C4tigVNK8BS7P6CktNMCIruu9e2oseNThhxmayCV7xVHuYpQCgAAAACA1VAfDrsJwxsnEE8dZmeB0l+22qHVScOX1ddq834D3IpwyUPrXPhUUqqiNZh3ak3F57zqXRgLorJ1yF5TBFG5g1AKAAAAAIA0QpGIvq+JTRpu8zjZanPJw+xs7qL0a73FWKWOBVPxScN7FRS6Ch5bac0qo6zd5nW6dMvtlI1qQhH5PTY5e0RlAa9CUZucPfuTqfhE57bKnrchl8qFgCqSo/1eE4RSAAAAAJCHOno1uFzsdzga0Q81NQ1VTvFqp8aqp0U1NYq0GjtJRT5fw3C65hOJ21aK6rj1J2hgSbm26D9AS2tD6l3k19vfL9T3NVVZO2l4XTiquz9ergdnr9TKYETlAa8OGFOuw8f3UqHPk9XBzuKasJbWhhPhTu8in/oW+7I64InkaL/XVPb/iwMAAACg3epDNfJ6/aqtX6mignJFIiEV+LNvKfSmCEqyezW4XOu3+6BfW9PiCnY29M6GzbWmwOttNoF4bGhdmQaVlrrqJ08bocE+w0frHx8t159e+zYR8EweU64jxg9Soc+blRVSFkjd8eHyRJv1O75/2LjKTquYijZ8P5K/K/FvUbq2WHtsx8IbC3Us3ImzgCe+byFP0BrSPnEb/Wrv19GOkwp8Hi2ra7nfPTmYyt5/JdHhcvEXk1zss6HfXScX+2zod9fJxT4b+t21crHfudhnQ7+7RjBcp+mzp+n1ufeqJrhSxYFybT3qEO049igFfIXKVvkSlGT7anA2uXU2Bmpt9XvPYcP1wjdfpVQ7WehUH4m0el2/x6uBJSWNFU4NYVOs8qlMfYqK1igQiAc8dzYJeGzfrnrgmAqtCkVdOBaOKP02KoUjUYUatm6/lfOSt6EMrpu8temjTt28r6uQSsfafzmuUie/sFAr6yPuOpat2GMtKLIgsJcvpEMHhORdXi9fjbche4mmCZOStu1NfZqwbG9krwIXSqVj7RbufLMy6L7+bOHLsN89Vfb9S4NOkYu/mORinw397jq52GdDv7tOLvbZ0O+ulYv9zsU+G/rddQGa9feFT25JtFm/4/s7jJmSlYFaTw1K2tNvqxCxD/g2j1EoGoltXRARaaMt9phwmrbG82L7Nj/QASPHtLoa3JQx43TNB+9qVSjoAgTLCix2aKxWiYUQyRUtdj92Xix1iDZpV4vnxK4bv1LT54s/V6k/oIu32KbNVezumfNJs1XsbPW7/sUlLVQ7lWqt4mL5PB1T9WNf4+LasBZUhfRdVchVukxer7zVgMeqjqY++a2W1WVHUjKiMqAltWEXnKVj7UtrI+6cecuDac+pKwg3BF1StKXKpA6QnBUGvB73vm/p6SIN/bHKtPp0CVjDtVY3fvSsZt8LvB7Xr9b6nTzHVE+Tff+qo8Pl4i8mq9tn+49AJBpWNBpJ2ibfb9xae+ZtqcciStMWjWhYnwl6/6un/r+984CTokjf/9uTNrG75KRkAUmCIFFBUATMeJ6CEbP3O8Nf77zzgqcXPPX0zoQ5n2fOOWc94VTMigoKGMgssHF2Uv0/b810T8/spF12e6pmnq+fsaere3qebaprup5+6y16dfmtKXQL2r3/gbSm5lNykUGG4ZZhvq7YUq5TfF0uU+wXLXeRYURfLvuyjeWhSJDeKpI6km+g2zl01MxAt7PoqFtHzcWmm+8LwhF+Eh9KXApemq+gjLbi3+CIVW7uE0y5TygSooi1LURh0fI7PO4Smr/776WBlgounzXiZFIRHvqWyXA4fthIOvfd1+XwOMbsn1nLWA8v3m+LrSd1NI2k8vjeiZ+Pb09dzvuzUfKH8ZOz6j7jrVdoa8CfaCbZjCKzLNswsvZgSFVnmrVT/4yzwW3x++m9jevp29ptpAqsu6bZn1H39kAzHTpoF2lC2aOd2JDyuNpvqFlDMBIznYK0tiFqPpkm1LqGkMzFZDd4ZvYvz2jwbPNHqFeFh5rDQWkacuSM2740OJomaZm0nyfdfmn2N4/rSbFfmdegbmUeOcQwlW4u58ids8Z3kWYJX3v8Wb42ZA+D34eaiWp+or6VHiot9VqftV9WyddkYlmc5Gs4WpbaoeEoLf7+VAYPl/Pf3r8qriffDBw4kNasWdOi/KiTTqcLL7/G0l2ohhQDU6oI4FDzTDcmfDN1y5unUVOgVpbZnmVE/29d0Nbzi9hq0roN86lJ+s8kHdN2rDJfFf3fzDuyav7HcwdTffMWy3hikyiVFqeo8HWm8w94lt5d+UDK7Vy+9/AT6LlPrqSGgDo/8HHdmc/335+ZS42K6C73dabfzHtCK82t0X3JM/tL3ck/tvEfbGlXWqWxosR1qzxpP2u3xP3ix2n5neW+avrlPv/Oqvuql46gxsD2dmkHEstb1wbxcfhcnzfvsayaL332AGpizdY5ZSPY/Mv5fawsds7i+9jO3458Nmlbua+STtzruqy6b33rF+QPpn7img9KvZW0aNpVWXSfQHe8fSb5g/U5nZv4PtE71MR90n02sTz+7xM7atIxSz0VdODYX2XUPXPXE+jxZX8nf6gh9gTffH5vPuWPPcO3IgHs+2QqN48SLbf2yvLZEm8nOm7qvwq0juir+58vzKda/2ZpILExlM/7kV5Vu8j7IzbOUsHlfB12KulCqsFmUybDgQ2JDY2N2hklvH1roJm+rY3/RrYG7uSzccCmCg8zc8tlbD1W5klZZsT3t23noYXdSuOzwSUT3V5GBw0YRM3hSKxdtVpP229d9L4h2rKabS8llJt78mfibXG6Y8XLU30f53XiWeoyzWLHf9cvR42jHYXNww2NcbPpJ7kMWqZTtogmNhB6lrupT4WXdunslQZOJoOne5mb7pjXl1SChxxyUnN7TikTLmcDdVKf8rSf9/uJVm03qNTjki8n4bxR9txM9vJsiGZB5CYSjYKMcoMoTGSUdJwj9P7771M4zAEOgmqawvTex5/SyYcfSPMO+VmrdOsMTKkigHMfZLoxaWjeSg3N22hD7UpSgRJPBdU312TVzE8lg43+Vh2bI4OikULuhOWOlEWjjtzUrWJn2SHPpJu3j95pNtU0/EiC462sSKvoUr6Sy2VUVuJ+rS3nsnR0Ku2e0/lmY6LOv4lUgLXoprk1ust8lVTr30CqUJajbr7C6vybSQX4HOaiudTbibY3rSdViHYms+uu99co02bnrruGtjdtVE53nT9z553P9eotnyijOxfDQd86oq9ut8tHgVBj2uNw19rt8sZeHrl0GR7yuDzy4aFVbsS3W0sjtr/Ltn+G/Uo85VRZ2l0OMUylm8u57VMRTg6eyShhQ+KMUeMoGOF7m8QHHPHnF8nliQ84Wj4QSSyPP/hIXZ68Pw+7YWMkm+5zx0yQRotpFLE5xMPFoiZSvMwyk2xmU0ckN+Yhh5zzyj7k0ITLuYN89NCRpBqsuz1msWOjn42ln+qDVoSTPeJpYyNHImY+RnWJi/pUeKhvJ/PltdZ7lXvIa5udLpvBwxFz3jYPGusYOIk5z7LHJM++d/yozjIxt4rw9WLmX2rtLHYiKCj4TICCLwWIuEkvJ/LO9ZH3YB8Z3o75e3v06GG97y0ELf7X5dR/0GCauOcMzL4HCgdOxpnpxoRvXA4Z+xsZLr6jURX2fVoeKzHuMt2x+CatqrRHVs3HT7syNpwtR/NIDlXr2IuZw+sz6e5U2o0Om/AHchrzKbyMJjOHOMbWuaH2uUuznu+T97our09+W0TvlHTWSnNrdJ+012L5b5Q+mig5YojSRBglRyqZq+kiklJHMPG1k8s1edTkS6QRGv0MZWkH0g2xaFu7kdxmsVFcUdIlq+YT9rwmdq5TR68kR8TEo1qyR760JSLGbbhzOtcHjf2VHKqjCtwpzkX3/mPOplCEO21mXpL4+aCM5yb1v4N5hMRyyvmzHrcva+ed2+2pQ46I6U6MvsoUKWePaEyM0Er3WfvVkP64brevoOuIrrqPnXq5fEjliZlNCWYRG0mG2/Ehh5zzyj7k0ITLOaKLXOoMXzFhQyGTUcKRGXv22YlUI5vBw7on9upNKsE5rjgJO6NLcnZTd66z2LERZBlO0nSKRTrF1v1ZXCc2XfpWeKiPaTpZ771yvSIX90tzg6fEbch8V4tGdZZDFvlvZgNNVb0mbOB0LXVRV5crIReT0Zx6lI9EEAWfC1DwCZu53EgUfDy67p3n47DF3ChJP7wwE6FgkB598D4699xzaWjXEkt3IRtSDEypIoBvPDLemIgwDek1kVQi682UCFO3TjuTduc6TzeB0RBq7uS42ny+q8p7kkroqDlX3dXlvUhH3b2rdyHdNHep6EOqkYvuob2mkI66d+2zF+mmm6NNpww5glSikOuIrrp7VA4kleBock7CzuiSnF13o0RH3ayLE4OfuOsoagyFqNzjkcagqnqzzWLHTOtbRtcs2yoNKE7EnQnu5sshdrYop506xU2orqXtG52iq8HDhhrTOVYvVIvoSocrYFDjqfW57VxpUPlVFdEIqRQEXwyQ90AfNZ7bQFSX/YF3+a2diEpbq5joiSeeoG3bttGJJ54oIyaLBZhSRYCONyY6amag2zl01MxAt3PoqJmBbmfRUbeOmhnodhbWxfmuOKk555DiIXv8cExVvamMEs4xxUP6VDdKdDV4oriIhEGRiIdIsPngfIR5cyhCtYHYq5mXYdv7CNXxejOnpRB04bQeaWexe/TrOjp2ZLUckmfmfKr0uawoJ15akU4VHplY3GlDSFeDp9Axqg0StSI6ZC8VjSS3y/1yMKXayu233077778/9e2rVn6xjsYQ8fEdIA21tbVUXV1N27dvp6qqKtIVftLHeQjsNyYqznKju2YGup1DR80MdDuHjpoZ6HYWHXXrqJmBblCocBQPJxOvD0aoUywKxjQhVIRniPvPF9taDCfjYWYc1dMauEvZGBJUJ82kcEqTqS5mMsl1632EAtmSN9lmsfvH3j3piKd+SrvPk/N3plW1Aar2RSOgKn2qm4KFi9/vp1WrVtGgQYOotLQNYUM7iLQ5mlvxAQ9R4xn1qY2pcqLy6zsRhTpu+N6aNWto8ODB9Nhjj9Ghhx5KhfDvnKuPgkipIsK8cbJmW1Ewl0AhaGag2zl01MxAt3PoqJmBbmfRUbeOmhnoBoUIGzw8rKw9DB4nh8HZE2+zbnP958OqZN4laTIlRS7xetxgiptMOXpLKeFTVFXioiqfm6p8vHRRpX29xEXdSnmWOk/GWeyqS9w0sXf6GeFA8SBNoVZ4YTzrHic1N3NI2eFyOQtfacddy3feeSf17NmTDjzwQCo2YEoVEeFgExkuD4UCdeTxVZKIhMjtVfsJn46addYNAADFio7tto6addatI7qea90ijrIZPEcMq5LrPJyPjRu5jJD8u+JLQaEIyaTovEzYN1bGy4TPxbbF36dbxj7P3yGIytwG/XWv9MPguJxzH/3mzQ3WMLhc8bnYXIobSaapFDWYYuvWe97HLYfYlXsSJ3zIdK51m8UO6IFRYshZ9swcUk7NvsdEIhFpSi1atIg8nuKzaIrvLy5SIqFm+vGjf9Pazx6gcHMduUsqqe+YhdRv/Ink8qiZW0BHzTrr1vXmVUfNDHQ7h46aGeh2Dh3bbR0166xbx7qt67l2OuKIh/gEIoIag0Imn27kVyj+viHIw9IisXUR2x5f51zEV87qldXgOf3Zda02eDoKHgZX4w+njDZiuHybP0JDu/ik5riB5JLD4eKGU0uTqaSDzUNdZ7EDesDGEyc09x7iI2oUROVGNEKqAw0p5pVXXqHvv/+eTjrpJCpGYEoVAXwTxTclP3xwa7ysuc5a7zv2GKLY9PPKYLhp7Sf36qU5B907775I2RtYHW9eddTMQLdz6KiZgW51fiNVbLd11Kyzbh3rtq7nOlvEEZs7bEq0MJJCccOoIY2pJM0k2/6mqcTLHRl2lqvBw7O6RUSI2LNxG4acWYv9E7l0kYwMk8tYudtlWGXR/W1L27bkzyUu7fvHl6UeI+swuO5lbrp6n96kIrrOYgf0gCOmJFWGY47JnDlzojmwihSYUkUAP9Xjm6hUcDnfmLz/n/kU8m8jFfCUdqaJxz2jlebW6T6YwoEGMtwecrm8ZLi91pL/rVxy6bWWafdr42ejS0/Cfi5vWVYzzeVxPkFhJiIhf9YbbtU0M9CtlmYVO2W6diZ3VLeIhGXkSSQSlEsRDspE0tH3ieXJ+yWupzpGMKk8elxuEwfteW7mdnv8CbT8xd9ROJDjtNIdjNvXiYbt++esmr966Q+Jmq1hMdFlfJhMbGn15WLbrfLU+0W3p94nPgInXu72ltOgvX6VVfd3/72KIsEmeRCp0YhGXRhyyev8zbFy6z3vG4vOiO0X/Sxvje6X8DnzeAnvzaFD0X3M4/J6dd/xtPGbZ+mHD25LWbd7DN2ftv/0Prc60U6FsC8jtqUgQbGlVR7bj2c8s+/Hy1Rl1jFSfFfs2Pybvsvef8h4rvtNOJlUhA2WTBFHPLPawqd+pHWNITkcrb0p8xhU7nVRhdegcg8vXVTuNajCw0vzFV/n/Tg6KBeD55a5as2mpfswOMxiB0DhAFOqCOAwc755SgWXB5u2kq+8uzIGD2sJNtVopbk1uvnGvLluLelmpv3vztnKnG8dNTPQrZ7mpXfuRyH/9lgn2uyQmp3XeFm8s0qJ+9jKrH1iZfZObXR7/LPxYySWeUurafQhN2bV/ekTp1KouS6FcUAJ69b2FPu1MCWS9on7CumOEd+PjZLh+12SVffHDx9HwaYtUaMoZgyZRhF3qp2mvOsuFGzckrndbqyhpq2rqLFmJalArpoba75VRnNrdG/7YalSuuNtyYMZ6/aa925Upv3L5VyzYekqiyVsVwjOIZUp4mirP0Jet5FgSJlGEuckippILU2l6HabyWStmyaUi0rdHHFkFI3Bg2FwAABVgClVBHDeAw4zT3VzwuW+ih60+4L7SSX4iblumnPT3Z1GHnAVRcLN8af28kl+dMlP8yOyo8bL6HrKMvPpf7bP5rBfSade2pmAhW5cQreDmsu6UqiphoMLEshXALXLvUtOukP+WqU67rIT3JTFcGjaSpFwgJrrN+R4VCMe3enyxCI/o1Ge0XVvfN2MCo3tZ0WTJu9nRZRG93H7KmRdydhul3ejnSecTCLccjaefGC4fTlqPpFEKKpZRuHIN2bNTlpai8z7xa8TjsxJ3pZ81SQeK1fdPXc9SEZKRY9nRgjxezMaSP7YxiKGTB1mZBHZIofs5UnHkG9TlJvHs6KRiHz8G+nfnrFuh5prqeewA6i5YUMsMstlRXlZy1jEVjwqy4zUallmRnTFj2FGhSV91ooQs33WMGTUarZzzUayinBS80wRR93K3HTx9B7SUGFTiQ2pthpJ7YmuBg+GwQEAVACmVBHAT6A574F9SIUJl/N2vklXiUikWTvNuekOU2mVWuHbDJtT2UzAMYfenMeuejKG7EzqpZmBbrU0d6fRB1+f0LG1OrpMhrJ4R1YWJh3D7NynKDPX5TGin7WOSYIMwyPPZTbdQ6b/VhrNcU2xY9mImwQtjYa4t5B6n/jfa+2YcT82fLIaDhXdaeisP0U7ztYQZNNAippHCWaSKzokw4lhhxnbbRGhnkPnkErkpnkeqUYuuncedxzp9hvpLetKg/f6NWl1rjk6UcH7KDZEMkUc8SxyA6qis2Ophq4GD4bBAQDyDUypIoBzeHAiTkaXBJ06atZZdy7Gpbcs+gRQpxtu1TQz0K2S5rA0SlQjF93VO00gHXVX9hpNqqFju62j5kL/jVTN4NH1XOsacWQCgwcAAFqPIYo5zXuO1NbWUnV1NW3fvp2qqqpIV8ypjDmPAIdtqz6Vsa6addXNMwv98OGdWt286qiZgW7n0FEzA93Oo2O7raNmXXXrWrd1PNdmjiZOem6PODINHwCAHvj9flq1ahUNGjSISkvVmgwHOPPvnKuPAlOqiEwpAArx5lVHzQx0O4eOmhnoBkAtULcBACB3YEoVB/52MKUwfA8AYGHeXFsz8ig2HKFQNDPQ7Rw6amagGwC1QN0GAAAA2h/EwQIAAAAAAAAAAAAAx4EpBQAAAAAAAAAAAAAcB6YUAAAAAAAAAAAAgMO89dZbdPDBB1Pfvn3JMAx64oknErZzCvALL7yQ+vTpQ2VlZTR79mxasWIFFRIwpQAAAAAAAAAAAFD0iOYwiVCERF0wumwOd+j3NTQ00NixY+n6669Puf3yyy+na6+9lm666Sb63//+RxUVFTR37lyZYLxQQKJzAAAAAAAAAAAAFDUiGKHgi+sp9NomosYwUbmbPPv0IO/+fcjwdkw8z/777y9fKfUIQVdffTVdcMEFdOihh8qyu+++m3r16iUjqhYuXEiFACKlAAAAAAAAAAAAUDCwoSOjnnJ9NYUo+Pw6Cj2zPmpIMY1huc7lvD3nYwnRLn/DqlWraP369XLInkl1dTVNnjyZlixZQoUCIqUAAAAAAAAAAABQOAQi1HTWx7nt28lDZZeOjkZIpYDLvXN7U9PvPyeqD2U9XNnicUQlbtpR1q9fL5ccGWWH181thQAipQAAAAAAAAAAAFCUGNUeEnWheIRUMo1huZ33A+0PzioAAAAAAAAAAAAKB58rGrGUK25D5pBKaUyVu8no7KXS3+2a83e3B71795bLDRs2yNn3THh93LhW/G2Kg0ipIqIpFKBgJEw1zfVyyeuqo6NmAAAAAAAAAEgmFBQUDgvyN0bkktdBx2AYBhkl7pxfFBYyqXkqZHlY5H48w2iXv2HQoEHSmHr11VetstraWjkL39SpU6lQQKRUkdAcDtLdK9+mB757l+qCfqr0ltLCwdPohKEzqMTtJRXRUbMJm2cel5vqgk1U6S2jUCRMZR4fqY6OunXUzEC3c+iomYFuZ9FRt46aGeh2Dh01M9xRN1xEwWZB3hKDRITI422fTl5HoqNuHTXrqjscEvTle0H6+qMgBZqJfCVEw8d7adQkL7k96mrX8VwzIiKIDF6S1E+86kqvm80knmWPcXL2vfr6elq5cqW1/t1339FHH31EXTp3pQED+9P/+3//jy6++GIaOnSoNKn+9Kc/Ud++fWn+/PlUKMCUKgL4hoTNnVu/fs0qY5PHXD9+l+nK3aDoqDnRTHuLHvhuiVZmmo66dTUuods5dNTMQLez6KhbR80MdDuHjpp17rjrqFtHzbrqZmOHNX+2NGiVsfbPlkTXR070Kmn0mOd61fKg1Md/x6CRap9rhme/a2oUFGiKGlNsSPnKDCqriEZQpYONJ05o7j2gD1FTmKgsGkHVUYYU88EHH9CsWbOs9V//+tdyedSC4+mGxXfQWWf8hhoaGui0006jbdu20V577UUvvPAClZaWUqFgiPaar7CA4RA5nnpx+/btVFVVRbrBw97mvHCJvCFJhm9QXpj7O7r96zeoKazG0Lgyt49OHj6T5r14WUbNd3zzptRsNitG7F28nYmtp9lurlt7xzbkfLyk/fndzD4j6ZWfPqPbvnm9he5Ths2i/XYaQ2+t/4pUY0bvXenlDLrn7DSG/rvxG9s5ib4zzBL7umE/d4nl5pbourWX9Rkj4bwmlid8BxEN79yXnlqzLLXm4bPo0P4T6NvaDaQaQ6p60ZNZdH9Xt1Gu289jdN0kXnvT1dv4Inu9jZan2T/2rldZNT26+r2Uuk8dvg8dPnASbfbXJh65xTHb9xrNdswKTwk9sGoJ3fZ1as0LB08lfziY43Wf+TyZG3L+WzIcLywidM+379CtaXSrasqnephgAt3ti46aGeh2Dh01p+u4m4yZ6lW2466ibu7icS9PviKxskhsnfvpBtFXy9JonuKlYbt7qLkpvj//T76XB4qXR7eleM//pdtmX49pzW0/or4D3bT6qxB9vjRIJWVEZRUGNTUIqXX0FC/1H+qm1V+Ho3+z/Rwkv2LnJMLRNGm2y++Ux0k6nym3p9gntp+3hGjuUWX0+M2N0ohK1s2m2mGnl9Mbj/kpFIpG9bjMl9uQSyPtOi+NpHVbWdr1WFnCevT45rG8PqLVy0NU1clFPQe6KVwnyF1p0IZVYaprjNDgUV65Xzr8fj+t+X41DRo00FEDhc87m1H8t/DfYEZKBQPRf29faeJd2Q6bIaJ9djeMzLpLWHeGSK98wf/Oq1atklFcyf/OufooiJQqAjhkO5W5E93mpy3N9fTm+uX0bZ0aHfghlb3o0AETsmp+Y92XymhmOvvK6Zghe9KDq5ak3M7li4bOoHu/fYe2BRpJJd3cOc+m+98r3lJGN2t+er/fpNf83RJatMsM+vNHjyqjuTW6L/rwEa1081N47uAsXHKXMrotzd9l1nz4q1cpo9mumyMWM+me/fzfaXugyTJy+T+Xadza1ploedwIttatzyRuo9YcK/a+yltG/5x0jNSXTveiodPp3KX/ofpQ6rY9H3TylNKlExdopVtHzQx0q6X5pGEzSUW4A8bRL0xyx/3rD4PS3HnjiSYKNtsfHpgfTlikKE+9Qy7HybQPdx4nzi7JqvutJ5soEEg0hiilySGybI+bH1wQSbVflk4ya5x/anl6zR8FaeQkLz1zV6NcVwXWOXS3clq3OkT7HFzSwij59IOAjOD59jO/Uro7dzfI3yiotMKgveb4Wuhe9m5Abm/2C9q2WY14EbOODB7upcjzAfL/q4mokShYTtRtPx/12N8nr4vHb0lfR3zlzTRofIS2bY6QzxtzAR1oQ7p0d0njibYLimwQRGEi4SbyVBpE1dGWYOvmiGVMqoCRg+6WjVvhAFOqCODIIn6lizrqVtKJ9v0+QtPqSkgFyioj1H3vyqyaZ30focl1sad8sYvUbMaTl/aLOO0+5nqOx0ou79GzO9VmMQB5+88au9PGTetIFXr2YN2NWXUf0tSdNmxeF70hMl+2cxFdj56N9NtbrtvPY3Tddgxzu2EkrO/cpTNta27IqHl7cwNNpK70Y1MozZ2qvXFP0dDb70CTomZyX088zs4l3bPrDjTSHuV96Yfw5uh5SNJlnru0dTrpnNr/hqx1X5bwuY6NwY+VD+jUnbYGMuveFmigYZW9aXX9pvi/YewA9n9T+4a4jsT9zS3ptpvr8cO13L9vWWfamuVc89/Uq7S6xT6pjucU3Uoq5cQO2XTzfmymicQTk9eHCVuy6K5pbqC1jVuVepggdfv10q2jZga61dJcH/RTl5IKUg3OWZOt496wXZ2Oe2sMh7pt6uhmAyoXzZVd+GZDRG9l+GGEebvES9uLWrw3H2yk2pa0bkZCZzpm7FgVVQYFAoL2mV9GIoVRwuXBgKARE73U3MB5kFoeV7440ihmBEitydoStqfQ12J70n5J2zmaiM/5vCPLUho8XO4qIZowy0ehYNRYjJivsEhaj0bNiIzrtrJ067HP8fvk/XjJ55oCgiLPByn0pG00TSPJdTYR3Pt75d/VzEPk2gnr9jbpkEaO+/IEemzmUJ0gsc22gQ2ebSL6mUqDfOz5ZDOlYh/vaC/IMGefy6abjSk3FSQwpYqAUDBICwdOpVtXtBwKwuWRYJBO7DyGhOChN/nH6FxFoUB2zSdXjyYRNjUnd8qS1tOVt3bdDC+2NscbDcPoQYavIqOZ1tVXQaeIwSQCnUgVDNGTDF+nrLp/4e9HYqsn/ihOhjvzk7rE9cTt5uNAGR+duG1HqIiQe27mc93NV0EXvRsiaigjZahoJPf0LLq95fTnV+qJGvJ145rie3uEyT01s1HcvbSSrnw7QrRJkUlde/jIPSOz5h6llXT70hKiTZXRu0Y3P45yRZduNxkeXsbW5fvYemwfEduflwavm/vz3ae1P5cbtv25jO9Q48cUbhcZfBwZK++lktKqzLpLKumGcUdRhK8/OTxCUPS+SsTKYk/ReT02fCK+X/Tf1/5ZeXnGHrOb73P9jPk9nEi5Rxbd3Usq6Yxh+1CQ24KE3ooDd3xp8Oaqe+R+cii8CuiomYFutTR38qqZi4STKGfruO+2p092oFtEA6Xz55MfaCTtkPU4yfsnveHmPBfDYfRUH4lwopHR0ugwWmyXo3USjI6YOZRs4KQwUpKNGLJt5787o+ZSHnJWTqoR8QsKPhNIbZQYRCUHeGnkOK/tCWi6V3zYXvTAaZYpPmN/mRFrsR/G1N/DeARF3khj8PC/83QPdV/H98jR48iPyffxMvtLJvG2l1n7Rz8jo4ASXkZ8m0gus39PNJE5myGcM6r55dTpXUIvB8h3sI9mfhchqkv6+2PHbK4StG4MUVWAqDSc4nrqiFtdNm3cRKIu9cG53OhsUBk3jWo02bnrliZxYQJTqggodfvohIHT5PsHVtuSWA+cKst9nhIy5u9LKuEJhbNrPmw2qUZTsDmjmSZnvfn5fqSl7qMPaNfvTGlmSeMq9gOebGLF3svPRQQ1s9k6eFrKfBkLB02joL+ZSk86LPbjm+670hhmSd+VEDefYLYlHzPV5xL/luCmGlo4aCrdmiI3E5cH128iz7ABWbXl8l0tjMKUZmL2c254vRRqDmSuI80Bcnnc6e8v2hxtlrSePIYizX5GeVnrNPPfyokcOLCulfdK8TxSmbfnREUZhf50ambd4RBVXPUAUYNCYxMqyij8p10y6g6HQzTp5tdT6zZNqkwv+cTbfCXub6TcJ/3+1quslMInDM6sOxKmKa+vIgoG4z07V4rvlEk+Uugwy83PWNtiPUjb9sTPpv+eQHUgYzsSCgRoz61qRD/byao7GKA96yui14zVE7f9+8keOqUpt4VTpCi3zqPZhpjn0/pM8jHj5f5wKKNurtvTew4nlfCHspzrcEiaV6phcO6UF9IbDu55Xtq5tzv2GxXP59OiYy5/x2KmgVVu64DbtlvGQsKxzN/geHnCd5mfN8u6RCiyJJTecJjsob4rY4Z8iz86aZlreSs/nxhVbZBrmIsi72bQPMVDwU9juZnCSQZIOMn4CMcOnKo8yfQQyWW2z4rkcrsJw+vlROWXVEhDJBWhlwLkO8hHjf+vQUacKEOlQeVXVUh9GXX/u0kZ3cbOLhK1QtaJlDSS3G4EDBKbIumdBvOa2RE/xcj9vcFzOIQzGE6xbUYpkWiZTq3FbWW7aM4Fr5FdN59H9ZrtdgGmVDEQiZBr2XI6tlt/Omm/GVTvb6ROpeUU+Ga1LKfJu6lXw3XUzAagcNEJQ/ZKbaYN2Yt8QpEoEgV0xztarfxcbMnxTzyDkNScbmahykpSDf6tPKFXN/m3p9V93E6kGiKbUcxZPH99YvymoEUCDkU1n30sUShMFOZXRH4m+j5MFIrIpZDv4/vwe5G0T/Q9l8fWbceRZUnHjX8+dkzzfbdq8jUG6YSBU9Poniq3B6oqSChkShlVFeRrDLRdt/U0uW034229hTf6dKeShubMuhsCFPhxPYl10SG1eaeijEr/dDqdMGCa/MNbaB4wjXxuDzXf96xyxmVW3S4PNf/7Sf10k4uaL7peHd25aDbU7AJwhzJrx/1cBQ2HGdmNEv8z6hgOuZok/qcV0ixHU+RolFQbaSNOWh40zYtxpVrGI3xN7zvby+jjiurJpLtekHusm8QWIb9HRrZZr9j9su0lvztFefyztm1G8vbUnzM/I4/t4/NtSCMwpe7y6PaSk0uiuSbs32E+dwm7yKg3yNXLRa4yV5tMprbcU8oHr+40Bg+Xe4hcvdTrR4psutXsRrYLmH2vCGbfY0QwRKFXl1J42Zdk+DwkAiFyTxhJnn2nkOFV88ZER82m7qaaGvJ27WyZacEtW6msWzfo7qAZhnjoEOfH4OEIMqpLwRmFdNctAkEK/e9TCnSrJN/QgQlGsa+mjjyTdyPDp9YU4zpqZtgYC1x3L4XmTGmh2/PyUvKdeUx0aKGGuqX5Zg1/SB/JlxDNZ73M6IR0UyklHseczSnTPhx15Bo+kALX35de9xlHU/jD5USBWKIPuwZrGWkZkWlGHrYY2hwvTx2NmeY7ZNIPQdS1ijzz9qLgzQ9T6JAZLTU//Rb5Tj+Sgk+9RmLzNlIFo3tn8hw8i4K3ZNH92CskNtW0/He3R9ia5eZ4erOMScj6TFnK7ePx0+ju0528J/2Mgrc+kl73aUdQ4PZHlTEuc9J85tFkdFJwaFZthJrOaEi7vezKCvJf2UTix1hkRlJHOPF9PL+PtS2hcx7vSEc7+Mn7JXa0Wx4ndvweBnnn+qjpnAy6r6mg4CsBEjW2Opdm2GCry7Pu13LYotHdIO9BJdk1s2m1PWqSWCaHO8ncsK2b26WJ0KI8ZnjY9ks+rpFif+sz0kwwyOhqUOOZ9WmNkvLrOxGZETDZzCIHH6CJkKDGMzLrNjhETSFEs6DgswEKPt7SvPQe5iPvgT4ySow2zcrWkcjJArYLEltbNvA8BI5NSxVnsROa6sbseyBn2FTw7DOZPLOnEvmbiUpLZEY7lc0GHTUzrK+sSxf5C9rZXUI816qnaxfo7iBMI8dM2KricIRC0M3mjWfKWCI2ih9/g8p9HgoHQuRT2CjWUbMVKbrrYHLf9gSFK8qovKqCwrUN5G5oItecaVHTQsFI0Vx0GyW5G69O3XaxeZlRtxDkmTyGVDMARV1DSs2irISosoJ8i+aTauSk++SfOa+rhQFmy30on1y7M+uu6kS+Xx5FSlHiy6yZ76kUxCjPEpnRxaCyi/lNzBBRBDYcMuquMqjkSLXyeOWkeaFamk2jhE3AlEbJXF90aFaZOnXDIkxZdavWM2fDyXtw9Hc7+GIgWlfKo3q53OAhZwoi24bq6HsZWReOmZ5V6ho7OutuDxSr+qAjsSICrCdjCnZqCkBzgm6PmWQbuoH+6GgUa6mZzbR9p8j34beXRaMvykrIPWea0mYadDtIJELu6RMo/NK7csiYfUgkl6tsXKqo2xpOnsG4zKbbqFBoUo0cNStZR3LouGeKzMgbGhoOWmrW2SjRVbfXkBFR3kN8RI1sZEZzH6mqN9ngkUMQubnjaDueXFpxY8fQVPeOguF7RTJ8DwAAgF5wp1ImwbabaT51h3iaQLfDQ9zfXkbU1Bw10qZPUNdIiwHdzqGjZkYEBQWfDmjVcddVt46a7RFT0le1GyUqGpYForst5Gv4HtBv+B5MqRyAKQUAAAAA1dDNSDOBbufQUbPOHXcddeuoGegBTKniwN8OplQB53AHAAAAAChceOghJ73nhNVyqYHZwEC3c+iomWFThJM+G1Wu6FITk0RH3TpqBqCQuPTSS2nixIlUWVlJPXv2pPnz59PXX39NxQRMKQAAAAAAAAAAABQ9ojlEIhQhUdccXTaHOvT73nzzTTrjjDNo6dKl9PLLL1MwGKQ5c+ZQQ0P62TELDXUHlAMAAAAAAAAAAEkEgkKOTG0KCCrzGTJ3v0/xPFi66tZRMxOJCDmHBU+mynnCOWmRK0vCcBEMU+iVbyj0xrdETUGiMi95Zg4hz5zhZHg7ZnKIF154IWH9jjvupN69e9F7739AM/eekZNu3YEpVUQEQ03kMjwUCNaRz1tJEREirzXLmproqJmBbufQUTMD3c6ho2YGup1FR906amag2zl01KxzJ1hH3TpqDoYEvfJpkN76IkhNAaIyH9GMUV7ab6yXvB51teuoW0fNTEQIqmuMUF1tyDKlKssM6lRmkCvdbKsRQaHXVlDo+a/iZU1Ba92zz9DogXLB547O7NoG3Ws3bJPvQ67O9NOWiNRdWc5fre753lFgShUJoXAzffzlv+mzr++nQKCOfL5KGjP8KNp91InkcZeQiuiomYFu59BRMwPdzqGjZga6nUVH3TpqZqDbOXTUrHMnWEfdOmpmE401v/hR0Cpj7eb67N28SppqO6Kb5yVjY4UjZnjJxmHCuhDR97Hy5H3Nz6c+RtI227H79XDR+9+E6MWPU2veYxcPfbsuHN0Qk279BfwmHKTSoKCG5giFKZLh7LTu3yubN+PzEDX4BW3fHqIelz6bsC2Q7kOdfFT6l3nRCKkUcLln9jDyX/QCUX3ao1iISw4mKmmd1eLzENU1hum8886lPSZNo+EjRst/i+08CQGxqVa4EVMwpYoAfkrGNyXLPrvFKuObE3N93MhFyj0101EzA93OoaNmBrqdQ0fNDHQ7i466ddTMQLdz6Ki5WA2HHcVuWIQjScuYWdGiPBLt4L6zPJRW8+RhHlpbE0lpgMj1HAyQVEaH9fmUJkqGYwvutAs6bmapNNFSweWzx3rphuebqLE5+TwlrSe9MdeTJ6ZP3i/TZ5O/yywvLyE664CyzLp389LfHmygOn/y+Wx5fCeoKCW6aEE5vfVles377ualpz8IUIM/9TGqSoI0b7ig7Q2CGgKZ/or2+ws56q9vFxfVNbXumEZVqcwhJYfspaIpSKK+ObpfDqbU5roIUXMmIy617rPPPpO++eoLeuTpNxO2899TxbNjFigwpYoADtvmp2Sp4PJxI0+gp1/9P3mzogL8JG/e3ldppbkYdD/z6hky/N8kHpKauEwOVTWsRydt2y9xW3RR4q2kWVP/klHz7iNPoFfe+QMFgvWkCj5vJ5o55ULoVkjzq/9lzQ0p6mVyfaXE9XT12totab+k/e212/69Xk8FTR1/Tlbd77x/OQVDjaQKXk85Tdn9bOh2AB01M9Ctlubxo04mFeGOWTbD4dElzdScpt+YD0q8RAdP9GXVffdrfmoMxIwX03SxmS/RddGy3Hqf+nPJZkurDIeYZl6vKjOotklIg8E0HO5/uzmt4ZAP+nQxZOeczbNUurmct9c2Clq3NR9WTgbd/iy6/UJGpzUHW6+bbyFcsZf13mW+N1qUJ6wbRvR9UnmPKoMamzNr5u3jB3toa71IacaVut3ybyrxGuT17YChksb8S4XHHb82yOumLX88kNyuqBHL1w3Tp4tLRh9xmf0c9ujskTmkUhpTZV4yqsuo9tRojqdslHD+qVYMt3O7iM4860x69aVn6aEnX6eddt45Qbf5N7kL1JeCKVUEsJGQzgThcr+/hpr8W6hm20pSga6dd5F6dNJcDLob/ZuU0c2aG7NobvLXUM32lcpoZqBbPc1btqmjuTW61278ALqLVLeOmhnoVkszP0Aoc3ch1eC8RtkMhxVrw+oZDjkYJWu3RhzXzf1X02ywlgZR786GHN7EkReLpvtol53cFGgU5Cs3aMVPYXpiWUAaDrv2dVNNfTTnVAsTI8H4sBkarujjmLTb2SRpYYwQGa4Ux086Bg9vYs39exh0wG4tdT//aUBuP3SyzzIgkoeVJT1jSvGQKOkcttgvsTztuq2ctVdn0c3bT5pdav2bJZyDNMaR+b4tuYtyIRQWGTVzrqOfT0s/FNjvJ1q1yqBulS4qLXWRU3C0m89LVF3mluYQR95x/WIze3tThDxlLuqeIuqIZ9njpOYJOaVicDk7RD17+DpE71lnnUVPPvEEPfLUq7T76CHS7E7WXaAj9yQwpYoATmzJ0TCpbk64vLysO00d/yuKRDp2ustccbk8VFHWQyvNxaB7yu7nUCQSf3IQD29OXLYMezYfb4iU61n3a1HOTxN8UlMmzWVl3Wj3kSdSOJI9xNYpoFs9zeNGnEDhSHOaupn45M9aT7eftVvqOpx8bbQsF+R2l+Ske8SQ+TJfjCpwfhrodgYdNTPQrZZmjiZVEU60ndFwKDNoynAPBWNpbFSAAyJYVzbd+471SqPEbsokmEWueFRL6u2xbS22p/6MaQBlMhzOPbCMtvw3SF/c00xhP5G7lKj7VK8s9/qIjt+nlFQcKnnWvDLa+HZL3VzOHfkRO3u00811o2e1c8ZNLrCmbJqpYyak2yH4tqpnlYtC9YL8W6JDWPlS8HQyZLm5noxR4pGz7DFOzr53xhln0H333UePP/4EDexTTZu+X0ehBkFVnaqpvLwsq+5CQL0rFrQ7PNMKJ7a05xUw4fKICFO/PlNItVwIumkudN39+04jnTQLEaGhg/Yn1YButTQPG3wAqUYuusfsejSpBnQ7h46aGehW6Xc9RG7ykmpk6wRzp2zm6PaPVOhwo0QQTdwlf+dbPvzg/ET2lxBU826INrwef+DIunmd+709JnuoyczLY3vGIt/aEx1ZZfF1c5fUn822X+yRjkj92bLeLtq8LL3u7uM9tPWncNp8UKnWWz4zSp2AqsXx0hw31fdWDnLTlk/S6+421kObvlPnoTVTOTiz5q5jPbTx21Da8xAwghQuExRsiJA7ZBsr18aAwRYfS3Mcd5lB4SZBwTqR8E9qrvP2QH2afE8ug9yzhlLp3F0tUyrSHKZgs0HUlHuOqNZw4403yuU++8xKKL/pytvp2CMXWbq9nQrUkSo2U+r666+nK664gtavX09jx46lxYsX06RJk6jQcQuDxu16rPwF+uybB+MzsAxbIMt5e1vgmzCKhElw1I9cRl/yvYiXxZchEiK+bv9c9DOxfSJhKt1pXEbNon4Lbf/2HVKNsiF7QbdD6KiZgW7n0FEzA93OoqNuHTUz0K2O5rbe+3U0bkG0/p1g5k7wSrU67kzlLm6qydB57zLaTZs+5Xte/idJYRBxXzci4uthsyy6f+J+5nuRWBZOKoslDDe32/GUE43+TTltWpI6DxaX957hpeXXNpIiqdJapfv7p5q11L32lYAyunPVvO7VDJo7BckzU1CQh4D6nRm6ysPd2LxpjuW5Soajp+T2hui1koogcdihIMPlIcHHiXAEW8fpr/8xJHWX9XJR0/pIypxVUnelmu12e1A0ptSDDz5Iv/rVr+imm26iyZMn09VXX01z586lr7/+mnr27EmFjOFy04Z7T6Ph006k3ee/QAH/VvKVdqHG1UtowwO/pL5H3UI/3X86RfzbWppIllmUWMbrHXVxuso604DTn6G1D5yeXvPCm6nm3Vsp0rSNVEHqHnModDuAjpoZ6HYOHTUz0O0sOurWUTMD3Wpp3umY20lFDDfRpnezdIJfU6fjbnbeu03I3nnf/L5fGd2eSkN2ctk4SwWX8/Chku4Gic0imh/JniQpeZ6PdHPVcL6jpPXM+xkZ9yvpZlCoMbPucKOgquFuCmxL7Ke0GPaUZj15cp10++d+PCJfZ0Pqyqi7SVDXcR4KbFcjX5qvOkfNu3soyJpT/P1hr5v8XoM8JQZ52pLovC0fcZuRgKm3yyC/CJGnwkhrSuUDw5Wbbv77CpGiMaWuvPJKOvXUU+nEE0+U62xOPfvss3THHXfQ7373OypkIv46al7/BW167Dx5o+Kp6E6hhs3WzVO4sUa+D2xupwSdhlsaYeSyLz0pyj1yaRiJZd4u/Sjs355Rc8RfS5WjDqJQ3QZSBU9lL+h2CB01M9DtHDpqZqDbWXTUraNmBroV09xcT+5y9RKdcyc3ayd4fKwTrAjeHDvvvfbyUrCBoy8M2QE1X5yTJ/o+Xs6BGvF9jJZl7hRlsX1blvF3JH6n7ADzTF6lUX3JcLm3yqBdTy8n1YiERUbdbLgN+nmpfro7GdTvwPRJw5XVfED2ROe+zi4qcTjROZuGqQwemRjeTeSrUit/V0661ZPcbhSFKRUIBGjZsmX0+9//3ipzuVw0e/ZsWrJkSYv9m5ub5cuktraWdMZVWkmukkqKNNdFzSfbkzwud1d0p277/lqu2w0iaSSZZpGRaCQlGE5GvIyvlvaYAUKEg1k0d6Xu+5xLqgHdzqGjZga6nUNHzQx0O4uOunXUzEC3OppdJWomOudcL1k7wfur1XHPtfPee2+1cmFFAoJ6TPPS+tdaRnhxOQ+UUDKJdTiqD7o7Hh01S0T0mrPnlDLhcjnYR8WRcEJT3e1AAfttcTZv3kzhcJh69eqVUM7rnF8qmUsvvZSqq6utV79+/UhnOHdT9YSFKbfJchGm8gGT5Kus/wQq23kclfYdQyW9R1BJz2Hk6z6EfN0Gyggmb3Uf8lT2JE9FN3KXdSY339j4ysjw+GJRT4YjmmU+KgWBbufQUTMD3c6ho2YGup1FR906amag2zl01GzvBKfC6gQriI663T6D+szwUu99vNI4k2WlJNe5nLerCHQ7h46aGY4Y5LxRnIPJGhFqkFznchlRqCCGprrbg6KIlGotHFHF+afskVI6G1Mubxl1nhIdtrh92QPyqRk/JeObEi53edR74qSjZga6nUNHzQx0O4eOmhnodhYddeuomYFu59BRs70TzHBuKXMWOzZ2uNzlVbNTpqtu1tV7upf6zPRamtlAU1WvCXQ7h46a4wZP1NCRuZhiucpVN3YMTXXvKIaQc4QW/vC98vJyeuSRR2j+/PlW+aJFi2jbtm305JNPZvw8m1IcMbV9+3aqqqoiXYkEm+SQPM4jwGHbIhySUU4qo6NmBrqdQ0fNDHQ7h46aGeh2Fh1166iZgW7n0FEzEw4ImffF3glWNSqjEHQD0BH4/X5atWoVDRgwQPbFQWHS2NhIa9asoUGDBlFpaWmbfJSiMKUYnnFv0qRJtHjxYrkeiUSof//+dOaZZ2ZNdF4ophQAAAAAAAAAANDRcH97xYoV5Ha7qUePHuTz+dot1QvIP2wjcfDPpk2bZKqkoUOHyrzdbfFRimb4Hg/H48ioPfbYQ5pTV199NTU0NFiz8QEAAAAAAAAAAGDHYYOCo2fWrVtHa9euzbcc0EFwFBwH+yQbUq2haEypBQsWSBfvwgsvlMnNx40bRy+88EKL5OcAAAAAAAAAAADYMTg6ig2LUCgko2lAYeF2u8nj8exwBFzRDN/bETB8DwAAAAAAAAAAAKB9fZS2x1gBAAAAAAAAAAAAANBGYEoBAAAAAAAAAAAAAMeBKQUAAAAAAAAAAAAAHAemFAAAAAAAAAAAAABwHJhSAAAAAAAAAAAAAMBxYEoBAAAAAAAAAAAAAMeBKQUAAAAAAAAAAAAAHAemFAAAAAAAAAAAAABwHJhSAAAAAAAAAAAAAMBxYEoBAAAAAAAAAAAAAMeBKQUAAAAAAAAAAAAAHAemFAAAAAAAAAAAAABwHI/zX6kfQgi5rK2tzbcUAAAAAAAAAAAAAKUx/RPTT0kHTKkcqKurk8t+/frlWwoAAAAAAAAAAACANn5KdXV12u2GyGZbAYpEIrR27VqqrKwkwzBId7eSzbUffviBqqqqSAd01MxAt3PoqJmBbufQUTMD3c6io24dNTPQ7Rw6amag2zl01MxAt3PoqJmB7vzCVhMbUn379iWXK33mKERK5QCfwJ133pkKCa7culVwHTUz0O0cOmpmoNs5dNTMQLez6KhbR80MdDuHjpoZ6HYOHTUz0O0cOmpmoDt/ZIqQMkGicwAAAAAAAAAAAADgODClAAAAAAAAAAAAAIDjwJQqMkpKSuiiiy6SS13QUTMD3c6ho2YGup1DR80MdDuLjrp11MxAt3PoqJmBbufQUTMD3c6ho2YGuvUAic4BAAAAAAAAAAAAgOMgUgoAAAAAAAAAAAAAOA5MKQAAAAAAAAAAAADgODClAAAAAAAAAAAAAIDjwJQCrebDDz8kv99POvHNN99QMBgk3YBu51i7di1FIhHSjdraWtIRHXXrqFnX61HXa1JHzQx0O4uObYmOmnXWrWPd1vVcQ7dz6KiZge6OB6YUaBU33ngj/fznP6c1a9aQLtxwww10zDHH0Pr160knoNs5rrvuOjrxxBOppqaGdGLx4sX0i1/8ghoaGkgndNSto2Zdr0ddr0kdNTPQ7Sw6tiU6atZZt451W9dzDd3OoaNmBrodgmffAyAXbrrpJuFyucQjjzwidOHGG28UhmGIhx9+WOgEdDtbr1nzQw89JHTC1P3ggw8KndBRt46adb0edb0mddTMQLez6NiW6Ki5EHTrVLd1P9fQ3fHoqJmBbueAKQVygn8cuXK/9tprcj0cDgvV4QuRNb/zzjtyPRQKCR2Abue4//77peY333xTm3rN3Hvvvdpdj7rq1lGzrtejrtekjpoZ6HYWHdsSHTXrrFvHuq3ruYZu59BRMwPdzoLheyArt9xyCy1YsEC+/+GHH+TS5VK76tx22220cOFC+b6urs7SzEasykC3c9x+++109NFHU/fu3cnn88kywzCU1szceeeddOyxx9LIkSOpT58+WpxrXXXrqFnX61HXa1JHzQx0O4uObYmOmnXWrWPd1vVcQ7dz6KiZge484LAJBjTj5ptvFm63WzzwwAPimmuukc7rDTfcIFTX7PV6Zeji+eefL6qqqhKGr0QiEaEi0O285ksuuUScdNJJYvTo0eKll14SqmPqPu+888TBBx8sDjjgAPG///1PqI6OunXUrOv1qOs1qaNmBrqdRce2REfNhaBbp7qt+7mG7o5HR80MdOcHmFIgLRz2xybUE088IdcbGhrEpZdeqrQx9fTTT0t9Tz75pFxftWqVOOuss5TvmEG3czz++ONS81NPPSXX3333XXHUUUcpfxPI55N18zlnHnvsMbHffvvJH5333ntPqIqOunXUzDzzzDPaXY+6XpM6amag21l0bEt01Kyzbh3rtq7nGrqdQ0fNDHTnD5hSICPLli1LWG9sbFTemDJzqJisXr1ai47ZkiVLtNT91ltvaaV7zZo1Vr4G+7lX+SaQx4Oz5ldeeaXFzSz/6Bx44IHK/uiw7ldffVUr3bqea13bP74m33jjDa2uSdac3PaprtnU/frrr2upG+22M+jYZjM6nmsd67au9ZpB3XYG1BHneVPT820HphRoQbaEaCoaU9u3bxc//PBDQpk9sa+9Y2bOHqhCp4wjGT788EO51Ek3P9Gzz8LIdcauS1Xdydg1LV261LoJfPnll4UqcH0IBAItylT/0dm6davYuHFjwjlWXTd3BD7//POEem1vD1XUnO7a0uF6bGpqkvXEjr2OqHhNrlu3TqxcuVJs27ZNG80M36zajb/kNltV3anQQbeO7baObbbO7baOdVvHes2gbjsH6oizLNGwjqQDphRI4NlnnxX/+Mc/5FC9TB0X05jyeDziiiuuEPnkvvvuE7NnzxZ9+vQRhx56aNrpz7ljdvbZZ4suXbqIu+++W+Sbu+66S4wbN0706tVLTJw4UVx11VVa6P7ss8+kIbnTTjslTFmcXFdU0v3222/Lhjtb551vAo8++mgxduxYKwQ2n/CPybHHHiv22GMPOUZ8w4YNlma7bt5vzpw5cgx5cqRMvq7JfffdV9aRn/3sZ9J4NVFVN3fYuV7zv39yhKiqmk2zgXP+NTc3Z2yzVboeGW47uL0eOnSoOOGEE8T777+v/DX5n//8R0ydOlX06NFD1m+uC6prZvhGlOv2nnvumdC5TW5HVNONdts5dGyzdW63dazbOtZrBnXbOVBHnOUNDetIJmBKAYtHH31UVu7hw4eLf/3rXzkZU3/4wx/kjW6+nrpzJ4Gf/v/zn/+UJg83KvziyKl0YdLHH3+8dI3zyb///W9RUVEhNf/3v/+VmthYCwaD1j7296roZjhKYPDgweK0004To0aNklPPmyTXAxV0m1MsT5gwIeGHJtNN4Lx588Rxxx0n8smdd94pDYRzzjlH/Pa3vxWVlZXilFNOSaubc7+NHz9e3gjkWzdrvfzyy+UPPf/I/+IXv0jYx163VdHN9cTn84l99tlHLFq0SHz00UcJ2+1P/lTRzMYO1+0xY8bI9tvUmK49VuF6NNu/6upqceGFF8q2e9CgQWL+/PlKX5PcVnfq1ElGBz/33HNir732EkcccUTaeq2CZhMeZti1a1dx5JFHyn97e4h/KmNKBd1ot51D1zZb13Zbx7qtY71mULedA3XEee7XrI5kA6YUkKxYsUJMmzZNztbEjQhH7nAEVDZjip/Om9ucNqb4x5xNkdtuu80q+/HHH0V5eXnCE+xk1q9fn3WIYkfCMyEMHDhQ3HPPPQlJ5RcuXCgTXNpvUuwNSr512zXNmjVLdohPPvlkaWI+//zz1t9mD3fNt+5PP/1UNsJ/+tOfxIgRI2RkWvLTBBN7/f3iiy/yeq75KSp31O0RLZwHpnPnzglhusm6ufOZT91cj/kHnSN3TBYvXizbFTZE2MhO9SOfb93Md999Jw0bvinZfffdZQeAo4vs59iuMd+aly9fLtvp3//+9/IJGNdzHpqXzZjKdzvCbcSwYcPkjaD9bykpKWmRo0mVa5Kvx379+ol7773XKmMz/vTTT5fXI//upGqz892OmNTU1IiDDjpIauakp3wD+8EHH8ht5rB3Vc41g3bbOXRus3Vst3Ws2zrWawZ12zlQR/LDdxrVkVyAKQUkmzdvFhdccIFliPDNdiZjKtl4cNqQ4u/jmQU4ZNG8AM0GgyO3zAYmk+Z8XZg8lOLaa6+1wloZfgrWt29fOZRvt912S4hkSD63+WxQ+Bxzfdh7772lI//NN9+IM888U+y6664y8oGjp3ifVPUhH7rZ5OMhS99//73sLLJO8yYwlUb7j06+NHM95WmhDz/8cCvij3VwPeeOMd/UpvqMCrpvv/12+bSpvr7eKmcDk4do8c0JRzFefPHFaXXmq25zXWBjfsiQIaK2tlY+fZo8ebL8ged6/etf/1o5zXzt/eY3vxFfffWVPPdz585tYUypVkf4O2+99VaxYMECq/3ja47rOXfQkhNwq6Cbv49nNbzyyisT8l9xGz1gwABZr6dMmZLwRFiVOmKePz7XnJeG20FOhsrDE/ha5LrN7bcZLaXKbw3abWfQuc3Wtd3WrW7rWK9NDajbzoA6kh8iGtWRXIEpBSzq6uqs936/P8GYMt3i5KS0+eSnn36SnQUT8wedOwu33HKLUBWOLtu0aZO1zokseTgc35Sw6815vbiRsUeAqQYnTTb18RP3bt26yaEtqp13NtD4nNrXzZtAM1LALFcJNhx4uJC9bvM1yREmybM0qgQnf7Yn7eecQf3795eRdDwE4Ze//KVsUzgyRiXMH2geb2/eQPHQYB5iy2axKklmkzsrHPVkwm20aUxxXj2zM8M3KyrB9SNVLjoeymJOia4afMNqj4Y65JBD5M0252bgp8BXX321krNk2c8v5/l48cUX5fsXXnhB3rR27949bQ7GfIJ22zl0bbN1bbd1rNs61msGdds5UEecJ6xZHckFmFKgBWZnhp/icOQLX5CcY4ov3OnTp8uwxnyT/ETJPoSQneLLLrvM2sbmGl+oqsJhr/zUzISfanOHh0NIVTalzj33XPmeb6a4Q8nuPHfM7D9MKmEmgubOOw85ZN0c7cWzabF2+9CcfJLuCQZfl/xjyaalCU82kOoplCrnm4do2X/w+Yedc2nYzWSV4KFNnO+I2xGuH2Zn4aSTTlJ61hIzMopvAnkoH1+PHEnKQ7P4hoWjfFQgXUQt13k+1/Yhffw7o6LJw3DCYXu95ifCbMqr/DvDDz+4vWC4TnNELpuY/LK3KaqBdts5dGyzdW63dajbhVCvGdTtjgN1JL8coEEdyRUXAZCEx+OhcDhMXq+XrrvuOpowYQLdd999NHnyZNqyZQv97W9/y7dEMgwj5Tovq6urqXv37nJ97ty59Morr9DChQtJVfbaay/q16+ftR4KhWjQoEE0YMAAUpWDDjqINm7cSGPGjKHKykp688036fzzz6ddd92VXnzxRVIRn88nz21ZWRl9/PHH1NzcTCeccALtu+++tHTpUjryyCNJBVyuls0yP0Bg7SUlJdStWzdZNmfOHLrpppto5MiRpOr55vM7cOBAqZ/x+/00depU5ep2JBKRS9a2cuVKuayqqqLPP/+c/vCHP8g2RNV6zXBbzW0214+nnnqKevToIdvp6dOn04oVK+iss84iFUhutxmuG1znuR2xt9sPPfQQ7bPPPqRq+8f12iQYDNK4ceMSylTBvPa4vfjxxx9pjz32kHX7vffeo9/97ndUW1urdN1Gu+0cOrXZhdBu61C3C6FeM6jbHQfqSH6IaFRHcibfrhhQF9P95qftHA7IeTPMKKrkce4qPYXnfBk33XSTnM2JQ0fNKILkMcyqDqHkyIYZM2Yorfezzz6TTw9mzpyZkBuLxzerOlbZxDyvHN3AfwMn+Fe9jrAurhs8LTTP1sghxvw0xNSt6jm3R8ZwFA8Pe+KnOqrqffLJJ616bR8ax2HQqtYNO6ZGTtDJf8fUqVOtOqJim81wXWDdnKeOJ6jgdpujBlS+Ju31mqMcuM3m3BOq1mszIjdVm/3+++8rrdsE7bYz6NZmF1K7rUvd1rFeM6jbzoE64hxPalpHUmHw//JtjAF1qampoZkzZ8qn8J988omMomL3m5cqwtWZnzK98cYbNGLECPn0iaMIVNbMNDU10csvv0w33HADrV+/nt5//30r+sHtdpNq7jw/GVm+fLl8AtKzZ8+0+6jKpk2bZLRDfX29FvXajMbgyLQffviBdtppJ/riiy+0qNt8jvl6vPnmm2n16tX04YcfSt0q1pFt27bR66+/Tnvuuaes19ye2KN7VLwek9m8ebN8IslP3XWp21wXJk6cSB999BENGzaMPvvsM+XrdmNjI7366qt044030k8//UQffPCBsvXarMdvv/02DR8+PGXdVlF3Mmi3nUGnNrtQ2m3d6raO9ZpB3XYO1BFn2KZxHUlGvbMLOgTTe2ytB9m1a1fab7/9ZGfB6R/JtmjmRqN///7SSOMf9nw0gG3RzSGibPJwh8Hs3LBuJxuSXHWbjTKbfqkMKfs+Kput3Pll01L1mz97J3jr1q00ePBg+vLLL7X4cWcaGhrk8F8eosDtiKlbxTrSuXNnOuyww6x6nTzcTIcfdj6/kyZNykub3VYCgQCVlpZK3Rx6rkPd5uuRbwR79+5Ny5YtU7pem/WYh3Omq9sq6k4G7bYz6NRmq9Zut/VeO591uy2aVajXbdGtQt1ujW6V6rZpcOhUR9qiW4U60hrdqtWRHQGRUkUCX2QVFRXy6TmP8c3F8U3eh11vvjhV1szwU2vuKPCF6LTmHdFtfo7JR8PdVt35JPnfN/kJQTrs++WjjrRWt7md8wNxvrF8dcjaer75hpt/OLk+Oa27rZoLgXzU7bbCTyQ5tx6326p32k04HxPnwuL6pItmncl3u91aVGm320I+22yd4Y44d2a5fnKOGh3uSVqrWZV63dZzne+63Vbd+YSjlznqKdfIG1XqSGt1q1JHPmujbt2BKVUE3H///fTwww/L8OCdd96ZTjvtNJo1a1bWz+WzoWyrZnvjkY8Lua267VrzYQbpWEceeeQReu655+j777+XQzY59J0b8WznL99mW1t1229U81G326rbrtXp+tJWzfm+SeThu+Xl5TRq1KhWfS7fdbutuvPZbrdVcz7r9Y7oznfd5uvx3Xffpa+++kpOQDJjxoy0Ebcq1e226s5nu91Wzfmu223Vne+6zb83/GKDnaMSzzjjjJwmP8hn3W6rZhXuR9qiO991u62681m3H330UTriiCNkv4ATlef6b57vOtJW3fmuI4+2UXe+27/2QO0wCLDD/Oc//6FTTjlFDmebN2+eHCLB+UZuueUWOW42l8r9/PPPyxsEHTSbHRvW/L///Y+cZEd0m40N6+ZZV5xExzpyzz330LHHHitnGePZJniGCTYdXnrpJXlzl85rN2f6YpYsWSI7w06yI7rNH3euH04/S9gR3Wbd5vPdmhDqfGo263U+6ggbxJwb4LLLLpM5GHLFXrd5WNmaNWtIF91mu826eYY4HTSb9Zo1s+npJDui26zb+agjd955p7wmOW8iRzRfcMEFcpZF+0xCKrbbO6I7X+32jmjOV5u9o7rz2W7fcccddOKJJ9Lo0aNp7Nix8vri+yJTm4p1e0c05/N+ZEd057Nu74jufNZtvhY5XQcPrT/99NNlGZ9HVdu+HdWdzzqyI7rzWUfajXxnWgcdx5YtW+SMRrfccotV9u2334oePXoIn88nrrzyyhazDSSv33jjjcLtdsvZE6AZulXQ3dDQIGbPni0uvvhiq+zzzz8Xp556qtTx7LPPyrLk2TLsmm+44QY5W8Wnn37qiGbodla3jpoZvoZGjRolDjroIDF58mRx8skny5kus5FKN8+q5hQ66tZRs866X3rpJdG3b1/x8MMPW2VnnXWWGDFiRMaZjfJ9TeqoW0fNOut++umnRc+ePcWjjz5qlR1++OHiX//6l5z1lH+PVPu90VEzdDuvm7nrrrvkTL7cH+DfntNOO83atn379hb7q6CZgW79gClVwPz444+yEXzssccSKu5RRx0ljjnmGFlxecrIdJX7pptuEp07d064QYBm6M637m3btolBgwaJxYsXJ5Rv2rRJ/OIXvxAVFRXivffey6i5S5cujp9r6EYdycZTTz0ljjjiCLF27Vpx9913i/Hjx2c1HaC7eDTrqruxsVFccMEF4uyzzxb19fXWtOBsFA8ZMiRhGmvoLj7NOutuamqSxsJf/vIXOYW8yYwZM8S0adNkp3LOnDninXfeSdCbT906aobu/PzeMEuXLhXHHnusvCb57xg3bpw4/fTTxe677y71sKlmoopm6NYTmFIFTG1trdhvv/3EOeecIztjDFfWTp06iU8++UQsWLBAHHbYYVYFT67cVVVV4pFHHoFm6FZONzfY8+bNE5s3b04oX7VqlTjkkEOkocY3AippZqAbmrN1zL788ktr/c4777RMB/uTL/N6tN+cQHfha9ZZ98033yyeeOKJhLKvv/5aVFZWiuXLl7fYPxQKWe+hu/A166ybf1O+//57a/2AAw6QD0X4Xoqj0Pkh3+jRo+VDQFV+b3TUDN35uf/jvsFuu+0mtbGuf/7zn7KPwAbI1q1brWtRJc3QrScwpQoQ+w/1ZZddJqZMmSJGjhwpFi5cKCNf7rjjDmvbrrvumuDcm8OxqqurHa3cOmqGbud1m9x2223yqcHVV18tjTU7l19+uejfv7+oqalJKL/++utF165d89poQ7dz6Kg5FXbT4YsvvpBh/nwDa++kQXfxatZRt3kzzTfdvXv3FitWrLC2XXPNNTIKzAS6i0+zzrrZNF60aJFMg2DCkejdunVrMaRGFd06amagu+Phhxo8ZGzMmDHSWGO4r8DRixzhdeaZZ7b4TL41M9CtJzClCgh+omRihj4zPIb5t7/9rQyLfvPNN61yHtrCkQTmGGa+Cfjmm29ajOmHZujOp27OocIm2HXXXZegjfMDDR8+XDbI9miY1157TXbQ7DetPFSLzbaHHnrIEc3Q7axuHTUn637rrbcSttlzS3COgT322ENGf40dO1YMHjzYioDhYVvQXZiaC0W3/Zq0a+ZrcpdddhEbNmyQ6/vuu6/8G8yHJpzzCroLU3Oh6LZfk/aoRMbU+MYbb8j8b6tXr1biN1IXzdCtRh1huG9wzz33yN+WmTNnipUrV4prr71W9OrVS1xxxRV50wzd7zmuuyOBKVUg3HfffaKkpERcdNFFVllzc3PCPnZjgbdxgmvutCVjDzHtSHTUzEC3c7pvv/12+ZSUG2W+MeXIFzP/FXPSSSfJRps1cuPM+Sd4bD4PSbSHtvJ7jiBwCuh2TreOmtPpfvLJJxP2sXfO2CDmm4+JEydahrJ5Q8s3LNBdWJoLTTfnwkqGO2B8k83XJA+pHTZsmKWb/y4VrknVdeuoudB0J1+T9t8VjjLnSQk4qbVKv5Gqa4ZuteoI5zTi3xa+dzINYh5K9sADDySMvFDtXEO3XsCUKgD4qf/AgQOlgcBjkjmZnklyQjRef/zxx8WsWbPkvvZcQckzrEEzdOdTN9+gdu/eXTbCZsPLCX7PPffcBB3/+Mc/5Exr3ICz+cBDEe03rU4D3dC8I7qZ5BvTjRs3yoSoHCFgzxWk0vlWVbeOmotFNz/c6NOnj4zqspsNydEE0F04motFN+cr/PDDD2WkOf/mmHpVvh5V0QzdatUR0zi75JJLrOjy5L6A3SiB7sLU7QQwpTSHG7Hzzz9fHH/88TIKgM0GzgH05z//OWXl5caOx51yAut8/bjrqBm6ndXNs6ex3vPOOy+hnKdIHTp0qByTb//h5qiuDz74QA5PNMvzca6hG5rbQ3cyPAPmgAED8tqO6KhbR83FpJvzBXFy1unTp0N3EWguJt38IJDzBnEEjC51RAXNDHSrpTkf5l42oLsw8RDQGo/HQ+eccw59/vnnNHHiROrXrx9FIhF64IEH5PaLLrqI3G43m49kGAa5XC46/PDD5YsJhULyGNAM3SrpZg2jRo2isWPHynVT24gRI+TS1Gni8/lowoQJ1jr/ffk419ANze2hO5nZs2fTqlWr5LZ8tSM66tZRczHp3mmnnejSSy+l0047TeqF7sLWXEy6Z82aRZ07d5b782d1qCMqaIZute+jzHun5DKnge4CJd+uGGh/ONyP8wbZo2F4lilOqKaqA6ujZga6O45169ZZ783Q1Y8//ljOSmGfTe2ll14SKgHdzqGjZga6nUNHzcWg+/nnn1dqOIKOunXUXAy6X3jhhYTP5fOeSkfNDHQ7R6H/1kC3PiBSSkOWLFlCGzdupK1bt9LPf/5zqqiokO4qu6m87NOnj3yqxO8feughamxslJ/59ttvZTk0Q7eKuk3NW7ZsoQULFlDPnj1bPCWora2Vr5KSErm+//7709q1a+njjz9OGT0A3YWlW0fN0A3N0J1a99y5c+U6a+doXeguPM3FqnvOnDnWNelklIOOmqFbnzqi628NdGtCvl0x0DpuueUW0bVrV+moduvWTSZ/vOOOO6zpzs3ZSJj169eL3/zmNzK576RJk6wxy04n2dZRM3Tnt44MGTIkQbOph58cDBo0SNTX18uZeIYPH67UuYZuaIZu1BHohm5ohm7UEehWTbeOmqE7IooFmFIa8dFHH4m+ffuKRx99VFZonrnhuOOOEyNHjhQXXnihnH3HXoG5co8fP16+7LPxQDN0q6Q7V81miCvPCDhhwgTZuOczqSV0QzN0q6NbR83QDd2Fqhm6UUegWy3dOmqG7qAoJookc1ZhsG3bNpkEb9y4cdStWzcqLS2lu+++mw4++GB67LHH6N5776Xm5mZrmNZll11G4XCYli5dmrcEkTpqhm416wjT0NBAX3zxhUwOuHz5cvJ6vcqfa+guTs3QjToC3dBdrJqhG3UEutXSraNm6PZQUZFvVwzkDk/5zK7rl19+KdfZdTX55S9/KQYOHChWrlxplW3atMlKDJkvt1VHzQx0q6n522+/FX/5y1/yGo1mAt3QnA3ohuZsQLez6KhbR80MdENzNqAbmrMB3cUDTCnNGDVqlJg7d6617vf7rfcjRowQZ5xxRotZSvI9G4WOmhnoVk+zHRUabeh2Dh01M9DtHDpqZqDbWXTUraNmBrqdQ0fNDHQ7h46aGeguDjB8T2E48/7q1atp06ZNVtktt9xCH374IR1zzDFynTP18zAsZsyYMVaWfvssJU7O6qCjZujWp47YcTqsFbqd062jZga6UUeyAd3QXYiaGehGHckGdKOOZAO6PVSswJRSFB5retBBB9GsWbNo+PDhchwqw2NTr7nmGnrppZfoZz/7GdXX18sxqRz19v3331OnTp2gGbqV1a2jZuiGZuhWS7eOmqEbugtVM3RDM3SrpVtHzdANMHxPQe655x7RqVMncdttt4m3335b/PGPfxSlpaVi+fLlcntjY6N47rnnxIABA8TgwYPFlClTxOTJk2UoYL7C/nTUDN3QDN1q6dZRM3RDM3RDd7Fqhm5ohm61dOuoGboBA1NKMTgh2qRJk8TNN9+cUM7TRF5xxRUJZTw2lcv++te/issvvzxvCdJ01MxANzRnA7qhORvQDc3ZgG5n0VG3jpoZ6IbmbEA3NGcDugFTvAMXFcUM5ZsxY4ZcsnHIY055OskNGzZYZfzisannnXdewufD4bDj41F11AzdqCPQrZZuHTVDN+oIdEN3sWqGbtQR6FZLt46aoRtWjAlySilGv3796LHHHqNdd91VrgeDQbns27cvlZWVyfdc4TkxdU1NTYvP25NXO4WOmhnodg4dNTPQ7Rw6amag2zl01MxAt7PoqFtHzQx0O4eOmhnodg4dNTPQDRiYUgqy0047ySU7q16v13JTt2zZYpUvWLBAXgiqoKNmBrqdQ0fNDHQ7h46aGeh2Dh01M9DtLDrq1lEzA93OoaNmBrqdQ0fNDHQDxIwpjH2qyFAoZL3nDP+ffPIJ3XPPPaQaOmpmoNs5dNTMQLdz6KiZgW7n0FEzA93OoqNuHTUz0O0cOmpmoNs5dNTMQHfxgkgpxYlEInJZVVUlx66y27pixQpatWqVdGTtFV8VdNTMQLdz6KiZgW7n0FEzA93OoaNmBrqdRUfdOmpmoNs5dNTMQLdz6KiZge7iBKaU4vA4VIYr8hVXXEErV66kL774wqrcKiZI01EzA93OoaNmBrqdQ0fNDHQ7h46aGeh2Fh1166iZgW7n0FEzA93OoaNmBrqLFExCqAdvv/22GDp0qFZTSOqomYFu59BRMwPdzqGjZga6nUNHzQx0O4uOunXUzEC3c+iomYFu59BRMwPdxYXB/8u3MQZyw5xqUie3VUfNDHQ7h46aGeh2Dh01M9DtHDpqZqDbWXTUraNmBrqdQ0fNDHQ7h46aGeguHmBKaYZZyXVCR80MdDuHjpoZ6HYOHTUz0O0cOmpmoNtZdNSto2YGup1DR80MdDuHjpoZ6C4OYEoBAAAAAAAAAAAAAMdBonMAAAAAAAAAAAAA4DgwpQAAAAAAAAAAAACA48CUAgAAAAAAAAAAAACOA1MKAAAAAAAAAAAAADgOTCkAAAAAAAAAAAAA4DgwpQAAAABQUJxwwgk0f/78vH3/cccdR5dccknevr9YWbhwIf3rX//KtwwAAAAAtAKYUgAAAADQBsMwMr7+/Oc/0zXXXEN33XVXXvR98skn9Nxzz9HZZ59Nzc3NNGrUKDrttNNa7Pfb3/6WBg0aRHV1dXnR2dTURBdddBENGzaMSkpKqHv37nTEEUfQF1984ZgG/rcaN25cux3vggsuoL///e+0ffv2djsmAAAAADoWmFIAAAAA0IZ169ZZr6uvvpqqqqoSys477zyqrq6mzp0750Xf4sWLpbnTqVMnafbcfffd0iB78cUXrX2WLl1KV111lSyvrKxs1+8XQlAoFMq4D5tls2fPpjvuuIMuvvhi+uabb6SRxp+bPHmy1NeR5KKxNQQCAbkcPXo0DRkyhO655552OzYAAAAAOhaYUgAAAADQht69e1svNp84OspexmZQ8vC9mTNn0llnnUXnnHMOdenShXr16kW33norNTQ00IknniiNoV122YWef/75hO/6/PPPaf/995fH5M/wsLzNmzen1RYOh+mRRx6hgw8+2CqbMGEC/fGPf6STTz6Ztm3bRn6/X34n69l7773pnXfeoenTp1NZWRn169dPRlixLpP//Oc/tMcee0iN/PcdffTRtHHjRmv7G2+8Ic8Ba+fvYiOMj5kJNvOWLFlCzzzzDB155JE0YMAAmjRpEj366KM0YsQIqZWNI/Pc8Xmzw+eWz/GOaGTj6C9/+YuMLDOj3MzoNj5Pp5xyCvXo0UOajvvss4/cLznC6rbbbpPRZqWlpdY2PvcPPPBAxr8fAAAAAOoAUwoAAAAABc+///1vOUTtvffek4bQ//3f/8mIpmnTptGHH35Ic+bMkaZTY2OjZYywGbL77rvTBx98QC+88AJt2LBBmjjp+PTTT+XQMTZo7LApxWYNG048xIwNGM459e2339K8efPo8MMPl5998MEHpaF05plnWp8NBoP0t7/9TZoyTzzxBK1evTrBEDL53e9+R5dddhktX76cdtttt4zn4r777qP99tuPxo4dm1Ducrno3HPPpS+//DLBBMpGWzTy9//617+WwxvNKLcFCxbI/fjfhU0tNrGWLVtG48ePp3333ZdqamqsY61cuVKaaI899hh9/PHHVjmba/xvzNFgAAAAAFAfT74FAAAAAAB0NGzAsCHE/P73v5fmCJtUp556qiy78MIL6cYbb5Tm0JQpU+i6666ThpQ9YTkPd+NoJh7uxrmYklmzZg253W7q2bNnQrnH45HD+DhKKBKJ0H//+18Z3XPppZfSMcccY0UiDR06lK699loZQcVaeJ+TTjrJOs7gwYPl9okTJ1J9fb2M4DL561//Ko2eXGD9s2bNSrmNI6XMfXLN99RWjbyNzw0bdiZsyrGpxKYUR1Qx//znP6XZxVFoZn4uHrLH55Sjqez07dtXblu/fr2MAAMAAACA2sCUAgAAAEDBY48eYuOoW7duNGbMGKuMh+cx5rAzjvp5/fXXE0wVE45wSmVKcfJwNlI4EiqZkSNHyogojsAyI6n4O9gEu/fee639eNgcG1erVq2SBhFHCvFwNd5369atchvz/fffy2OaJEdnZcMcnpcOn8+X87HaUyMfg80s/vdJPrd83k3YcEo2pBgeBsmYEW8AAAAAUBuYUgAAAAAoeLxeb8I6G0f2MtNIMg0VNkY4P9E//vGPFsfq06dPyu/gyCs2QzhSJ5Wpw1FB/DLh7zj99NPlsL5k+vfvL3NLzZ07V77YuGITho0eXjeTe5tUVFRQrnBEFg+hS4VZbppuPKQv2cDi4Xom7a2RzwmfX85DlYw9eX26Y5lD/FIZVgAAAABQD5hSAAAAAABJcB4jzlk0cODABCMpE+ZwN87JlMvQN/4O3peTrKfis88+oy1btsihhjxskOH8VjvKUUcdJfNccVSSPa8UG3I8KyBHNJkRTmzucL4nezJ3TgBvDv/76quv2qyRjTs+XvI54aF3fM753LcW1rbzzjtLgxAAAAAA6oNE5wAAAAAASZxxxhky6oYNnPfff18OHXvxxRflzHnJRooJGzhsqmSb/c7k/PPPp3fffVcmNudk3StWrKAnn3zSSnTO0VJs3CxevJi+++47euqpp2RC8R2Fk5lzQnCOBHv44YdlZBP/jTy8kDVwUngTTvb+7LPPyhcbUJwgnocgmuyIRjadeJgi/+08qyEnJ589ezZNnTpVzvD30ksvyaTpfI7YRMvF7Hr77bdl0noAAAAA6AFMKQAAAACAJDhhNickZwOKTQ7OP8UJyXkIGQ9pS8cpp5ySkCMqW56rN998UyYVnz59ukyszgnX+btNk+uuu+6SxhFHLnE0Eif93lE4gfqrr75Kxx9/vEz6PmTIEGlScZQRv+x5oDiJ+aJFi+S+nICdE5nbk6TviEY2wXj2QT4eH+f++++Xwyife+45mjFjhjQAeRjhwoULZRJ5M+9XOvx+v0yIbiavBwAAAID6GCJbpksAAAAAAJATnJB7+PDh9OCDD8qIH114/vnn6bDDDpOGkhmppRs8Y+Hjjz8uI6wAAAAAoAeIlAIAAAAAaCd49re7775bDkfTif33318aUzxkUTftJpy4nocRAgAAAEAfECkFAAAAAFBAjBo1Sg53S8XNN99MxxxzjOOaAAAAAABSAVMKAAAAAKCAYEMqGAym3MZ5mSorKx3XBAAAAACQCphSAAAAAAAAAAAAAMBxkFMKAAAAAAAAAAAAADgOTCkAAAAAAAAAAAAA4DgwpQAAAAAAAAAAAACA48CUAgAAAAAAAAAAAACOA1MKAAAAAAAAAAAAADgOTCkAAAAAAAAAAAAA4DgwpQAAAAAAAAAAAACA48CUAgAAAAAAAAAAAADkNP8fS0O6qoY1BrEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We collect all quarterly HUT files from the exploitation zone\n",
    "hut_files = sorted(glob(f\"{exploitation}/hut_district_20*_*.parquet\"))\n",
    "\n",
    "dfs = []\n",
    "for file in hut_files:\n",
    "    name = os.path.basename(file).replace(\"hut_district_\", \"\").replace(\".parquet\", \"\")\n",
    "    year, quarter = name.split(\"_\")\n",
    "    df_temp = spark.read.parquet(file).toPandas()\n",
    "    df_temp[\"YEAR\"] = int(year)\n",
    "    df_temp[\"QUARTER\"] = quarter\n",
    "    dfs.append(df_temp)\n",
    "\n",
    "df_hut_time = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Optional: sort quarters\n",
    "quarter_order = [\"1T\", \"2T\", \"3T\", \"4T\"]\n",
    "df_hut_time[\"QUARTER\"] = pd.Categorical(df_hut_time[\"QUARTER\"], categories=quarter_order, ordered=True)\n",
    "df_hut_time[\"TIME\"] = df_hut_time[\"YEAR\"].astype(str) + \"_\" + df_hut_time[\"QUARTER\"].astype(str)\n",
    "\n",
    "# We plot total tourist licenses per quarter\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df_hut_time, x=\"TIME\", y=\"TOTAL\", hue=\"COD_DISTRICTE\", marker=\"o\")\n",
    "plt.title(\"Tourist Licenses Over Time by District\")\n",
    "plt.xlabel(\"Time (Year_Quarter)\")\n",
    "plt.ylabel(\"Number of Licenses\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36a5a7",
   "metadata": {},
   "source": [
    "We can see that the number of tourist licenses remained stable in most districts over time, with a notable increase starting in 2023 for a few districts - especially district 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf20a7f",
   "metadata": {},
   "source": [
    "### **Distribution of Tourist Housing Licenses**\n",
    "\n",
    "We inspect the distribution of license counts across districts to assess skewness and concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2af7389b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(pdf_hut_dis[\"TOTAL\"], bins=20, kde=True)  # we have to use the Pandas DataFrame here\n",
    "plt.title(\"Distribution of Tourist Licenses per District (Q1 2022)\")\n",
    "plt.xlabel(\"Number of Licenses\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d072a42",
   "metadata": {},
   "source": [
    "We can see that the distribution of tourist licenses across districts is highly right-skewed, with most districts having relatively few licenses and only one or two with exceptionally high numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58ab82c",
   "metadata": {},
   "source": [
    "### **KPI Summary Table**\n",
    "\n",
    "We combine multiple KPIs for each district, providing an at-a-glance comparison of household size, tourism pressure, and commercial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71fa0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mf/w_wd3t0951z162wpkh1xbddc0000gn/T/ipykernel_96297/1910876596.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  avg_household = pdf_household_dis.groupby(\"COD_DISTRICTE\").apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_DISTRICTE</th>\n",
       "      <th>NUM_TOURIST_LICENSES</th>\n",
       "      <th>NUM_COMMERCIAL_PREMISES</th>\n",
       "      <th>TOTAL_IND_COWORKING</th>\n",
       "      <th>TOTAL_IND_OCI_NOCTURN</th>\n",
       "      <th>AVG_HOUSEHOLD_SIZE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>1637</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>1377</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>4001</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>1040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>3027</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>695</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2</td>\n",
       "      <td>4378</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.337383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>731</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>2120</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>1017</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>1134</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>781</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>1362</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>2816</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>982</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>335</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.458589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>2048</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>727</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>418</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>600</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>213</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>6</td>\n",
       "      <td>1055</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.269660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>214</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>672</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>1504</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>1682</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>182</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>1111</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>614</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>592</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>285</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>434</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>2212</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>847</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>691</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>5</td>\n",
       "      <td>491</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.581935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>302</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>1054</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.436087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>1517</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>495</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>602</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>614</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>218</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.409038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>651</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>1728</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.464967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>590</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>1515</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.490032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     COD_DISTRICTE  NUM_TOURIST_LICENSES  NUM_COMMERCIAL_PREMISES  \\\n",
       "158              2                  4378                      274   \n",
       "150              2                  4378                      444   \n",
       "143              2                  4378                     1637   \n",
       "144              2                  4378                      201   \n",
       "145              2                  4378                     1377   \n",
       "146              2                  4378                      126   \n",
       "147              2                  4378                      546   \n",
       "149              2                  4378                     4001   \n",
       "148              2                  4378                      483   \n",
       "151              2                  4378                     1040   \n",
       "152              2                  4378                      316   \n",
       "153              2                  4378                     3027   \n",
       "154              2                  4378                       47   \n",
       "155              2                  4378                      256   \n",
       "156              2                  4378                      695   \n",
       "157              2                  4378                      203   \n",
       "24               3                  1134                      731   \n",
       "30               3                  1134                      170   \n",
       "29               3                  1134                      178   \n",
       "28               3                  1134                       78   \n",
       "27               3                  1134                      122   \n",
       "26               3                  1134                       33   \n",
       "25               3                  1134                     2120   \n",
       "31               3                  1134                       40   \n",
       "23               3                  1134                      781   \n",
       "21               3                  1134                      245   \n",
       "20               3                  1134                     1017   \n",
       "19               3                  1134                      143   \n",
       "18               3                  1134                      119   \n",
       "17               3                  1134                      218   \n",
       "16               3                  1134                      178   \n",
       "22               3                  1134                       97   \n",
       "119             10                  1120                      117   \n",
       "111             10                  1120                      152   \n",
       "112             10                  1120                      226   \n",
       "113             10                  1120                       79   \n",
       "114             10                  1120                      781   \n",
       "115             10                  1120                      104   \n",
       "117             10                  1120                      196   \n",
       "118             10                  1120                       97   \n",
       "116             10                  1120                      302   \n",
       "120             10                  1120                     1362   \n",
       "122             10                  1120                     2816   \n",
       "123             10                  1120                      982   \n",
       "124             10                  1120                      247   \n",
       "125             10                  1120                      311   \n",
       "126             10                  1120                      335   \n",
       "121             10                  1120                       52   \n",
       "72               6                  1055                       64   \n",
       "66               6                  1055                      160   \n",
       "67               6                  1055                      227   \n",
       "68               6                  1055                     2048   \n",
       "69               6                  1055                      727   \n",
       "70               6                  1055                      418   \n",
       "71               6                  1055                      120   \n",
       "75               6                  1055                      600   \n",
       "73               6                  1055                      769   \n",
       "74               6                  1055                      201   \n",
       "76               6                  1055                      239   \n",
       "77               6                  1055                       20   \n",
       "78               6                  1055                       12   \n",
       "64               6                  1055                       66   \n",
       "65               6                  1055                      213   \n",
       "79               6                  1055                       69   \n",
       "105              1                   605                      214   \n",
       "104              1                   605                       31   \n",
       "98               1                   605                      117   \n",
       "99               1                   605                      672   \n",
       "100              1                   605                        4   \n",
       "101              1                   605                     1504   \n",
       "102              1                   605                       19   \n",
       "103              1                   605                     1682   \n",
       "97               1                   605                      182   \n",
       "96               1                   605                       42   \n",
       "106              1                   605                      241   \n",
       "107              1                   605                     1111   \n",
       "108              1                   605                      170   \n",
       "109              1                   605                      857   \n",
       "110              1                   605                       76   \n",
       "62               5                   491                      614   \n",
       "63               5                   491                      592   \n",
       "48               5                   491                      265   \n",
       "54               5                   491                       66   \n",
       "59               5                   491                       55   \n",
       "57               5                   491                      285   \n",
       "56               5                   491                      133   \n",
       "55               5                   491                      434   \n",
       "60               5                   491                       83   \n",
       "53               5                   491                     2212   \n",
       "52               5                   491                      129   \n",
       "51               5                   491                      847   \n",
       "50               5                   491                       11   \n",
       "49               5                   491                      117   \n",
       "61               5                   491                      691   \n",
       "58               5                   491                      218   \n",
       "139              4                   257                       37   \n",
       "141              4                   257                       90   \n",
       "142              4                   257                      302   \n",
       "138              4                   257                       50   \n",
       "137              4                   257                     1054   \n",
       "136              4                   257                       11   \n",
       "135              4                   257                      154   \n",
       "134              4                   257                      124   \n",
       "133              4                   257                       52   \n",
       "132              4                   257                      152   \n",
       "131              4                   257                      167   \n",
       "130              4                   257                       76   \n",
       "129              4                   257                      316   \n",
       "140              4                   257                       26   \n",
       "128              4                   257                      502   \n",
       "127              4                   257                       70   \n",
       "8                7                   218                       12   \n",
       "2                7                   218                     1517   \n",
       "3                7                   218                      148   \n",
       "4                7                   218                       60   \n",
       "5                7                   218                      156   \n",
       "6                7                   218                      145   \n",
       "7                7                   218                      203   \n",
       "9                7                   218                      495   \n",
       "1                7                   218                       51   \n",
       "10               7                   218                      143   \n",
       "11               7                   218                      602   \n",
       "12               7                   218                       69   \n",
       "13               7                   218                      122   \n",
       "14               7                   218                      614   \n",
       "15               7                   218                       66   \n",
       "0                7                   218                       24   \n",
       "82               9                    76                      560   \n",
       "80               9                    76                      179   \n",
       "84               9                    76                      651   \n",
       "85               9                    76                     1728   \n",
       "86               9                    76                      578   \n",
       "87               9                    76                      192   \n",
       "83               9                    76                      236   \n",
       "88               9                    76                       56   \n",
       "89               9                    76                       88   \n",
       "90               9                    76                       43   \n",
       "91               9                    76                      161   \n",
       "92               9                    76                      165   \n",
       "93               9                    76                       69   \n",
       "94               9                    76                       40   \n",
       "95               9                    76                      198   \n",
       "81               9                    76                       68   \n",
       "33               8                    29                       79   \n",
       "32               8                    29                      163   \n",
       "34               8                    29                      590   \n",
       "47               8                    29                      173   \n",
       "46               8                    29                      512   \n",
       "45               8                    29                      103   \n",
       "44               8                    29                      215   \n",
       "43               8                    29                      191   \n",
       "42               8                    29                      156   \n",
       "41               8                    29                     1515   \n",
       "40               8                    29                       54   \n",
       "38               8                    29                      137   \n",
       "37               8                    29                      754   \n",
       "36               8                    29                       54   \n",
       "35               8                    29                       19   \n",
       "39               8                    29                       22   \n",
       "\n",
       "     TOTAL_IND_COWORKING  TOTAL_IND_OCI_NOCTURN  AVG_HOUSEHOLD_SIZE  \n",
       "158                    1                      0            2.337383  \n",
       "150                    0                      0            2.337383  \n",
       "143                    0                      0            2.337383  \n",
       "144                    1                      0            2.337383  \n",
       "145                    2                      3            2.337383  \n",
       "146                    0                      0            2.337383  \n",
       "147                    0                      0            2.337383  \n",
       "149                   30                      0            2.337383  \n",
       "148                    0                      0            2.337383  \n",
       "151                    0                      0            2.337383  \n",
       "152                    0                      0            2.337383  \n",
       "153                    0                     34            2.337383  \n",
       "154                    0                      0            2.337383  \n",
       "155                    0                      0            2.337383  \n",
       "156                    1                      0            2.337383  \n",
       "157                    0                      4            2.337383  \n",
       "24                     6                      5            2.405275  \n",
       "30                     0                      0            2.405275  \n",
       "29                     0                      0            2.405275  \n",
       "28                     0                      0            2.405275  \n",
       "27                     1                      2            2.405275  \n",
       "26                     1                      0            2.405275  \n",
       "25                    20                      0            2.405275  \n",
       "31                     0                      0            2.405275  \n",
       "23                     0                      0            2.405275  \n",
       "21                     0                      0            2.405275  \n",
       "20                     1                     30            2.405275  \n",
       "19                     0                      0            2.405275  \n",
       "18                     0                      0            2.405275  \n",
       "17                     0                      0            2.405275  \n",
       "16                     0                      0            2.405275  \n",
       "22                     0                      0            2.405275  \n",
       "119                    0                      0            2.458589  \n",
       "111                    0                      0            2.458589  \n",
       "112                    0                      0            2.458589  \n",
       "113                    0                      0            2.458589  \n",
       "114                    1                      1            2.458589  \n",
       "115                    0                      0            2.458589  \n",
       "117                    0                      0            2.458589  \n",
       "118                    0                      0            2.458589  \n",
       "116                    0                      0            2.458589  \n",
       "120                    2                      9            2.458589  \n",
       "122                   24                      0            2.458589  \n",
       "123                    1                      0            2.458589  \n",
       "124                    0                      0            2.458589  \n",
       "125                    0                      0            2.458589  \n",
       "126                    1                      0            2.458589  \n",
       "121                    0                      0            2.458589  \n",
       "72                     0                      0            2.269660  \n",
       "66                     0                      0            2.269660  \n",
       "67                     1                      0            2.269660  \n",
       "68                    25                      0            2.269660  \n",
       "69                     0                     14            2.269660  \n",
       "70                     1                      0            2.269660  \n",
       "71                     0                      0            2.269660  \n",
       "75                     3                      1            2.269660  \n",
       "73                     0                      0            2.269660  \n",
       "74                     0                      0            2.269660  \n",
       "76                     0                      0            2.269660  \n",
       "77                     0                      0            2.269660  \n",
       "78                     0                      0            2.269660  \n",
       "64                     1                      0            2.269660  \n",
       "65                     1                      0            2.269660  \n",
       "79                     0                      0            2.269660  \n",
       "105                    1                      0            2.350724  \n",
       "104                    0                      0            2.350724  \n",
       "98                     0                      0            2.350724  \n",
       "99                     1                      0            2.350724  \n",
       "100                    0                      0            2.350724  \n",
       "101                    0                     38            2.350724  \n",
       "102                    0                      0            2.350724  \n",
       "103                   27                      0            2.350724  \n",
       "97                     5                      0            2.350724  \n",
       "96                     0                      0            2.350724  \n",
       "106                    0                      0            2.350724  \n",
       "107                    2                      4            2.350724  \n",
       "108                    0                      0            2.350724  \n",
       "109                    1                      0            2.350724  \n",
       "110                    1                      0            2.350724  \n",
       "62                     1                      0            2.581935  \n",
       "63                    14                      3            2.581935  \n",
       "48                     2                      0            2.581935  \n",
       "54                     1                      0            2.581935  \n",
       "59                     2                      0            2.581935  \n",
       "57                     4                      0            2.581935  \n",
       "56                     1                      0            2.581935  \n",
       "55                    17                      0            2.581935  \n",
       "60                     0                      0            2.581935  \n",
       "53                    92                      0            2.581935  \n",
       "52                     0                      0            2.581935  \n",
       "51                     1                     42            2.581935  \n",
       "50                     2                      0            2.581935  \n",
       "49                     0                      0            2.581935  \n",
       "61                     1                      0            2.581935  \n",
       "58                     0                      0            2.581935  \n",
       "139                    0                      3            2.436087  \n",
       "141                    0                      0            2.436087  \n",
       "142                    2                      1            2.436087  \n",
       "138                    0                      0            2.436087  \n",
       "137                    7                      0            2.436087  \n",
       "136                    0                      0            2.436087  \n",
       "135                    0                      0            2.436087  \n",
       "134                    0                      0            2.436087  \n",
       "133                    0                      0            2.436087  \n",
       "132                    0                      0            2.436087  \n",
       "131                    0                      0            2.436087  \n",
       "130                    0                      0            2.436087  \n",
       "129                    0                      0            2.436087  \n",
       "140                    0                      0            2.436087  \n",
       "128                    0                      8            2.436087  \n",
       "127                    0                      0            2.436087  \n",
       "8                      0                      0            2.409038  \n",
       "2                      2                      1            2.409038  \n",
       "3                      0                      0            2.409038  \n",
       "4                      0                      0            2.409038  \n",
       "5                      0                      0            2.409038  \n",
       "6                      0                      0            2.409038  \n",
       "7                      0                      0            2.409038  \n",
       "9                      1                      3            2.409038  \n",
       "1                      0                      1            2.409038  \n",
       "10                     0                      0            2.409038  \n",
       "11                     0                      0            2.409038  \n",
       "12                     0                      0            2.409038  \n",
       "13                     0                      0            2.409038  \n",
       "14                     1                      2            2.409038  \n",
       "15                     0                      0            2.409038  \n",
       "0                      0                      0            2.409038  \n",
       "82                     0                      3            2.464967  \n",
       "80                     0                      0            2.464967  \n",
       "84                     0                      5            2.464967  \n",
       "85                     5                      0            2.464967  \n",
       "86                     0                      0            2.464967  \n",
       "87                     0                      0            2.464967  \n",
       "83                     0                      0            2.464967  \n",
       "88                     0                      0            2.464967  \n",
       "89                     0                      0            2.464967  \n",
       "90                     0                      0            2.464967  \n",
       "91                     0                      0            2.464967  \n",
       "92                     0                      0            2.464967  \n",
       "93                     0                      0            2.464967  \n",
       "94                     0                      0            2.464967  \n",
       "95                     0                      0            2.464967  \n",
       "81                     0                      0            2.464967  \n",
       "33                     0                      0            2.490032  \n",
       "32                     0                      0            2.490032  \n",
       "34                     0                      2            2.490032  \n",
       "47                     0                      0            2.490032  \n",
       "46                     1                      0            2.490032  \n",
       "45                     0                      0            2.490032  \n",
       "44                     0                      0            2.490032  \n",
       "43                     0                      0            2.490032  \n",
       "42                     0                      0            2.490032  \n",
       "41                     3                      0            2.490032  \n",
       "40                     0                      0            2.490032  \n",
       "38                     1                      0            2.490032  \n",
       "37                     0                      0            2.490032  \n",
       "36                     0                      0            2.490032  \n",
       "35                     0                      0            2.490032  \n",
       "39                     0                      0            2.490032  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/24 06:14:51 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 2055405 ms exceeds timeout 120000 ms\n",
      "25/06/24 06:14:51 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "25/06/24 06:14:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 06:14:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 06:51:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 06:51:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 06:51:53 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 06:51:53 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 06:52:03 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 06:52:03 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 07:24:03 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 07:24:03 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 07:52:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 07:52:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 08:00:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 08:00:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 08:17:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 08:17:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 08:53:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 08:53:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 08:53:53 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 08:53:53 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 09:27:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 09:27:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 09:54:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 09:54:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 10:00:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 10:00:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 10:17:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 10:17:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 10:55:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 10:55:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 11:12:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 11:12:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 11:43:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 11:43:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 11:56:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 11:56:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 12:57:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 12:57:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 13:53:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 13:53:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 13:53:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 13:53:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 13:58:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 13:58:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 14:00:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 14:00:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 14:18:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 14:18:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 14:52:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 14:52:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 14:59:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 14:59:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 15:02:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 15:02:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 16:00:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 16:00:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 17:01:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 17:01:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:02:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:02:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:02:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:02:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:19:03 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:19:03 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:19:13 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:19:13 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:31:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:31:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:31:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:31:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:32:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:32:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:32:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:32:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:32:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:32:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:32:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:32:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:32:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:32:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:32:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:32:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:33:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:33:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:33:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:33:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:33:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:33:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:33:33 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:33:33 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:33:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:33:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:33:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:33:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:34:03 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:34:03 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:34:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:34:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:34:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:34:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:34:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:34:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:34:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:34:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:34:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:34:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:35:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:35:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:35:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:35:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:35:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:35:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:35:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:35:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:35:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:35:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:35:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:35:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/24 18:36:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1240)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:296)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:36:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.23:51053\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/24 18:36:02 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "# We compute average household size per district:\n",
    "avg_household = pdf_household_dis.groupby(\"COD_DISTRICTE\").apply(\n",
    "    lambda g: (g[\"NUM_PERSONES_AGG\"] * g[\"NUM_VALOR\"]).sum() / g[\"NUM_VALOR\"].sum()\n",
    ").reset_index(name=\"AVG_HOUSEHOLD_SIZE\")\n",
    "\n",
    "# We join with tourist housing:\n",
    "df_kpi = pdf_hut_dis.merge(avg_household, on=\"COD_DISTRICTE\", how=\"left\")\n",
    "\n",
    "# We also merge commercial indicators (PCT already computed):\n",
    "df_kpi = df_kpi.merge(\n",
    "    pdf_com_dis[[\"COD_DISTRICTE\", \"TOTAL\", \"TOTAL_IND_COWORKING\", \"TOTAL_IND_OCI_NOCTURN\"]],\n",
    "    on=\"COD_DISTRICTE\", how=\"left\"\n",
    ")\n",
    "\n",
    "df_kpi = df_kpi.rename(columns={\"TOTAL_x\": \"NUM_TOURIST_LICENSES\", \"TOTAL_y\": \"NUM_COMMERCIAL_PREMISES\"})\n",
    "\n",
    "# to see all columns:\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# Display final KPI table:\n",
    "df_kpi_sorted = df_kpi.sort_values(\"NUM_TOURIST_LICENSES\", ascending=False)\n",
    "df_kpi_sorted[[\"COD_DISTRICTE\", \"NUM_TOURIST_LICENSES\", \"NUM_COMMERCIAL_PREMISES\", \n",
    "               \"TOTAL_IND_COWORKING\", \"TOTAL_IND_OCI_NOCTURN\", \"AVG_HOUSEHOLD_SIZE\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lab3_env)",
   "language": "python",
   "name": "lab3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
